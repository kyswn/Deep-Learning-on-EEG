{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "ShallowCNN_ differenttime.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBXueCiGvQeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a0e03ce-0a4e-4d6e-f3bd-48f4a68c72c4"
      },
      "source": [
        "## Importing the necessary packages\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
        "from torchvision import transforms, utils\n",
        "import time\n",
        "\n",
        "# get the device type of machine\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device = 'cpu'\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJDRmqho71-z",
        "outputId": "5be4e5e3-d7d4-4442-ec9c-1cd0cd16cb39"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "% cd 'drive/My Drive/ECE C147'\r\n",
        "% cd 'project'\r\n",
        "% ls\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/ECE C147\n",
            "/content/drive/My Drive/ECE C147/project\n",
            "EEG_loading.ipynb  person_train_valid.npy  X_train_valid.npy  y_train_valid.npy\n",
            "person_test.npy    X_test.npy              y_test.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZSMiUd4vQer"
      },
      "source": [
        "## Loading the dataset and creating a windowed version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPruGHz5vQes",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c7fc76-5400-4816-ce9c-d30cbb199724"
      },
      "source": [
        "## Loading the numpy arrays\n",
        "\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "person_test = np.load(\"person_test.npy\")\n",
        "\n",
        "## Adjusting the labels so that \n",
        "\n",
        "# Cue onset left - 0\n",
        "# Cue onset right - 1\n",
        "# Cue onset foot - 2\n",
        "# Cue onset tongue - 3\n",
        "\n",
        "y_train_valid -= 769\n",
        "y_test -= 769\n",
        "\n",
        "\n",
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv1uiZd5vQes"
      },
      "source": [
        "def make_steps(samples,samples_per_frame,stride):\n",
        "    '''\n",
        "    in:\n",
        "    samples - number of samples in the session\n",
        "    samples_per_frame - number of samples in the frame\n",
        "    stride - the gap between succesive frames\n",
        "    out: list of tuple ranges\n",
        "    '''\n",
        "    \n",
        "    i = 0\n",
        "    intervals = []\n",
        "    while i+samples_per_frame <= samples:\n",
        "        intervals.append((i,i+samples_per_frame))\n",
        "        i = i + stride\n",
        "    return intervals\n",
        "\n",
        "def make_win_data_pipeline(data_arr,label_arr,num_samples_frame,stride):\n",
        "    '''\n",
        "    in:\n",
        "    data_arr - original data array without windowing\n",
        "    label_arr - labels of the data array without windowing\n",
        "    num_samples_frame - number of samples in the frame\n",
        "    stride - the gap between succesive frames\n",
        "    \n",
        "    out:\n",
        "    data_win_arr - windowed data array\n",
        "    label_win_arr - labels of the windowed data array\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    num_trials = data_arr.shape[0]\n",
        "    num_channels = data_arr.shape[1]\n",
        "    num_samples = data_arr.shape[2]\n",
        "    \n",
        "    steps_list = make_steps(num_samples,num_samples_frame,stride)\n",
        "    num_windows = len(steps_list)\n",
        "    \n",
        "    data_win_arr = np.zeros((num_trials*num_windows,num_channels,num_samples_frame))\n",
        "    label_win_arr = []\n",
        "    k = 0\n",
        "    \n",
        "    for i in range(num_trials):\n",
        "        \n",
        "        trial_label = label_arr[i]\n",
        "        trial_data = data_arr[i,:,:]\n",
        "        \n",
        "        for m,n in enumerate(steps_list):\n",
        "            start_ind = n[0]\n",
        "            end_ind = n[1]\n",
        "            \n",
        "            win_data = trial_data[:,start_ind:end_ind]\n",
        "            data_win_arr[k,:,:] = win_data\n",
        "            label_win_arr.append(trial_label)\n",
        "            k = k+1\n",
        "    \n",
        "    label_win_arr = np.asarray(label_win_arr)\n",
        "    return data_win_arr, label_win_arr\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CU1r0LMvQet"
      },
      "source": [
        "## Creating the custom dataset for torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAteGY4RvQet"
      },
      "source": [
        "# Creating the custom dataset\n",
        "\n",
        "class EEGDataset(Dataset):\n",
        "    \n",
        "    \"\"\"EEG dataset\"\"\"\n",
        "    def __init__(self, subset, transform=None):\n",
        "        \n",
        "        'Initialization'\n",
        "        \n",
        "        self.subset = subset\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        'Generates one sample of data'\n",
        "        \n",
        "        x, y = self.subset[index]\n",
        "        if self.transform:\n",
        "          pass \n",
        "            # x = self.transform(x)\n",
        "            # y = self.transform(y)\n",
        "        return x, y\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        'Denotes the total number of samples'\n",
        "        return len(self.subset)\n",
        "    \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFOWYgUzvQeu"
      },
      "source": [
        "## Defining the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMeAP64pvQeu"
      },
      "source": [
        "# Defining the shallow conv net\n",
        "\n",
        "\n",
        "class ShallowConv(nn.Module):\n",
        "    \n",
        "    # Defining the building blocks of shallow conv net\n",
        "    \n",
        "    def __init__(self, in_channels, num_conv_filters, num_samples_frame, num_eeg_channels,classes):\n",
        "    \n",
        "        # Defining as a subclass\n",
        "        super(ShallowConv, self).__init__()\n",
        "\n",
        "        self.num_samples_frame = num_samples_frame\n",
        "        self.num_conv_filters = num_conv_filters\n",
        "        self.num_eeg_channels = num_eeg_channels\n",
        "        \n",
        "        # Define the convolution layer, https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "        self.conv1 = nn.Conv2d(in_channels, self.num_conv_filters, (1, 25), stride=1)\n",
        "        self.conv_output_width =  int(self.num_samples_frame - (25-1) - 1 + 1)\n",
        "        \n",
        "        # Define the 2d batchnorm layer\n",
        "        self.bnorm2d = nn.BatchNorm2d(self.num_conv_filters)\n",
        "        \n",
        "        # Define the 1d batchnorm layer\n",
        "        self.bnorm1d = nn.BatchNorm1d(self.num_conv_filters)\n",
        "\n",
        "\n",
        "        # Define the fc layer, https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
        "        self.fc1 = nn.Linear(self.num_eeg_channels*self.num_conv_filters, self.num_conv_filters)\n",
        "        \n",
        "        # Define the elu activation\n",
        "        self.elu = nn.ELU(0.2)\n",
        "\n",
        "        # Define the avg pooling layer\n",
        "        self.avgpool = nn.AvgPool1d(75, stride=15)\n",
        "        \n",
        "        self.num_features_linear = int(np.floor(((self.conv_output_width - 75)/15)+1))\n",
        "        \n",
        "        \n",
        "\n",
        "        # Define the fc layer for generating the scores for classes \n",
        "        self.fc2 = nn.Linear(self.num_features_linear*self.num_conv_filters, classes)\n",
        "\n",
        "    \n",
        "    \n",
        "      # Defining the connections of shallow conv net\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # Reshaping the input for 2-D convolution (B,22,num_samples_frame) -> (B,1,22,num_samples_frame)\n",
        "        \n",
        "        x = x.view(-1, 1, 22, self.num_samples_frame)\n",
        "        \n",
        "        # Performing the 2-D convolution (B,1,22,300) -> (B,40,22,x_shape_4dim)\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x_shape_4dim = x.shape[3]\n",
        "        \n",
        "        # ELU activation\n",
        "        \n",
        "        x = self.elu(x)\n",
        "        \n",
        "        # 2d Batch normalization\n",
        "        \n",
        "        x = self.bnorm2d(x)\n",
        "        \n",
        "        \n",
        "        # Reshaping the input to dense layer (B,40,22,x_shape_4dim) -> (B,x_shape_4dim,880)\n",
        "        \n",
        "        x = x.permute(0,3,1,2) # (B,40,22,x_shape_4dim) -> (B,x_shape_4dim,40,22)\n",
        "        x = x.view(-1,x_shape_4dim,880)\n",
        "        \n",
        "        # Passing through the dense layer (B,x_shape_4dim,880) -> (B,x_shape_4dim,40)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        \n",
        "        # ELU activation\n",
        "        \n",
        "        x = self.elu(x)\n",
        "        \n",
        "        # Square activation\n",
        "        \n",
        "        x = torch.square(x)\n",
        "        \n",
        "        # Reshaping the input for average pooling layer (B,x_shape_4dim,40) -> (B,40,x_shape_4dim)\n",
        "        \n",
        "        x = x.permute(0,2,1)\n",
        "        \n",
        "        # Passing through the average pooling layer (B,40,x_shape_4dim) -> (B,40,x_pool_3dim)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x_pool_3dim = x.shape[2]\n",
        "        \n",
        "        # Log activation\n",
        "        \n",
        "        x = torch.log(x)\n",
        "        \n",
        "        # 1D Batch normalization\n",
        "        \n",
        "        x = self.bnorm1d(x)\n",
        "        #print(x.shape)\n",
        "        \n",
        "        # Reshaping the input to dense layer (B,40,x_pool_3dim) -> (B,40*x_pool_3dim)\n",
        "        \n",
        "        x = x.reshape(-1, 40*x_pool_3dim)\n",
        "        \n",
        "        # Passing through the dense layer (B,40*x_pool_3dim) -> (B,classes)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        # Passing through the softmax layer\n",
        "        \n",
        "        \n",
        "        \n",
        "        return x"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBTctV0gvQev"
      },
      "source": [
        "## Defining the training and validation of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81kG34njvQev"
      },
      "source": [
        "## Defining the training and validation function\n",
        "\n",
        "def train_val(model,optimizer,criterion,num_epochs):\n",
        "    \n",
        "    \n",
        "    \n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    val_loss = []\n",
        "    val_acc = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        for phase in ['train','val']:\n",
        "            \n",
        "            \n",
        "            \n",
        "            #Initializing the losses and accuracy\n",
        "            \n",
        "            training_loss = 0\n",
        "            correct_train_preds = 0\n",
        "            total_train_preds = 0\n",
        "            batch_train_idx = 0\n",
        "            \n",
        "            validation_loss = 0\n",
        "            correct_val_preds = 0\n",
        "            total_val_preds = 0\n",
        "            batch_val_idx = 0\n",
        "            \n",
        "            \n",
        "            # Implementing the training phase\n",
        "            \n",
        "            if phase == 'train':\n",
        "                \n",
        "                # setting the model to training mode\n",
        "                \n",
        "                model.train()\n",
        "                \n",
        "                # Loading the training dataset in batches \n",
        "                \n",
        "                for inputs, labels in dataloaders['train']:\n",
        "                    \n",
        "                    # Transfer input data and labels to device\n",
        "                    \n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "                    \n",
        "                    # Incrementing the batch counter\n",
        "                    \n",
        "                    batch_train_idx += 1\n",
        "                    \n",
        "                    # Zeroing the gradient buffer\n",
        "                    \n",
        "                    optimizer.zero_grad()\n",
        "                    \n",
        "                    # Perform the forward pass\n",
        "                    \n",
        "                    outputs = model(inputs)\n",
        "                    \n",
        "                    # Compute loss\n",
        "                    \n",
        "                    loss = criterion(outputs,labels)\n",
        "                    \n",
        "                    \n",
        "                    # Perform the backward pass\n",
        "                    \n",
        "                    loss.backward()\n",
        "                    \n",
        "                    # Perform optimization step\n",
        "                    \n",
        "                    optimizer.step()\n",
        "                    \n",
        "                    # Compute training statistics\n",
        "                    \n",
        "                    training_loss += loss.item()\n",
        "                    _, predicted = outputs.max(1)\n",
        "                    total_train_preds += labels.size(0)\n",
        "                    correct_train_preds += predicted.eq(labels).sum().item()\n",
        "                    \n",
        "                \n",
        "                train_loss.append(training_loss)\n",
        "                t_acc = correct_train_preds/total_train_preds\n",
        "                train_acc.append(t_acc)\n",
        "                print('Training loss:',training_loss)\n",
        "                print('Training accuracy:',t_acc)\n",
        "                \n",
        "                    \n",
        "            else:\n",
        "                \n",
        "                \n",
        "                \n",
        "                # setting the model to evaluation mode\n",
        "                \n",
        "                model.eval()\n",
        "                \n",
        "                # Disable gradient computation\n",
        "                \n",
        "                with torch.no_grad():\n",
        "                    \n",
        "                    # Loading the training dataset in batches \n",
        "                    \n",
        "                    for val_inputs, val_labels in dataloaders['val']:\n",
        "                        \n",
        "                        \n",
        "                        # Transfer input data and labels to device\n",
        "                    \n",
        "                        val_inputs = val_inputs.to(device)\n",
        "                        val_labels = val_labels.to(device)\n",
        "                        \n",
        "                        # Incrementing the batch counter\n",
        "                    \n",
        "                        batch_val_idx += 1\n",
        "                        \n",
        "                        # Perform forward pass\n",
        "                        \n",
        "                        val_outputs = model(val_inputs)\n",
        "                        \n",
        "                        # Compute loss\n",
        "                        \n",
        "                        valid_loss = criterion(val_outputs,val_labels)\n",
        "                        \n",
        "                        \n",
        "                        # Compute validation statistics\n",
        "                    \n",
        "                        validation_loss += valid_loss.item()\n",
        "                        _, val_predicted = val_outputs.max(1)\n",
        "                        total_val_preds += val_labels.size(0)\n",
        "                        correct_val_preds += val_predicted.eq(val_labels).sum().item()\n",
        "                        \n",
        "                    val_loss.append(validation_loss)\n",
        "                    v_acc = correct_val_preds/total_val_preds\n",
        "                    val_acc.append(v_acc)\n",
        "                    print('Validation loss:',validation_loss)\n",
        "                    print('Validation accuracy:',v_acc)\n",
        "            \n",
        "\n",
        "            \n",
        "           \n",
        "        \n",
        "    return model, train_loss, train_acc, val_loss, val_acc\n",
        "                    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvU5klhkvQey"
      },
      "source": [
        "## Training,validating and testing the model with 1000 samples per trial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIhersN7vQe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ea8eea-c987-43a7-aa5b-cd55a9fc5d73"
      },
      "source": [
        "## Preparing the training and validation data\n",
        "\n",
        "num_samples_frame = 1000\n",
        "stride = 50\n",
        "X_train_win,y_train_win = make_win_data_pipeline(X_train_valid,y_train_valid,num_samples_frame,stride)\n",
        "\n",
        "print ('Windowed Training/Valid data shape: {}'.format(X_train_win.shape))\n",
        "print ('Windowed Training/Valid label shape: {}'.format(y_train_win.shape))\n",
        "\n",
        "# Converting the numpy data to torch tensors\n",
        "\n",
        "X_train_valid_tensor = torch.from_numpy(X_train_win).float().to(device)\n",
        "y_train_valid_tensor = torch.from_numpy(y_train_win).float().long().to(device) \n",
        "\n",
        "print ('Training/Valid tensor shape: {}'.format(X_train_valid_tensor.shape))\n",
        "print ('Training/Valid target tensor shape: {}'.format(y_train_valid_tensor.shape))\n",
        "\n",
        "init_dataset = TensorDataset(X_train_valid_tensor, y_train_valid_tensor) \n",
        "\n",
        "# Spliting the dataset into training and validation\n",
        "\n",
        "lengths = [int(len(init_dataset)*0.8), int(len(init_dataset)*0.2)] \n",
        "subset_train, subset_val = random_split(init_dataset, lengths) \n",
        "\n",
        "train_data = EEGDataset(subset_train, transform=None)\n",
        "val_data = EEGDataset(subset_val, transform=None)\n",
        "\n",
        "# Constructing the training and validation dataloaders\n",
        "\n",
        "dataloaders = {\n",
        "    'train': torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=0),\n",
        "    'val': torch.utils.data.DataLoader(val_data, batch_size=8, shuffle=False, num_workers=0)\n",
        "}\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Windowed Training/Valid data shape: (2115, 22, 1000)\n",
            "Windowed Training/Valid label shape: (2115,)\n",
            "Training/Valid tensor shape: torch.Size([2115, 22, 1000])\n",
            "Training/Valid target tensor shape: torch.Size([2115])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCxWezukvQe0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06b8b10-18d8-49da-cdce-3a8e23e7db33"
      },
      "source": [
        "# Defining the parameters for model training\n",
        "\n",
        "\n",
        "weight_decay = 0.15  # weight decay to alleviate overfiting\n",
        "shallow_model = ShallowConv(in_channels=1, num_conv_filters=40,num_samples_frame=1000,num_eeg_channels=22,classes=4).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(shallow_model.parameters(), lr = 1e-4, weight_decay=weight_decay)\n",
        "\n",
        "# Training and validating the model\n",
        "num_epoch=200\n",
        "shallow_model,t_l,t_a,v_l,v_a=train_val(shallow_model, optimizer, criterion, num_epochs=num_epoch)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/199\n",
            "----------\n",
            "Training loss: 72.69222795963287\n",
            "Training accuracy: 0.3398345153664303\n",
            "Validation loss: 71.37843060493469\n",
            "Validation accuracy: 0.34515366430260047\n",
            "Epoch 1/199\n",
            "----------\n",
            "Training loss: 64.2348268032074\n",
            "Training accuracy: 0.458628841607565\n",
            "Validation loss: 68.03074586391449\n",
            "Validation accuracy: 0.3829787234042553\n",
            "Epoch 2/199\n",
            "----------\n",
            "Training loss: 58.912817895412445\n",
            "Training accuracy: 0.5437352245862884\n",
            "Validation loss: 66.1180517077446\n",
            "Validation accuracy: 0.44208037825059104\n",
            "Epoch 3/199\n",
            "----------\n",
            "Training loss: 54.28694397211075\n",
            "Training accuracy: 0.5986997635933806\n",
            "Validation loss: 63.72051686048508\n",
            "Validation accuracy: 0.47754137115839246\n",
            "Epoch 4/199\n",
            "----------\n",
            "Training loss: 49.75051301717758\n",
            "Training accuracy: 0.6418439716312057\n",
            "Validation loss: 61.95068734884262\n",
            "Validation accuracy: 0.48936170212765956\n",
            "Epoch 5/199\n",
            "----------\n",
            "Training loss: 45.919988095760345\n",
            "Training accuracy: 0.7021276595744681\n",
            "Validation loss: 60.607842206954956\n",
            "Validation accuracy: 0.4988179669030733\n",
            "Epoch 6/199\n",
            "----------\n",
            "Training loss: 43.60534071922302\n",
            "Training accuracy: 0.692080378250591\n",
            "Validation loss: 58.41928559541702\n",
            "Validation accuracy: 0.5295508274231678\n",
            "Epoch 7/199\n",
            "----------\n",
            "Training loss: 40.03717029094696\n",
            "Training accuracy: 0.7399527186761229\n",
            "Validation loss: 58.249530494213104\n",
            "Validation accuracy: 0.5295508274231678\n",
            "Epoch 8/199\n",
            "----------\n",
            "Training loss: 37.35034570097923\n",
            "Training accuracy: 0.7712765957446809\n",
            "Validation loss: 57.92374265193939\n",
            "Validation accuracy: 0.5200945626477541\n",
            "Epoch 9/199\n",
            "----------\n",
            "Training loss: 34.925532817840576\n",
            "Training accuracy: 0.7978723404255319\n",
            "Validation loss: 56.89697867631912\n",
            "Validation accuracy: 0.5531914893617021\n",
            "Epoch 10/199\n",
            "----------\n",
            "Training loss: 32.71536588668823\n",
            "Training accuracy: 0.8043735224586288\n",
            "Validation loss: 57.28828299045563\n",
            "Validation accuracy: 0.5460992907801419\n",
            "Epoch 11/199\n",
            "----------\n",
            "Training loss: 31.037609577178955\n",
            "Training accuracy: 0.8351063829787234\n",
            "Validation loss: 55.58171373605728\n",
            "Validation accuracy: 0.5602836879432624\n",
            "Epoch 12/199\n",
            "----------\n",
            "Training loss: 29.24411028623581\n",
            "Training accuracy: 0.8368794326241135\n",
            "Validation loss: 54.892154932022095\n",
            "Validation accuracy: 0.5602836879432624\n",
            "Epoch 13/199\n",
            "----------\n",
            "Training loss: 28.11726638674736\n",
            "Training accuracy: 0.849290780141844\n",
            "Validation loss: 53.14980113506317\n",
            "Validation accuracy: 0.5673758865248227\n",
            "Epoch 14/199\n",
            "----------\n",
            "Training loss: 26.586973011493683\n",
            "Training accuracy: 0.8676122931442081\n",
            "Validation loss: 53.83217138051987\n",
            "Validation accuracy: 0.5626477541371159\n",
            "Epoch 15/199\n",
            "----------\n",
            "Training loss: 24.632797956466675\n",
            "Training accuracy: 0.875886524822695\n",
            "Validation loss: 55.31429040431976\n",
            "Validation accuracy: 0.5791962174940898\n",
            "Epoch 16/199\n",
            "----------\n",
            "Training loss: 23.958768635988235\n",
            "Training accuracy: 0.8871158392434988\n",
            "Validation loss: 54.747388780117035\n",
            "Validation accuracy: 0.5815602836879432\n",
            "Epoch 17/199\n",
            "----------\n",
            "Training loss: 22.38500463962555\n",
            "Training accuracy: 0.8930260047281324\n",
            "Validation loss: 53.920591831207275\n",
            "Validation accuracy: 0.5626477541371159\n",
            "Epoch 18/199\n",
            "----------\n",
            "Training loss: 20.79124841094017\n",
            "Training accuracy: 0.9137115839243499\n",
            "Validation loss: 54.104821771383286\n",
            "Validation accuracy: 0.5673758865248227\n",
            "Epoch 19/199\n",
            "----------\n",
            "Training loss: 20.147637635469437\n",
            "Training accuracy: 0.9078014184397163\n",
            "Validation loss: 52.74014973640442\n",
            "Validation accuracy: 0.5910165484633569\n",
            "Epoch 20/199\n",
            "----------\n",
            "Training loss: 18.832579419016838\n",
            "Training accuracy: 0.9273049645390071\n",
            "Validation loss: 53.31650793552399\n",
            "Validation accuracy: 0.5886524822695035\n",
            "Epoch 21/199\n",
            "----------\n",
            "Training loss: 18.088350281119347\n",
            "Training accuracy: 0.9326241134751773\n",
            "Validation loss: 52.76390340924263\n",
            "Validation accuracy: 0.5721040189125296\n",
            "Epoch 22/199\n",
            "----------\n",
            "Training loss: 18.223428279161453\n",
            "Training accuracy: 0.9225768321513003\n",
            "Validation loss: 54.050298899412155\n",
            "Validation accuracy: 0.5886524822695035\n",
            "Epoch 23/199\n",
            "----------\n",
            "Training loss: 16.773193687200546\n",
            "Training accuracy: 0.9479905437352246\n",
            "Validation loss: 52.19854912161827\n",
            "Validation accuracy: 0.5957446808510638\n",
            "Epoch 24/199\n",
            "----------\n",
            "Training loss: 15.91927094757557\n",
            "Training accuracy: 0.9509456264775413\n",
            "Validation loss: 53.73776537179947\n",
            "Validation accuracy: 0.5910165484633569\n",
            "Epoch 25/199\n",
            "----------\n",
            "Training loss: 14.885555297136307\n",
            "Training accuracy: 0.9574468085106383\n",
            "Validation loss: 52.524815648794174\n",
            "Validation accuracy: 0.574468085106383\n",
            "Epoch 26/199\n",
            "----------\n",
            "Training loss: 14.868342369794846\n",
            "Training accuracy: 0.9544917257683215\n",
            "Validation loss: 51.96402868628502\n",
            "Validation accuracy: 0.6193853427895981\n",
            "Epoch 27/199\n",
            "----------\n",
            "Training loss: 13.642389431595802\n",
            "Training accuracy: 0.9680851063829787\n",
            "Validation loss: 51.239588886499405\n",
            "Validation accuracy: 0.6004728132387707\n",
            "Epoch 28/199\n",
            "----------\n",
            "Training loss: 12.807305365800858\n",
            "Training accuracy: 0.9745862884160756\n",
            "Validation loss: 51.571962386369705\n",
            "Validation accuracy: 0.624113475177305\n",
            "Epoch 29/199\n",
            "----------\n",
            "Training loss: 12.322634190320969\n",
            "Training accuracy: 0.9781323877068558\n",
            "Validation loss: 51.64811435341835\n",
            "Validation accuracy: 0.6099290780141844\n",
            "Epoch 30/199\n",
            "----------\n",
            "Training loss: 12.054148882627487\n",
            "Training accuracy: 0.9769503546099291\n",
            "Validation loss: 53.91779178380966\n",
            "Validation accuracy: 0.5957446808510638\n",
            "Epoch 31/199\n",
            "----------\n",
            "Training loss: 11.302030757069588\n",
            "Training accuracy: 0.9816784869976359\n",
            "Validation loss: 52.661547750234604\n",
            "Validation accuracy: 0.5910165484633569\n",
            "Epoch 32/199\n",
            "----------\n",
            "Training loss: 11.254769876599312\n",
            "Training accuracy: 0.9822695035460993\n",
            "Validation loss: 51.64089262485504\n",
            "Validation accuracy: 0.6028368794326241\n",
            "Epoch 33/199\n",
            "----------\n",
            "Training loss: 10.59535401314497\n",
            "Training accuracy: 0.9858156028368794\n",
            "Validation loss: 53.32457157969475\n",
            "Validation accuracy: 0.5981087470449172\n",
            "Epoch 34/199\n",
            "----------\n",
            "Training loss: 10.631253212690353\n",
            "Training accuracy: 0.9822695035460993\n",
            "Validation loss: 54.564577519893646\n",
            "Validation accuracy: 0.5981087470449172\n",
            "Epoch 35/199\n",
            "----------\n",
            "Training loss: 10.150461450219154\n",
            "Training accuracy: 0.9846335697399528\n",
            "Validation loss: 53.84715521335602\n",
            "Validation accuracy: 0.6004728132387707\n",
            "Epoch 36/199\n",
            "----------\n",
            "Training loss: 9.744563534855843\n",
            "Training accuracy: 0.9869976359338062\n",
            "Validation loss: 57.717907071113586\n",
            "Validation accuracy: 0.5957446808510638\n",
            "Epoch 37/199\n",
            "----------\n",
            "Training loss: 9.17240347713232\n",
            "Training accuracy: 0.9923167848699763\n",
            "Validation loss: 51.31465616822243\n",
            "Validation accuracy: 0.6099290780141844\n",
            "Epoch 38/199\n",
            "----------\n",
            "Training loss: 8.716569766402245\n",
            "Training accuracy: 0.9923167848699763\n",
            "Validation loss: 51.704347401857376\n",
            "Validation accuracy: 0.6052009456264775\n",
            "Epoch 39/199\n",
            "----------\n",
            "Training loss: 9.072686366736889\n",
            "Training accuracy: 0.9905437352245863\n",
            "Validation loss: 52.12783858180046\n",
            "Validation accuracy: 0.6028368794326241\n",
            "Epoch 40/199\n",
            "----------\n",
            "Training loss: 8.444063939154148\n",
            "Training accuracy: 0.9934988179669031\n",
            "Validation loss: 53.764831215143204\n",
            "Validation accuracy: 0.5886524822695035\n",
            "Epoch 41/199\n",
            "----------\n",
            "Training loss: 7.791539318859577\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 51.278284937143326\n",
            "Validation accuracy: 0.6146572104018913\n",
            "Epoch 42/199\n",
            "----------\n",
            "Training loss: 8.264672264456749\n",
            "Training accuracy: 0.9964539007092199\n",
            "Validation loss: 51.943486750125885\n",
            "Validation accuracy: 0.6359338061465721\n",
            "Epoch 43/199\n",
            "----------\n",
            "Training loss: 8.197252236306667\n",
            "Training accuracy: 0.9958628841607565\n",
            "Validation loss: 54.243615448474884\n",
            "Validation accuracy: 0.607565011820331\n",
            "Epoch 44/199\n",
            "----------\n",
            "Training loss: 8.025228083133698\n",
            "Training accuracy: 0.9940898345153665\n",
            "Validation loss: 52.870982229709625\n",
            "Validation accuracy: 0.6264775413711584\n",
            "Epoch 45/199\n",
            "----------\n",
            "Training loss: 7.97928436845541\n",
            "Training accuracy: 0.9929078014184397\n",
            "Validation loss: 50.898774445056915\n",
            "Validation accuracy: 0.6099290780141844\n",
            "Epoch 46/199\n",
            "----------\n",
            "Training loss: 7.495308689773083\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 56.37959420681\n",
            "Validation accuracy: 0.5460992907801419\n",
            "Epoch 47/199\n",
            "----------\n",
            "Training loss: 7.854111880064011\n",
            "Training accuracy: 0.9929078014184397\n",
            "Validation loss: 52.35579204559326\n",
            "Validation accuracy: 0.6122931442080378\n",
            "Epoch 48/199\n",
            "----------\n",
            "Training loss: 7.427817992866039\n",
            "Training accuracy: 0.9958628841607565\n",
            "Validation loss: 52.386441469192505\n",
            "Validation accuracy: 0.6052009456264775\n",
            "Epoch 49/199\n",
            "----------\n",
            "Training loss: 7.298483774065971\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 51.64736846089363\n",
            "Validation accuracy: 0.5791962174940898\n",
            "Epoch 50/199\n",
            "----------\n",
            "Training loss: 6.468833088874817\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 51.362381994724274\n",
            "Validation accuracy: 0.6099290780141844\n",
            "Epoch 51/199\n",
            "----------\n",
            "Training loss: 7.000610642135143\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 54.24182116985321\n",
            "Validation accuracy: 0.6052009456264775\n",
            "Epoch 52/199\n",
            "----------\n",
            "Training loss: 6.818972535431385\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 52.41977137327194\n",
            "Validation accuracy: 0.607565011820331\n",
            "Epoch 53/199\n",
            "----------\n",
            "Training loss: 6.933315820991993\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 50.14874956011772\n",
            "Validation accuracy: 0.6193853427895981\n",
            "Epoch 54/199\n",
            "----------\n",
            "Training loss: 6.535694621503353\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 51.55158659815788\n",
            "Validation accuracy: 0.6193853427895981\n",
            "Epoch 55/199\n",
            "----------\n",
            "Training loss: 6.434702895581722\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 50.94449430704117\n",
            "Validation accuracy: 0.6146572104018913\n",
            "Epoch 56/199\n",
            "----------\n",
            "Training loss: 6.270333617925644\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 51.361794859170914\n",
            "Validation accuracy: 0.6193853427895981\n",
            "Epoch 57/199\n",
            "----------\n",
            "Training loss: 6.611390650272369\n",
            "Training accuracy: 0.9964539007092199\n",
            "Validation loss: 51.023975521326065\n",
            "Validation accuracy: 0.6170212765957447\n",
            "Epoch 58/199\n",
            "----------\n",
            "Training loss: 6.478412874042988\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 52.513422667980194\n",
            "Validation accuracy: 0.5957446808510638\n",
            "Epoch 59/199\n",
            "----------\n",
            "Training loss: 6.580407455563545\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 50.186165779829025\n",
            "Validation accuracy: 0.6217494089834515\n",
            "Epoch 60/199\n",
            "----------\n",
            "Training loss: 6.131832458078861\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 49.0951769053936\n",
            "Validation accuracy: 0.6146572104018913\n",
            "Epoch 61/199\n",
            "----------\n",
            "Training loss: 7.021113745868206\n",
            "Training accuracy: 0.9964539007092199\n",
            "Validation loss: 52.748048573732376\n",
            "Validation accuracy: 0.6122931442080378\n",
            "Epoch 62/199\n",
            "----------\n",
            "Training loss: 6.660607025027275\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 51.329684764146805\n",
            "Validation accuracy: 0.6193853427895981\n",
            "Epoch 63/199\n",
            "----------\n",
            "Training loss: 5.924497276544571\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 52.47726371884346\n",
            "Validation accuracy: 0.6170212765957447\n",
            "Epoch 64/199\n",
            "----------\n",
            "Training loss: 6.54555020481348\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 55.528781563043594\n",
            "Validation accuracy: 0.5839243498817966\n",
            "Epoch 65/199\n",
            "----------\n",
            "Training loss: 6.174061760306358\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 52.28575339913368\n",
            "Validation accuracy: 0.6122931442080378\n",
            "Epoch 66/199\n",
            "----------\n",
            "Training loss: 6.682639807462692\n",
            "Training accuracy: 0.9964539007092199\n",
            "Validation loss: 52.98463249206543\n",
            "Validation accuracy: 0.5933806146572104\n",
            "Epoch 67/199\n",
            "----------\n",
            "Training loss: 6.709113754332066\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 50.56385210156441\n",
            "Validation accuracy: 0.6264775413711584\n",
            "Epoch 68/199\n",
            "----------\n",
            "Training loss: 6.198418445885181\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 50.61274290084839\n",
            "Validation accuracy: 0.6028368794326241\n",
            "Epoch 69/199\n",
            "----------\n",
            "Training loss: 6.839864179491997\n",
            "Training accuracy: 0.9964539007092199\n",
            "Validation loss: 57.487960159778595\n",
            "Validation accuracy: 0.574468085106383\n",
            "Epoch 70/199\n",
            "----------\n",
            "Training loss: 7.431968316435814\n",
            "Training accuracy: 0.9970449172576832\n",
            "Validation loss: 49.286241590976715\n",
            "Validation accuracy: 0.6288416075650118\n",
            "Epoch 71/199\n",
            "----------\n",
            "Training loss: 7.014521531760693\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 49.98530334234238\n",
            "Validation accuracy: 0.6122931442080378\n",
            "Epoch 72/199\n",
            "----------\n",
            "Training loss: 6.269086427986622\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 52.5900177359581\n",
            "Validation accuracy: 0.607565011820331\n",
            "Epoch 73/199\n",
            "----------\n",
            "Training loss: 6.384236417710781\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 49.19278383255005\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 74/199\n",
            "----------\n",
            "Training loss: 5.821399912238121\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 50.47659873962402\n",
            "Validation accuracy: 0.6052009456264775\n",
            "Epoch 75/199\n",
            "----------\n",
            "Training loss: 6.319448322057724\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 51.08814033865929\n",
            "Validation accuracy: 0.624113475177305\n",
            "Epoch 76/199\n",
            "----------\n",
            "Training loss: 6.168231479823589\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 48.73679241538048\n",
            "Validation accuracy: 0.6099290780141844\n",
            "Epoch 77/199\n",
            "----------\n",
            "Training loss: 6.128036104142666\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 47.715063631534576\n",
            "Validation accuracy: 0.6524822695035462\n",
            "Epoch 78/199\n",
            "----------\n",
            "Training loss: 5.901284962892532\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 54.050157964229584\n",
            "Validation accuracy: 0.607565011820331\n",
            "Epoch 79/199\n",
            "----------\n",
            "Training loss: 6.4719472378492355\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 48.92634844779968\n",
            "Validation accuracy: 0.6193853427895981\n",
            "Epoch 80/199\n",
            "----------\n",
            "Training loss: 6.36565051227808\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 49.92771872878075\n",
            "Validation accuracy: 0.5910165484633569\n",
            "Epoch 81/199\n",
            "----------\n",
            "Training loss: 5.959752894937992\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 49.34108582139015\n",
            "Validation accuracy: 0.6335697399527187\n",
            "Epoch 82/199\n",
            "----------\n",
            "Training loss: 6.1437428295612335\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 50.77786606550217\n",
            "Validation accuracy: 0.6028368794326241\n",
            "Epoch 83/199\n",
            "----------\n",
            "Training loss: 6.372367843985558\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 50.862276911735535\n",
            "Validation accuracy: 0.6170212765957447\n",
            "Epoch 84/199\n",
            "----------\n",
            "Training loss: 6.463562093675137\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 49.55568942427635\n",
            "Validation accuracy: 0.6052009456264775\n",
            "Epoch 85/199\n",
            "----------\n",
            "Training loss: 6.684622555971146\n",
            "Training accuracy: 0.9970449172576832\n",
            "Validation loss: 49.97473269701004\n",
            "Validation accuracy: 0.6004728132387707\n",
            "Epoch 86/199\n",
            "----------\n",
            "Training loss: 6.294904135167599\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 51.42151394486427\n",
            "Validation accuracy: 0.6146572104018913\n",
            "Epoch 87/199\n",
            "----------\n",
            "Training loss: 7.521029785275459\n",
            "Training accuracy: 0.9958628841607565\n",
            "Validation loss: 48.094618648290634\n",
            "Validation accuracy: 0.6359338061465721\n",
            "Epoch 88/199\n",
            "----------\n",
            "Training loss: 6.648466765880585\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 47.54767590761185\n",
            "Validation accuracy: 0.6524822695035462\n",
            "Epoch 89/199\n",
            "----------\n",
            "Training loss: 5.860232427716255\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 47.213698983192444\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 90/199\n",
            "----------\n",
            "Training loss: 6.1501531302928925\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 50.06585934758186\n",
            "Validation accuracy: 0.624113475177305\n",
            "Epoch 91/199\n",
            "----------\n",
            "Training loss: 6.808448940515518\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 49.77008080482483\n",
            "Validation accuracy: 0.6264775413711584\n",
            "Epoch 92/199\n",
            "----------\n",
            "Training loss: 6.589106552302837\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 50.24642172455788\n",
            "Validation accuracy: 0.6193853427895981\n",
            "Epoch 93/199\n",
            "----------\n",
            "Training loss: 6.6439060270786285\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 50.29473829269409\n",
            "Validation accuracy: 0.6052009456264775\n",
            "Epoch 94/199\n",
            "----------\n",
            "Training loss: 6.4584751054644585\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 47.68795391917229\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 95/199\n",
            "----------\n",
            "Training loss: 6.332351095974445\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 48.00894632935524\n",
            "Validation accuracy: 0.6288416075650118\n",
            "Epoch 96/199\n",
            "----------\n",
            "Training loss: 6.641752354800701\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 47.3199068903923\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 97/199\n",
            "----------\n",
            "Training loss: 7.246243201196194\n",
            "Training accuracy: 0.9970449172576832\n",
            "Validation loss: 52.36572176218033\n",
            "Validation accuracy: 0.6052009456264775\n",
            "Epoch 98/199\n",
            "----------\n",
            "Training loss: 7.149974435567856\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 47.214575111866\n",
            "Validation accuracy: 0.6288416075650118\n",
            "Epoch 99/199\n",
            "----------\n",
            "Training loss: 6.858360379934311\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 49.33980306982994\n",
            "Validation accuracy: 0.5933806146572104\n",
            "Epoch 100/199\n",
            "----------\n",
            "Training loss: 7.098285734653473\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 47.609795063734055\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 101/199\n",
            "----------\n",
            "Training loss: 6.703992836177349\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 48.47046026587486\n",
            "Validation accuracy: 0.6170212765957447\n",
            "Epoch 102/199\n",
            "----------\n",
            "Training loss: 6.347733959555626\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 47.102241069078445\n",
            "Validation accuracy: 0.6217494089834515\n",
            "Epoch 103/199\n",
            "----------\n",
            "Training loss: 6.363251067698002\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 47.77285370230675\n",
            "Validation accuracy: 0.6312056737588653\n",
            "Epoch 104/199\n",
            "----------\n",
            "Training loss: 7.164708569645882\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 46.6862750351429\n",
            "Validation accuracy: 0.6312056737588653\n",
            "Epoch 105/199\n",
            "----------\n",
            "Training loss: 6.988222144544125\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 46.192824840545654\n",
            "Validation accuracy: 0.6524822695035462\n",
            "Epoch 106/199\n",
            "----------\n",
            "Training loss: 6.844970785081387\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 47.088616609573364\n",
            "Validation accuracy: 0.6288416075650118\n",
            "Epoch 107/199\n",
            "----------\n",
            "Training loss: 6.547686904668808\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 47.75179371237755\n",
            "Validation accuracy: 0.6264775413711584\n",
            "Epoch 108/199\n",
            "----------\n",
            "Training loss: 7.191187329590321\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 45.46683940291405\n",
            "Validation accuracy: 0.6501182033096927\n",
            "Epoch 109/199\n",
            "----------\n",
            "Training loss: 7.255380101501942\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 51.3491867184639\n",
            "Validation accuracy: 0.5910165484633569\n",
            "Epoch 110/199\n",
            "----------\n",
            "Training loss: 8.335210777819157\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 49.54743841290474\n",
            "Validation accuracy: 0.6146572104018913\n",
            "Epoch 111/199\n",
            "----------\n",
            "Training loss: 7.6788128316402435\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 47.79251477122307\n",
            "Validation accuracy: 0.6335697399527187\n",
            "Epoch 112/199\n",
            "----------\n",
            "Training loss: 7.8158581256866455\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 48.48715981841087\n",
            "Validation accuracy: 0.624113475177305\n",
            "Epoch 113/199\n",
            "----------\n",
            "Training loss: 7.118647634983063\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 46.876482516527176\n",
            "Validation accuracy: 0.6193853427895981\n",
            "Epoch 114/199\n",
            "----------\n",
            "Training loss: 7.069186642765999\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 51.43211609125137\n",
            "Validation accuracy: 0.6004728132387707\n",
            "Epoch 115/199\n",
            "----------\n",
            "Training loss: 8.172444105148315\n",
            "Training accuracy: 0.9958628841607565\n",
            "Validation loss: 53.07917261123657\n",
            "Validation accuracy: 0.5981087470449172\n",
            "Epoch 116/199\n",
            "----------\n",
            "Training loss: 8.556075029075146\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 49.104479253292084\n",
            "Validation accuracy: 0.6288416075650118\n",
            "Epoch 117/199\n",
            "----------\n",
            "Training loss: 7.91288036853075\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 49.96781462430954\n",
            "Validation accuracy: 0.624113475177305\n",
            "Epoch 118/199\n",
            "----------\n",
            "Training loss: 7.66813013702631\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 47.584692031145096\n",
            "Validation accuracy: 0.6288416075650118\n",
            "Epoch 119/199\n",
            "----------\n",
            "Training loss: 7.839224986732006\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 47.1449493765831\n",
            "Validation accuracy: 0.6288416075650118\n",
            "Epoch 120/199\n",
            "----------\n",
            "Training loss: 7.669418267905712\n",
            "Training accuracy: 0.9970449172576832\n",
            "Validation loss: 46.49861028790474\n",
            "Validation accuracy: 0.640661938534279\n",
            "Epoch 121/199\n",
            "----------\n",
            "Training loss: 7.788154527544975\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 48.13179713487625\n",
            "Validation accuracy: 0.6004728132387707\n",
            "Epoch 122/199\n",
            "----------\n",
            "Training loss: 7.41819579154253\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 49.80589097738266\n",
            "Validation accuracy: 0.5839243498817966\n",
            "Epoch 123/199\n",
            "----------\n",
            "Training loss: 8.247232124209404\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 48.33335930109024\n",
            "Validation accuracy: 0.6217494089834515\n",
            "Epoch 124/199\n",
            "----------\n",
            "Training loss: 7.887464910745621\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 46.98106899857521\n",
            "Validation accuracy: 0.6170212765957447\n",
            "Epoch 125/199\n",
            "----------\n",
            "Training loss: 8.381358750164509\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 48.51747727394104\n",
            "Validation accuracy: 0.6099290780141844\n",
            "Epoch 126/199\n",
            "----------\n",
            "Training loss: 8.351435348391533\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 46.94192060828209\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 127/199\n",
            "----------\n",
            "Training loss: 7.9808852300047874\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 47.22534975409508\n",
            "Validation accuracy: 0.6477541371158393\n",
            "Epoch 128/199\n",
            "----------\n",
            "Training loss: 7.935475200414658\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 45.997721672058105\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 129/199\n",
            "----------\n",
            "Training loss: 8.226400919258595\n",
            "Training accuracy: 0.9970449172576832\n",
            "Validation loss: 46.679207265377045\n",
            "Validation accuracy: 0.6453900709219859\n",
            "Epoch 130/199\n",
            "----------\n",
            "Training loss: 8.84906168282032\n",
            "Training accuracy: 0.9964539007092199\n",
            "Validation loss: 46.871296644210815\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 131/199\n",
            "----------\n",
            "Training loss: 8.984567143023014\n",
            "Training accuracy: 0.9970449172576832\n",
            "Validation loss: 49.76132160425186\n",
            "Validation accuracy: 0.624113475177305\n",
            "Epoch 132/199\n",
            "----------\n",
            "Training loss: 9.548464074730873\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 45.739808559417725\n",
            "Validation accuracy: 0.6524822695035462\n",
            "Epoch 133/199\n",
            "----------\n",
            "Training loss: 8.443150728940964\n",
            "Training accuracy: 0.9970449172576832\n",
            "Validation loss: 45.536828964948654\n",
            "Validation accuracy: 0.6501182033096927\n",
            "Epoch 134/199\n",
            "----------\n",
            "Training loss: 9.25236827135086\n",
            "Training accuracy: 0.9964539007092199\n",
            "Validation loss: 47.80447116494179\n",
            "Validation accuracy: 0.6217494089834515\n",
            "Epoch 135/199\n",
            "----------\n",
            "Training loss: 9.0708377212286\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 46.561901926994324\n",
            "Validation accuracy: 0.6430260047281324\n",
            "Epoch 136/199\n",
            "----------\n",
            "Training loss: 8.992464624345303\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 47.258543372154236\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 137/199\n",
            "----------\n",
            "Training loss: 9.02430835366249\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 48.24325102567673\n",
            "Validation accuracy: 0.6170212765957447\n",
            "Epoch 138/199\n",
            "----------\n",
            "Training loss: 8.828852429986\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 46.60489270091057\n",
            "Validation accuracy: 0.6430260047281324\n",
            "Epoch 139/199\n",
            "----------\n",
            "Training loss: 8.744565822184086\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 46.5074026286602\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 140/199\n",
            "----------\n",
            "Training loss: 9.011428833007812\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 45.02520701289177\n",
            "Validation accuracy: 0.6666666666666666\n",
            "Epoch 141/199\n",
            "----------\n",
            "Training loss: 9.125084444880486\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 46.499497443437576\n",
            "Validation accuracy: 0.6359338061465721\n",
            "Epoch 142/199\n",
            "----------\n",
            "Training loss: 9.119312047958374\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 46.96881723403931\n",
            "Validation accuracy: 0.6453900709219859\n",
            "Epoch 143/199\n",
            "----------\n",
            "Training loss: 8.94536392390728\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 46.42969474196434\n",
            "Validation accuracy: 0.6335697399527187\n",
            "Epoch 144/199\n",
            "----------\n",
            "Training loss: 9.280502691864967\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 44.879587173461914\n",
            "Validation accuracy: 0.6572104018912529\n",
            "Epoch 145/199\n",
            "----------\n",
            "Training loss: 9.349486783146858\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 46.400894343853\n",
            "Validation accuracy: 0.640661938534279\n",
            "Epoch 146/199\n",
            "----------\n",
            "Training loss: 9.355856910347939\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 48.378119081258774\n",
            "Validation accuracy: 0.6028368794326241\n",
            "Epoch 147/199\n",
            "----------\n",
            "Training loss: 9.534932881593704\n",
            "Training accuracy: 0.9970449172576832\n",
            "Validation loss: 47.51802682876587\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 148/199\n",
            "----------\n",
            "Training loss: 9.354017585515976\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 45.4719163775444\n",
            "Validation accuracy: 0.6595744680851063\n",
            "Epoch 149/199\n",
            "----------\n",
            "Training loss: 9.621998615562916\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 47.140491276979446\n",
            "Validation accuracy: 0.6217494089834515\n",
            "Epoch 150/199\n",
            "----------\n",
            "Training loss: 10.08463554084301\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 47.20750266313553\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 151/199\n",
            "----------\n",
            "Training loss: 10.765143483877182\n",
            "Training accuracy: 0.9964539007092199\n",
            "Validation loss: 45.443430095911026\n",
            "Validation accuracy: 0.6643026004728132\n",
            "Epoch 152/199\n",
            "----------\n",
            "Training loss: 9.766396164894104\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 45.73200485110283\n",
            "Validation accuracy: 0.640661938534279\n",
            "Epoch 153/199\n",
            "----------\n",
            "Training loss: 10.248323872685432\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 48.5252979695797\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 154/199\n",
            "----------\n",
            "Training loss: 10.204460933804512\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 46.0888047516346\n",
            "Validation accuracy: 0.6359338061465721\n",
            "Epoch 155/199\n",
            "----------\n",
            "Training loss: 10.422601193189621\n",
            "Training accuracy: 0.9970449172576832\n",
            "Validation loss: 46.4546183347702\n",
            "Validation accuracy: 0.6359338061465721\n",
            "Epoch 156/199\n",
            "----------\n",
            "Training loss: 10.926078170537949\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 47.28285330533981\n",
            "Validation accuracy: 0.6099290780141844\n",
            "Epoch 157/199\n",
            "----------\n",
            "Training loss: 10.043936356902122\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 46.16939026117325\n",
            "Validation accuracy: 0.6430260047281324\n",
            "Epoch 158/199\n",
            "----------\n",
            "Training loss: 10.112973004579544\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 45.02366480231285\n",
            "Validation accuracy: 0.6643026004728132\n",
            "Epoch 159/199\n",
            "----------\n",
            "Training loss: 10.55390140414238\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 45.6930730342865\n",
            "Validation accuracy: 0.6595744680851063\n",
            "Epoch 160/199\n",
            "----------\n",
            "Training loss: 10.601271525025368\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 46.93491753935814\n",
            "Validation accuracy: 0.6264775413711584\n",
            "Epoch 161/199\n",
            "----------\n",
            "Training loss: 10.441089853644371\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 46.004480719566345\n",
            "Validation accuracy: 0.6524822695035462\n",
            "Epoch 162/199\n",
            "----------\n",
            "Training loss: 10.436145335435867\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 45.42636349797249\n",
            "Validation accuracy: 0.6761229314420804\n",
            "Epoch 163/199\n",
            "----------\n",
            "Training loss: 10.747939378023148\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 45.648865699768066\n",
            "Validation accuracy: 0.6501182033096927\n",
            "Epoch 164/199\n",
            "----------\n",
            "Training loss: 10.511018097400665\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 46.084485709667206\n",
            "Validation accuracy: 0.6430260047281324\n",
            "Epoch 165/199\n",
            "----------\n",
            "Training loss: 11.230214953422546\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 46.03233045339584\n",
            "Validation accuracy: 0.640661938534279\n",
            "Epoch 166/199\n",
            "----------\n",
            "Training loss: 10.919410437345505\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 48.149532079696655\n",
            "Validation accuracy: 0.6122931442080378\n",
            "Epoch 167/199\n",
            "----------\n",
            "Training loss: 11.568279817700386\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 47.55500864982605\n",
            "Validation accuracy: 0.6193853427895981\n",
            "Epoch 168/199\n",
            "----------\n",
            "Training loss: 10.736871466040611\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 45.9501451253891\n",
            "Validation accuracy: 0.6501182033096927\n",
            "Epoch 169/199\n",
            "----------\n",
            "Training loss: 11.477064713835716\n",
            "Training accuracy: 0.9946808510638298\n",
            "Validation loss: 52.005067855119705\n",
            "Validation accuracy: 0.574468085106383\n",
            "Epoch 170/199\n",
            "----------\n",
            "Training loss: 11.412400215864182\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 48.43651431798935\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 171/199\n",
            "----------\n",
            "Training loss: 11.86650301516056\n",
            "Training accuracy: 0.9964539007092199\n",
            "Validation loss: 48.15419703722\n",
            "Validation accuracy: 0.624113475177305\n",
            "Epoch 172/199\n",
            "----------\n",
            "Training loss: 11.647758170962334\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 46.11830177903175\n",
            "Validation accuracy: 0.6382978723404256\n",
            "Epoch 173/199\n",
            "----------\n",
            "Training loss: 11.407721504569054\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 45.49349954724312\n",
            "Validation accuracy: 0.6690307328605201\n",
            "Epoch 174/199\n",
            "----------\n",
            "Training loss: 11.396889716386795\n",
            "Training accuracy: 1.0\n",
            "Validation loss: 44.68825417757034\n",
            "Validation accuracy: 0.6619385342789598\n",
            "Epoch 175/199\n",
            "----------\n",
            "Training loss: 11.854229256510735\n",
            "Training accuracy: 0.9964539007092199\n",
            "Validation loss: 45.879192531108856\n",
            "Validation accuracy: 0.6501182033096927\n",
            "Epoch 176/199\n",
            "----------\n",
            "Training loss: 11.673604145646095\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 48.07681804895401\n",
            "Validation accuracy: 0.624113475177305\n",
            "Epoch 177/199\n",
            "----------\n",
            "Training loss: 11.060602873563766\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 48.02093333005905\n",
            "Validation accuracy: 0.6477541371158393\n",
            "Epoch 178/199\n",
            "----------\n",
            "Training loss: 11.380024671554565\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 45.88360995054245\n",
            "Validation accuracy: 0.6619385342789598\n",
            "Epoch 179/199\n",
            "----------\n",
            "Training loss: 12.212719440460205\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 44.536706268787384\n",
            "Validation accuracy: 0.6572104018912529\n",
            "Epoch 180/199\n",
            "----------\n",
            "Training loss: 11.191499918699265\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 45.995551347732544\n",
            "Validation accuracy: 0.6477541371158393\n",
            "Epoch 181/199\n",
            "----------\n",
            "Training loss: 11.49531838297844\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 46.70263922214508\n",
            "Validation accuracy: 0.6359338061465721\n",
            "Epoch 182/199\n",
            "----------\n",
            "Training loss: 11.37694202363491\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 44.72935852408409\n",
            "Validation accuracy: 0.6737588652482269\n",
            "Epoch 183/199\n",
            "----------\n",
            "Training loss: 11.278370052576065\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 46.02473205327988\n",
            "Validation accuracy: 0.6453900709219859\n",
            "Epoch 184/199\n",
            "----------\n",
            "Training loss: 12.84393048286438\n",
            "Training accuracy: 0.9964539007092199\n",
            "Validation loss: 44.90875160694122\n",
            "Validation accuracy: 0.6548463356973995\n",
            "Epoch 185/199\n",
            "----------\n",
            "Training loss: 11.765519842505455\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 45.794081926345825\n",
            "Validation accuracy: 0.6477541371158393\n",
            "Epoch 186/199\n",
            "----------\n",
            "Training loss: 11.227344945073128\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 44.760723412036896\n",
            "Validation accuracy: 0.6643026004728132\n",
            "Epoch 187/199\n",
            "----------\n",
            "Training loss: 12.130997747182846\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 45.60364818572998\n",
            "Validation accuracy: 0.6643026004728132\n",
            "Epoch 188/199\n",
            "----------\n",
            "Training loss: 11.587701842188835\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 45.38387790322304\n",
            "Validation accuracy: 0.6501182033096927\n",
            "Epoch 189/199\n",
            "----------\n",
            "Training loss: 11.83407711982727\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 49.74789899587631\n",
            "Validation accuracy: 0.5981087470449172\n",
            "Epoch 190/199\n",
            "----------\n",
            "Training loss: 13.62040539085865\n",
            "Training accuracy: 0.9905437352245863\n",
            "Validation loss: 46.24142950773239\n",
            "Validation accuracy: 0.640661938534279\n",
            "Epoch 191/199\n",
            "----------\n",
            "Training loss: 11.871786415576935\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 46.138053804636\n",
            "Validation accuracy: 0.640661938534279\n",
            "Epoch 192/199\n",
            "----------\n",
            "Training loss: 11.304404214024544\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 45.59165704250336\n",
            "Validation accuracy: 0.6524822695035462\n",
            "Epoch 193/199\n",
            "----------\n",
            "Training loss: 11.66141477227211\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 45.31048172712326\n",
            "Validation accuracy: 0.6713947990543735\n",
            "Epoch 194/199\n",
            "----------\n",
            "Training loss: 11.064806789159775\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 46.9757679104805\n",
            "Validation accuracy: 0.6312056737588653\n",
            "Epoch 195/199\n",
            "----------\n",
            "Training loss: 11.57563641667366\n",
            "Training accuracy: 0.9994089834515366\n",
            "Validation loss: 45.78339001536369\n",
            "Validation accuracy: 0.6572104018912529\n",
            "Epoch 196/199\n",
            "----------\n",
            "Training loss: 11.33141578733921\n",
            "Training accuracy: 0.99822695035461\n",
            "Validation loss: 46.35113310813904\n",
            "Validation accuracy: 0.6501182033096927\n",
            "Epoch 197/199\n",
            "----------\n",
            "Training loss: 11.987960189580917\n",
            "Training accuracy: 0.9976359338061466\n",
            "Validation loss: 45.7522796690464\n",
            "Validation accuracy: 0.6477541371158393\n",
            "Epoch 198/199\n",
            "----------\n",
            "Training loss: 11.420435383915901\n",
            "Training accuracy: 0.9988179669030733\n",
            "Validation loss: 45.86351674795151\n",
            "Validation accuracy: 0.6359338061465721\n",
            "Epoch 199/199\n",
            "----------\n",
            "Training loss: 11.868240520358086\n",
            "Training accuracy: 0.9940898345153665\n",
            "Validation loss: 45.230103462934494\n",
            "Validation accuracy: 0.6548463356973995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp6s4M5HvQe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "6bbb9916-e3b5-4a90-9c08-ade0535c2aa6"
      },
      "source": [
        "# Plotting the training and validation history\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(v_a)\n",
        "plt.plot(range(num_epoch),t_a)\n",
        "plt.plot(range(num_epoch),v_a)\n",
        "plt.title('ShallowConv model accuracy with num_samples = 1000')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(range(num_epoch),t_l)\n",
        "plt.plot(range(num_epoch),v_l)\n",
        "plt.title('ShallowConv model loss with num_samples = 1000')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.34515366430260047, 0.3829787234042553, 0.44208037825059104, 0.47754137115839246, 0.48936170212765956, 0.4988179669030733, 0.5295508274231678, 0.5295508274231678, 0.5200945626477541, 0.5531914893617021, 0.5460992907801419, 0.5602836879432624, 0.5602836879432624, 0.5673758865248227, 0.5626477541371159, 0.5791962174940898, 0.5815602836879432, 0.5626477541371159, 0.5673758865248227, 0.5910165484633569, 0.5886524822695035, 0.5721040189125296, 0.5886524822695035, 0.5957446808510638, 0.5910165484633569, 0.574468085106383, 0.6193853427895981, 0.6004728132387707, 0.624113475177305, 0.6099290780141844, 0.5957446808510638, 0.5910165484633569, 0.6028368794326241, 0.5981087470449172, 0.5981087470449172, 0.6004728132387707, 0.5957446808510638, 0.6099290780141844, 0.6052009456264775, 0.6028368794326241, 0.5886524822695035, 0.6146572104018913, 0.6359338061465721, 0.607565011820331, 0.6264775413711584, 0.6099290780141844, 0.5460992907801419, 0.6122931442080378, 0.6052009456264775, 0.5791962174940898, 0.6099290780141844, 0.6052009456264775, 0.607565011820331, 0.6193853427895981, 0.6193853427895981, 0.6146572104018913, 0.6193853427895981, 0.6170212765957447, 0.5957446808510638, 0.6217494089834515, 0.6146572104018913, 0.6122931442080378, 0.6193853427895981, 0.6170212765957447, 0.5839243498817966, 0.6122931442080378, 0.5933806146572104, 0.6264775413711584, 0.6028368794326241, 0.574468085106383, 0.6288416075650118, 0.6122931442080378, 0.607565011820331, 0.6382978723404256, 0.6052009456264775, 0.624113475177305, 0.6099290780141844, 0.6524822695035462, 0.607565011820331, 0.6193853427895981, 0.5910165484633569, 0.6335697399527187, 0.6028368794326241, 0.6170212765957447, 0.6052009456264775, 0.6004728132387707, 0.6146572104018913, 0.6359338061465721, 0.6524822695035462, 0.6382978723404256, 0.624113475177305, 0.6264775413711584, 0.6193853427895981, 0.6052009456264775, 0.6382978723404256, 0.6288416075650118, 0.6382978723404256, 0.6052009456264775, 0.6288416075650118, 0.5933806146572104, 0.6382978723404256, 0.6170212765957447, 0.6217494089834515, 0.6312056737588653, 0.6312056737588653, 0.6524822695035462, 0.6288416075650118, 0.6264775413711584, 0.6501182033096927, 0.5910165484633569, 0.6146572104018913, 0.6335697399527187, 0.624113475177305, 0.6193853427895981, 0.6004728132387707, 0.5981087470449172, 0.6288416075650118, 0.624113475177305, 0.6288416075650118, 0.6288416075650118, 0.640661938534279, 0.6004728132387707, 0.5839243498817966, 0.6217494089834515, 0.6170212765957447, 0.6099290780141844, 0.6382978723404256, 0.6477541371158393, 0.6382978723404256, 0.6453900709219859, 0.6382978723404256, 0.624113475177305, 0.6524822695035462, 0.6501182033096927, 0.6217494089834515, 0.6430260047281324, 0.6382978723404256, 0.6170212765957447, 0.6430260047281324, 0.6382978723404256, 0.6666666666666666, 0.6359338061465721, 0.6453900709219859, 0.6335697399527187, 0.6572104018912529, 0.640661938534279, 0.6028368794326241, 0.6382978723404256, 0.6595744680851063, 0.6217494089834515, 0.6382978723404256, 0.6643026004728132, 0.640661938534279, 0.6382978723404256, 0.6359338061465721, 0.6359338061465721, 0.6099290780141844, 0.6430260047281324, 0.6643026004728132, 0.6595744680851063, 0.6264775413711584, 0.6524822695035462, 0.6761229314420804, 0.6501182033096927, 0.6430260047281324, 0.640661938534279, 0.6122931442080378, 0.6193853427895981, 0.6501182033096927, 0.574468085106383, 0.6382978723404256, 0.624113475177305, 0.6382978723404256, 0.6690307328605201, 0.6619385342789598, 0.6501182033096927, 0.624113475177305, 0.6477541371158393, 0.6619385342789598, 0.6572104018912529, 0.6477541371158393, 0.6359338061465721, 0.6737588652482269, 0.6453900709219859, 0.6548463356973995, 0.6477541371158393, 0.6643026004728132, 0.6643026004728132, 0.6501182033096927, 0.5981087470449172, 0.640661938534279, 0.640661938534279, 0.6524822695035462, 0.6713947990543735, 0.6312056737588653, 0.6572104018912529, 0.6501182033096927, 0.6477541371158393, 0.6359338061465721, 0.6548463356973995]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_ALZdwevQe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63c41715-261c-4327-fe5f-024369cf223c"
      },
      "source": [
        "# Testing the model\n",
        "\n",
        "num_samples_frame = 1000\n",
        "stride = 50\n",
        "X_test_win,y_test_win = make_win_data_pipeline(X_test,y_test,num_samples_frame,stride)\n",
        "\n",
        "# Preparing the test dataset\n",
        "X_test_tensor = torch.from_numpy(X_test_win).float().to(device)\n",
        "y_test_tensor = torch.from_numpy(y_test_win).float().long().to(device) \n",
        "    \n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor) \n",
        "    \n",
        "test_data = EEGDataset(test_dataset, transform=None)\n",
        "\n",
        "\n",
        "\n",
        "def test_model(model,test_data,criterion):\n",
        "    \n",
        "    \n",
        "    # Creating the test dataloader\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=True, num_workers=0)\n",
        "    \n",
        "    # Making the predictions on the dataset\n",
        "    \n",
        "    total_test_preds = 0\n",
        "    correct_test_preds = 0\n",
        "    test_loss = 0\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        for test_inputs, test_labels in test_dataloader:\n",
        "            \n",
        "            # Transfer test data and labels to device\n",
        "            test_inputs = test_inputs.to(device)\n",
        "            test_labels = test_labels.to(device)\n",
        "            \n",
        "            # Perform forward pass\n",
        "            test_outputs = model(test_inputs)\n",
        "            \n",
        "            # Compute loss\n",
        "            test_loss = criterion(test_outputs,test_labels)\n",
        "            \n",
        "            # Compute test statistics\n",
        "                    \n",
        "            test_loss += test_loss.item()\n",
        "            _, test_predicted = test_outputs.max(1)\n",
        "            total_test_preds += test_labels.size(0)\n",
        "            correct_test_preds += test_predicted.eq(test_labels).sum().item()\n",
        "            \n",
        "        test_acc = correct_test_preds/total_test_preds\n",
        "        print('Test loss', test_loss)\n",
        "        print('Test accuracy',test_acc*100)\n",
        "        \n",
        "    \n",
        "    return test_acc\n",
        "\n",
        "test_a = test_model(shallow_model,test_data,criterion)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss tensor(1.1953, device='cuda:0')\n",
            "Test accuracy 65.23702031602708\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISWD8GBEvQe1"
      },
      "source": [
        "## Training,validating and testing the model with 500 samples per trial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZXzAPWOvQe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea543e5-1181-4931-c67b-f05ee7276d70"
      },
      "source": [
        "## Preparing the training and validation data\n",
        "\n",
        "num_samples_frame = 500\n",
        "stride = 100\n",
        "X_train_win,y_train_win = make_win_data_pipeline(X_train_valid,y_train_valid,num_samples_frame,stride)\n",
        "\n",
        "print ('Windowed Training/Valid data shape: {}'.format(X_train_win.shape))\n",
        "print ('Windowed Training/Valid label shape: {}'.format(y_train_win.shape))\n",
        "\n",
        "# Converting the numpy data to torch tensors\n",
        "\n",
        "X_train_valid_tensor = torch.from_numpy(X_train_win).float().to(device)\n",
        "y_train_valid_tensor = torch.from_numpy(y_train_win).float().long().to(device) \n",
        "\n",
        "print ('Training/Valid tensor shape: {}'.format(X_train_valid_tensor.shape))\n",
        "print ('Training/Valid target tensor shape: {}'.format(y_train_valid_tensor.shape))\n",
        "\n",
        "init_dataset = TensorDataset(X_train_valid_tensor, y_train_valid_tensor) \n",
        "\n",
        "# Spliting the dataset into training and validation\n",
        "\n",
        "lengths = [int(len(init_dataset)*0.8), int(len(init_dataset)*0.2)] \n",
        "subset_train, subset_val = random_split(init_dataset, lengths) \n",
        "\n",
        "train_data = EEGDataset(subset_train, transform=None)\n",
        "val_data = EEGDataset(subset_val, transform=None)\n",
        "\n",
        "# Constructing the training and validation dataloaders\n",
        "\n",
        "dataloaders = {\n",
        "    'train': torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=0),\n",
        "    'val': torch.utils.data.DataLoader(val_data, batch_size=8, shuffle=False, num_workers=0)\n",
        "}\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Windowed Training/Valid data shape: (12690, 22, 500)\n",
            "Windowed Training/Valid label shape: (12690,)\n",
            "Training/Valid tensor shape: torch.Size([12690, 22, 500])\n",
            "Training/Valid target tensor shape: torch.Size([12690])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcABGsq_vQe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe20d80-5c73-4b8f-9117-e413173ba6db"
      },
      "source": [
        "# Defining the parameters for model training\n",
        "\n",
        "\n",
        "weight_decay = 0.15  # weight decay to alleviate overfiting\n",
        "shallow_model = ShallowConv(in_channels=1, num_conv_filters=40,num_samples_frame=500,num_eeg_channels=22,classes=4).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(shallow_model.parameters(), lr = 1e-5, weight_decay=weight_decay)\n",
        "\n",
        "# Training and validating the model\n",
        "epoch=600\n",
        "shallow_model,t_l,t_a,v_l,v_a=train_val(shallow_model, optimizer, criterion, num_epochs=epoch)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/599\n",
            "----------\n",
            "Training loss: 460.23816537857056\n",
            "Training accuracy: 0.25541765169424746\n",
            "Validation loss: 447.3215956687927\n",
            "Validation accuracy: 0.2777777777777778\n",
            "Epoch 1/599\n",
            "----------\n",
            "Training loss: 442.6060811281204\n",
            "Training accuracy: 0.2903861308116627\n",
            "Validation loss: 439.56864976882935\n",
            "Validation accuracy: 0.2970843183609141\n",
            "Epoch 2/599\n",
            "----------\n",
            "Training loss: 436.1013534069061\n",
            "Training accuracy: 0.3108747044917258\n",
            "Validation loss: 435.7006849050522\n",
            "Validation accuracy: 0.3073286052009456\n",
            "Epoch 3/599\n",
            "----------\n",
            "Training loss: 430.8013323545456\n",
            "Training accuracy: 0.32436958234830576\n",
            "Validation loss: 432.5277290344238\n",
            "Validation accuracy: 0.3195429472025217\n",
            "Epoch 4/599\n",
            "----------\n",
            "Training loss: 426.7705924510956\n",
            "Training accuracy: 0.34505516154452326\n",
            "Validation loss: 427.9044598340988\n",
            "Validation accuracy: 0.32978723404255317\n",
            "Epoch 5/599\n",
            "----------\n",
            "Training loss: 422.0230587720871\n",
            "Training accuracy: 0.35726950354609927\n",
            "Validation loss: 425.3234312534332\n",
            "Validation accuracy: 0.34948778565799843\n",
            "Epoch 6/599\n",
            "----------\n",
            "Training loss: 417.9340845346451\n",
            "Training accuracy: 0.3757880220646178\n",
            "Validation loss: 421.337522983551\n",
            "Validation accuracy: 0.3605200945626478\n",
            "Epoch 7/599\n",
            "----------\n",
            "Training loss: 413.66213834285736\n",
            "Training accuracy: 0.3900709219858156\n",
            "Validation loss: 417.0667868256569\n",
            "Validation accuracy: 0.3731284475965327\n",
            "Epoch 8/599\n",
            "----------\n",
            "Training loss: 408.7838679552078\n",
            "Training accuracy: 0.40622537431048067\n",
            "Validation loss: 413.58845871686935\n",
            "Validation accuracy: 0.3908589440504334\n",
            "Epoch 9/599\n",
            "----------\n",
            "Training loss: 404.3647001981735\n",
            "Training accuracy: 0.4198187549251379\n",
            "Validation loss: 410.056099653244\n",
            "Validation accuracy: 0.3979511426319937\n",
            "Epoch 10/599\n",
            "----------\n",
            "Training loss: 399.7733105421066\n",
            "Training accuracy: 0.43351063829787234\n",
            "Validation loss: 407.3915354013443\n",
            "Validation accuracy: 0.40583136327817176\n",
            "Epoch 11/599\n",
            "----------\n",
            "Training loss: 395.4553383588791\n",
            "Training accuracy: 0.4435579196217494\n",
            "Validation loss: 404.39014399051666\n",
            "Validation accuracy: 0.4176516942474389\n",
            "Epoch 12/599\n",
            "----------\n",
            "Training loss: 391.33951622247696\n",
            "Training accuracy: 0.453408195429472\n",
            "Validation loss: 399.5141275525093\n",
            "Validation accuracy: 0.42710795902285265\n",
            "Epoch 13/599\n",
            "----------\n",
            "Training loss: 387.6207718849182\n",
            "Training accuracy: 0.4645390070921986\n",
            "Validation loss: 395.7346165776253\n",
            "Validation accuracy: 0.43656422379826637\n",
            "Epoch 14/599\n",
            "----------\n",
            "Training loss: 382.5689806342125\n",
            "Training accuracy: 0.46926713947990545\n",
            "Validation loss: 392.9282857179642\n",
            "Validation accuracy: 0.44759653270291566\n",
            "Epoch 15/599\n",
            "----------\n",
            "Training loss: 379.05880856513977\n",
            "Training accuracy: 0.48177698975571315\n",
            "Validation loss: 391.45641016960144\n",
            "Validation accuracy: 0.44720252167060676\n",
            "Epoch 16/599\n",
            "----------\n",
            "Training loss: 376.5539864897728\n",
            "Training accuracy: 0.4862096138691883\n",
            "Validation loss: 387.4255669116974\n",
            "Validation accuracy: 0.45547675334909377\n",
            "Epoch 17/599\n",
            "----------\n",
            "Training loss: 372.2606154680252\n",
            "Training accuracy: 0.49714342001576045\n",
            "Validation loss: 384.2008667588234\n",
            "Validation accuracy: 0.4657210401891253\n",
            "Epoch 18/599\n",
            "----------\n",
            "Training loss: 367.7275148630142\n",
            "Training accuracy: 0.5053191489361702\n",
            "Validation loss: 382.90083760023117\n",
            "Validation accuracy: 0.4672970843183609\n",
            "Epoch 19/599\n",
            "----------\n",
            "Training loss: 364.39480197429657\n",
            "Training accuracy: 0.5106382978723404\n",
            "Validation loss: 379.6443382501602\n",
            "Validation accuracy: 0.4661150512214342\n",
            "Epoch 20/599\n",
            "----------\n",
            "Training loss: 361.6750262975693\n",
            "Training accuracy: 0.5132978723404256\n",
            "Validation loss: 376.62841469049454\n",
            "Validation accuracy: 0.47675334909377465\n",
            "Epoch 21/599\n",
            "----------\n",
            "Training loss: 358.77482640743256\n",
            "Training accuracy: 0.5235421591804571\n",
            "Validation loss: 374.45860600471497\n",
            "Validation accuracy: 0.4799054373522459\n",
            "Epoch 22/599\n",
            "----------\n",
            "Training loss: 353.6470279097557\n",
            "Training accuracy: 0.531816390858944\n",
            "Validation loss: 371.9037839770317\n",
            "Validation accuracy: 0.48187549251379036\n",
            "Epoch 23/599\n",
            "----------\n",
            "Training loss: 352.33969163894653\n",
            "Training accuracy: 0.5364460204885737\n",
            "Validation loss: 370.70037269592285\n",
            "Validation accuracy: 0.4842395587076438\n",
            "Epoch 24/599\n",
            "----------\n",
            "Training loss: 349.6815205216408\n",
            "Training accuracy: 0.5371355397951143\n",
            "Validation loss: 371.56953316926956\n",
            "Validation accuracy: 0.48266351457840817\n",
            "Epoch 25/599\n",
            "----------\n",
            "Training loss: 345.8089118003845\n",
            "Training accuracy: 0.5459022852639874\n",
            "Validation loss: 365.54740113019943\n",
            "Validation accuracy: 0.49724192277383766\n",
            "Epoch 26/599\n",
            "----------\n",
            "Training loss: 343.274078309536\n",
            "Training accuracy: 0.5517139479905437\n",
            "Validation loss: 364.19646513462067\n",
            "Validation accuracy: 0.49684791174152876\n",
            "Epoch 27/599\n",
            "----------\n",
            "Training loss: 341.23366367816925\n",
            "Training accuracy: 0.5541765169424744\n",
            "Validation loss: 363.8582406640053\n",
            "Validation accuracy: 0.5015760441292356\n",
            "Epoch 28/599\n",
            "----------\n",
            "Training loss: 338.2600471377373\n",
            "Training accuracy: 0.5569345941686368\n",
            "Validation loss: 361.2368564605713\n",
            "Validation accuracy: 0.5031520882584712\n",
            "Epoch 29/599\n",
            "----------\n",
            "Training loss: 336.7403242588043\n",
            "Training accuracy: 0.5624507486209613\n",
            "Validation loss: 359.6367690563202\n",
            "Validation accuracy: 0.49724192277383766\n",
            "Epoch 30/599\n",
            "----------\n",
            "Training loss: 334.83329677581787\n",
            "Training accuracy: 0.5632387706855791\n",
            "Validation loss: 357.0316652059555\n",
            "Validation accuracy: 0.5043341213553979\n",
            "Epoch 31/599\n",
            "----------\n",
            "Training loss: 330.4601401090622\n",
            "Training accuracy: 0.5724980299448384\n",
            "Validation loss: 354.9600509405136\n",
            "Validation accuracy: 0.5070921985815603\n",
            "Epoch 32/599\n",
            "----------\n",
            "Training loss: 328.3503621816635\n",
            "Training accuracy: 0.5780141843971631\n",
            "Validation loss: 353.4191384911537\n",
            "Validation accuracy: 0.5090622537431048\n",
            "Epoch 33/599\n",
            "----------\n",
            "Training loss: 326.8957740664482\n",
            "Training accuracy: 0.5789992119779354\n",
            "Validation loss: 352.5451709628105\n",
            "Validation accuracy: 0.5169424743892829\n",
            "Epoch 34/599\n",
            "----------\n",
            "Training loss: 323.7572942376137\n",
            "Training accuracy: 0.5898345153664303\n",
            "Validation loss: 350.88146686553955\n",
            "Validation accuracy: 0.5197005516154453\n",
            "Epoch 35/599\n",
            "----------\n",
            "Training loss: 322.30706638097763\n",
            "Training accuracy: 0.5886524822695035\n",
            "Validation loss: 348.76273143291473\n",
            "Validation accuracy: 0.5149724192277384\n",
            "Epoch 36/599\n",
            "----------\n",
            "Training loss: 320.40976744890213\n",
            "Training accuracy: 0.5891449960598897\n",
            "Validation loss: 347.6792470216751\n",
            "Validation accuracy: 0.5240346729708432\n",
            "Epoch 37/599\n",
            "----------\n",
            "Training loss: 318.2477573752403\n",
            "Training accuracy: 0.5942671394799054\n",
            "Validation loss: 345.20285081863403\n",
            "Validation accuracy: 0.5224586288416075\n",
            "Epoch 38/599\n",
            "----------\n",
            "Training loss: 315.25286334753036\n",
            "Training accuracy: 0.5985027580772262\n",
            "Validation loss: 344.2030384540558\n",
            "Validation accuracy: 0.5240346729708432\n",
            "Epoch 39/599\n",
            "----------\n",
            "Training loss: 312.8426864743233\n",
            "Training accuracy: 0.6085500394011032\n",
            "Validation loss: 342.09488838911057\n",
            "Validation accuracy: 0.5437352245862884\n",
            "Epoch 40/599\n",
            "----------\n",
            "Training loss: 310.16624623537064\n",
            "Training accuracy: 0.609338061465721\n",
            "Validation loss: 344.3412572145462\n",
            "Validation accuracy: 0.5370370370370371\n",
            "Epoch 41/599\n",
            "----------\n",
            "Training loss: 308.3782367706299\n",
            "Training accuracy: 0.6196808510638298\n",
            "Validation loss: 338.0063211917877\n",
            "Validation accuracy: 0.5350669818754925\n",
            "Epoch 42/599\n",
            "----------\n",
            "Training loss: 306.89892530441284\n",
            "Training accuracy: 0.6180063041765169\n",
            "Validation loss: 338.2888622879982\n",
            "Validation accuracy: 0.5386130811662726\n",
            "Epoch 43/599\n",
            "----------\n",
            "Training loss: 305.6093689799309\n",
            "Training accuracy: 0.6187943262411347\n",
            "Validation loss: 336.66954731941223\n",
            "Validation accuracy: 0.5472813238770685\n",
            "Epoch 44/599\n",
            "----------\n",
            "Training loss: 302.4541350007057\n",
            "Training accuracy: 0.6225374310480694\n",
            "Validation loss: 335.44203799963\n",
            "Validation accuracy: 0.5445232466509062\n",
            "Epoch 45/599\n",
            "----------\n",
            "Training loss: 300.4914122223854\n",
            "Training accuracy: 0.6305161544523247\n",
            "Validation loss: 333.27388125658035\n",
            "Validation accuracy: 0.55397951142632\n",
            "Epoch 46/599\n",
            "----------\n",
            "Training loss: 298.2064363360405\n",
            "Training accuracy: 0.6339637509850276\n",
            "Validation loss: 331.47666120529175\n",
            "Validation accuracy: 0.5480693459416863\n",
            "Epoch 47/599\n",
            "----------\n",
            "Training loss: 296.39055663347244\n",
            "Training accuracy: 0.6427304964539007\n",
            "Validation loss: 332.10831385850906\n",
            "Validation accuracy: 0.5614657210401891\n",
            "Epoch 48/599\n",
            "----------\n",
            "Training loss: 295.5680853128433\n",
            "Training accuracy: 0.6385933806146572\n",
            "Validation loss: 328.68009555339813\n",
            "Validation accuracy: 0.5575256107171\n",
            "Epoch 49/599\n",
            "----------\n",
            "Training loss: 292.9548820257187\n",
            "Training accuracy: 0.6428289992119779\n",
            "Validation loss: 327.0611338019371\n",
            "Validation accuracy: 0.5563435776201734\n",
            "Epoch 50/599\n",
            "----------\n",
            "Training loss: 290.9804040789604\n",
            "Training accuracy: 0.6469661150512215\n",
            "Validation loss: 326.73506420850754\n",
            "Validation accuracy: 0.5654058313632782\n",
            "Epoch 51/599\n",
            "----------\n",
            "Training loss: 289.37093383073807\n",
            "Training accuracy: 0.6496256895193065\n",
            "Validation loss: 326.3700124025345\n",
            "Validation accuracy: 0.5634357762017337\n",
            "Epoch 52/599\n",
            "----------\n",
            "Training loss: 287.2236410975456\n",
            "Training accuracy: 0.6562253743104807\n",
            "Validation loss: 325.9037601649761\n",
            "Validation accuracy: 0.5650118203309693\n",
            "Epoch 53/599\n",
            "----------\n",
            "Training loss: 285.63981425762177\n",
            "Training accuracy: 0.6535657998423956\n",
            "Validation loss: 321.74612921476364\n",
            "Validation accuracy: 0.5689519306540584\n",
            "Epoch 54/599\n",
            "----------\n",
            "Training loss: 284.0174608826637\n",
            "Training accuracy: 0.6578999211977935\n",
            "Validation loss: 324.30602982640266\n",
            "Validation accuracy: 0.5732860520094563\n",
            "Epoch 55/599\n",
            "----------\n",
            "Training loss: 281.7948659658432\n",
            "Training accuracy: 0.6620370370370371\n",
            "Validation loss: 319.73381838202477\n",
            "Validation accuracy: 0.5697399527186762\n",
            "Epoch 56/599\n",
            "----------\n",
            "Training loss: 280.61492395401\n",
            "Training accuracy: 0.6667651694247438\n",
            "Validation loss: 319.5457667708397\n",
            "Validation accuracy: 0.5646178092986603\n",
            "Epoch 57/599\n",
            "----------\n",
            "Training loss: 278.3396044373512\n",
            "Training accuracy: 0.6693262411347518\n",
            "Validation loss: 316.59098732471466\n",
            "Validation accuracy: 0.5811662726556344\n",
            "Epoch 58/599\n",
            "----------\n",
            "Training loss: 276.2040464282036\n",
            "Training accuracy: 0.6689322301024428\n",
            "Validation loss: 314.6418868601322\n",
            "Validation accuracy: 0.5819542947202522\n",
            "Epoch 59/599\n",
            "----------\n",
            "Training loss: 275.5370072722435\n",
            "Training accuracy: 0.6752364066193853\n",
            "Validation loss: 317.49249160289764\n",
            "Validation accuracy: 0.582348305752561\n",
            "Epoch 60/599\n",
            "----------\n",
            "Training loss: 273.0904942750931\n",
            "Training accuracy: 0.6786840031520882\n",
            "Validation loss: 314.12605652213097\n",
            "Validation accuracy: 0.5788022064617809\n",
            "Epoch 61/599\n",
            "----------\n",
            "Training loss: 271.2072983980179\n",
            "Training accuracy: 0.679472025216706\n",
            "Validation loss: 310.8808055818081\n",
            "Validation accuracy: 0.5973207249802994\n",
            "Epoch 62/599\n",
            "----------\n",
            "Training loss: 269.11798840761185\n",
            "Training accuracy: 0.6851851851851852\n",
            "Validation loss: 313.9685610830784\n",
            "Validation accuracy: 0.586682427107959\n",
            "Epoch 63/599\n",
            "----------\n",
            "Training loss: 266.5858789086342\n",
            "Training accuracy: 0.6903073286052009\n",
            "Validation loss: 311.90294831991196\n",
            "Validation accuracy: 0.5921985815602837\n",
            "Epoch 64/599\n",
            "----------\n",
            "Training loss: 265.1020103096962\n",
            "Training accuracy: 0.6939519306540584\n",
            "Validation loss: 313.2593881189823\n",
            "Validation accuracy: 0.5795902285263987\n",
            "Epoch 65/599\n",
            "----------\n",
            "Training loss: 264.168721139431\n",
            "Training accuracy: 0.6914893617021277\n",
            "Validation loss: 307.70997431874275\n",
            "Validation accuracy: 0.594956658786446\n",
            "Epoch 66/599\n",
            "----------\n",
            "Training loss: 262.17838591337204\n",
            "Training accuracy: 0.692966903073286\n",
            "Validation loss: 306.4515954852104\n",
            "Validation accuracy: 0.5957446808510638\n",
            "Epoch 67/599\n",
            "----------\n",
            "Training loss: 260.50025820732117\n",
            "Training accuracy: 0.7013396375098503\n",
            "Validation loss: 303.4096637070179\n",
            "Validation accuracy: 0.5981087470449172\n",
            "Epoch 68/599\n",
            "----------\n",
            "Training loss: 258.39583683013916\n",
            "Training accuracy: 0.705575256107171\n",
            "Validation loss: 303.2878120839596\n",
            "Validation accuracy: 0.5981087470449172\n",
            "Epoch 69/599\n",
            "----------\n",
            "Training loss: 256.7650188803673\n",
            "Training accuracy: 0.7074468085106383\n",
            "Validation loss: 301.25028735399246\n",
            "Validation accuracy: 0.5973207249802994\n",
            "Epoch 70/599\n",
            "----------\n",
            "Training loss: 254.58657324314117\n",
            "Training accuracy: 0.7133569739952719\n",
            "Validation loss: 300.30723586678505\n",
            "Validation accuracy: 0.598896769109535\n",
            "Epoch 71/599\n",
            "----------\n",
            "Training loss: 253.43641597032547\n",
            "Training accuracy: 0.7146375098502759\n",
            "Validation loss: 296.7392867207527\n",
            "Validation accuracy: 0.6103230890464934\n",
            "Epoch 72/599\n",
            "----------\n",
            "Training loss: 251.7189737856388\n",
            "Training accuracy: 0.7114854215918046\n",
            "Validation loss: 298.9104677438736\n",
            "Validation accuracy: 0.6083530338849488\n",
            "Epoch 73/599\n",
            "----------\n",
            "Training loss: 250.35435736179352\n",
            "Training accuracy: 0.7189716312056738\n",
            "Validation loss: 296.6923069059849\n",
            "Validation accuracy: 0.6055949566587865\n",
            "Epoch 74/599\n",
            "----------\n",
            "Training loss: 247.85704469680786\n",
            "Training accuracy: 0.7264578408195429\n",
            "Validation loss: 295.861241966486\n",
            "Validation accuracy: 0.611899133175729\n",
            "Epoch 75/599\n",
            "----------\n",
            "Training loss: 247.6554458141327\n",
            "Training accuracy: 0.7224192277383766\n",
            "Validation loss: 294.3218569457531\n",
            "Validation accuracy: 0.6154452324665091\n",
            "Epoch 76/599\n",
            "----------\n",
            "Training loss: 244.91265830397606\n",
            "Training accuracy: 0.7226162332545312\n",
            "Validation loss: 292.787696570158\n",
            "Validation accuracy: 0.6154452324665091\n",
            "Epoch 77/599\n",
            "----------\n",
            "Training loss: 244.20664280653\n",
            "Training accuracy: 0.7274428684003152\n",
            "Validation loss: 294.0966936349869\n",
            "Validation accuracy: 0.6103230890464934\n",
            "Epoch 78/599\n",
            "----------\n",
            "Training loss: 241.65512537956238\n",
            "Training accuracy: 0.7339440504334122\n",
            "Validation loss: 291.69708573818207\n",
            "Validation accuracy: 0.6170212765957447\n",
            "Epoch 79/599\n",
            "----------\n",
            "Training loss: 239.54856979846954\n",
            "Training accuracy: 0.7329590228526399\n",
            "Validation loss: 295.51278364658356\n",
            "Validation accuracy: 0.6142631993695824\n",
            "Epoch 80/599\n",
            "----------\n",
            "Training loss: 238.96816354990005\n",
            "Training accuracy: 0.734338061465721\n",
            "Validation loss: 287.65241768956184\n",
            "Validation accuracy: 0.6339637509850276\n",
            "Epoch 81/599\n",
            "----------\n",
            "Training loss: 236.55102509260178\n",
            "Training accuracy: 0.7370961386918834\n",
            "Validation loss: 286.54876816272736\n",
            "Validation accuracy: 0.6225374310480694\n",
            "Epoch 82/599\n",
            "----------\n",
            "Training loss: 234.88146007061005\n",
            "Training accuracy: 0.7467494089834515\n",
            "Validation loss: 284.5796027779579\n",
            "Validation accuracy: 0.6315996847911741\n",
            "Epoch 83/599\n",
            "----------\n",
            "Training loss: 233.36613512039185\n",
            "Training accuracy: 0.7465524034672971\n",
            "Validation loss: 286.56529292464256\n",
            "Validation accuracy: 0.6335697399527187\n",
            "Epoch 84/599\n",
            "----------\n",
            "Training loss: 233.16217827796936\n",
            "Training accuracy: 0.7458628841607565\n",
            "Validation loss: 283.2672167122364\n",
            "Validation accuracy: 0.636327817178881\n",
            "Epoch 85/599\n",
            "----------\n",
            "Training loss: 230.8014082312584\n",
            "Training accuracy: 0.7492119779353822\n",
            "Validation loss: 280.53121027350426\n",
            "Validation accuracy: 0.6410559495665878\n",
            "Epoch 86/599\n",
            "----------\n",
            "Training loss: 228.36120438575745\n",
            "Training accuracy: 0.7586682427107959\n",
            "Validation loss: 276.9782132804394\n",
            "Validation accuracy: 0.6497241922773838\n",
            "Epoch 87/599\n",
            "----------\n",
            "Training loss: 228.12970674037933\n",
            "Training accuracy: 0.753053585500394\n",
            "Validation loss: 291.4385161995888\n",
            "Validation accuracy: 0.6146572104018913\n",
            "Epoch 88/599\n",
            "----------\n",
            "Training loss: 225.83902406692505\n",
            "Training accuracy: 0.7637903861308116\n",
            "Validation loss: 278.4549988210201\n",
            "Validation accuracy: 0.6449960598896769\n",
            "Epoch 89/599\n",
            "----------\n",
            "Training loss: 224.96283981204033\n",
            "Training accuracy: 0.7602442868400315\n",
            "Validation loss: 277.50358587503433\n",
            "Validation accuracy: 0.644602048857368\n",
            "Epoch 90/599\n",
            "----------\n",
            "Training loss: 223.66465586423874\n",
            "Training accuracy: 0.7644799054373522\n",
            "Validation loss: 274.9415321946144\n",
            "Validation accuracy: 0.6442080378250591\n",
            "Epoch 91/599\n",
            "----------\n",
            "Training loss: 221.37001904845238\n",
            "Training accuracy: 0.7688140267927502\n",
            "Validation loss: 272.72523790597916\n",
            "Validation accuracy: 0.6544523246650906\n",
            "Epoch 92/599\n",
            "----------\n",
            "Training loss: 220.67457407712936\n",
            "Training accuracy: 0.7661544523246651\n",
            "Validation loss: 270.9385828077793\n",
            "Validation accuracy: 0.6619385342789598\n",
            "Epoch 93/599\n",
            "----------\n",
            "Training loss: 217.98254320025444\n",
            "Training accuracy: 0.7743301812450749\n",
            "Validation loss: 269.05055832862854\n",
            "Validation accuracy: 0.6576044129235619\n",
            "Epoch 94/599\n",
            "----------\n",
            "Training loss: 218.31082379817963\n",
            "Training accuracy: 0.7724586288416075\n",
            "Validation loss: 270.2385705113411\n",
            "Validation accuracy: 0.6623325453112687\n",
            "Epoch 95/599\n",
            "----------\n",
            "Training loss: 215.91049420833588\n",
            "Training accuracy: 0.7770882584712372\n",
            "Validation loss: 270.0785049498081\n",
            "Validation accuracy: 0.6599684791174153\n",
            "Epoch 96/599\n",
            "----------\n",
            "Training loss: 215.5382199883461\n",
            "Training accuracy: 0.7797478329393223\n",
            "Validation loss: 268.6167775988579\n",
            "Validation accuracy: 0.6607565011820331\n",
            "Epoch 97/599\n",
            "----------\n",
            "Training loss: 212.73417869210243\n",
            "Training accuracy: 0.7806343577620173\n",
            "Validation loss: 268.55527341365814\n",
            "Validation accuracy: 0.6674546887312844\n",
            "Epoch 98/599\n",
            "----------\n",
            "Training loss: 211.6304971575737\n",
            "Training accuracy: 0.7879235618597321\n",
            "Validation loss: 266.94740173220634\n",
            "Validation accuracy: 0.6670606776989756\n",
            "Epoch 99/599\n",
            "----------\n",
            "Training loss: 209.56877732276917\n",
            "Training accuracy: 0.7878250591016549\n",
            "Validation loss: 263.78811982274055\n",
            "Validation accuracy: 0.6662726556343578\n",
            "Epoch 100/599\n",
            "----------\n",
            "Training loss: 210.0435273349285\n",
            "Training accuracy: 0.7882190701339638\n",
            "Validation loss: 262.28010669350624\n",
            "Validation accuracy: 0.6792750197005516\n",
            "Epoch 101/599\n",
            "----------\n",
            "Training loss: 207.66219758987427\n",
            "Training accuracy: 0.793538219070134\n",
            "Validation loss: 260.97178360819817\n",
            "Validation accuracy: 0.6769109535066982\n",
            "Epoch 102/599\n",
            "----------\n",
            "Training loss: 207.21781393885612\n",
            "Training accuracy: 0.7929472025216706\n",
            "Validation loss: 262.6892316043377\n",
            "Validation accuracy: 0.6737588652482269\n",
            "Epoch 103/599\n",
            "----------\n",
            "Training loss: 205.10678246617317\n",
            "Training accuracy: 0.796591804570528\n",
            "Validation loss: 274.5522153377533\n",
            "Validation accuracy: 0.6513002364066194\n",
            "Epoch 104/599\n",
            "----------\n",
            "Training loss: 204.4227076768875\n",
            "Training accuracy: 0.7949172576832151\n",
            "Validation loss: 258.72836697101593\n",
            "Validation accuracy: 0.6843971631205674\n",
            "Epoch 105/599\n",
            "----------\n",
            "Training loss: 203.09122902154922\n",
            "Training accuracy: 0.8019109535066982\n",
            "Validation loss: 258.5194400548935\n",
            "Validation accuracy: 0.6824271079590228\n",
            "Epoch 106/599\n",
            "----------\n",
            "Training loss: 201.0783654153347\n",
            "Training accuracy: 0.8046690307328606\n",
            "Validation loss: 259.0123379230499\n",
            "Validation accuracy: 0.6863672182821119\n",
            "Epoch 107/599\n",
            "----------\n",
            "Training loss: 200.00012889504433\n",
            "Training accuracy: 0.8055555555555556\n",
            "Validation loss: 256.4344103336334\n",
            "Validation accuracy: 0.6836091410559496\n",
            "Epoch 108/599\n",
            "----------\n",
            "Training loss: 198.99974101781845\n",
            "Training accuracy: 0.8050630417651694\n",
            "Validation loss: 259.00159922242165\n",
            "Validation accuracy: 0.6784869976359338\n",
            "Epoch 109/599\n",
            "----------\n",
            "Training loss: 197.57174682617188\n",
            "Training accuracy: 0.8108747044917257\n",
            "Validation loss: 253.04939195513725\n",
            "Validation accuracy: 0.7005516154452325\n",
            "Epoch 110/599\n",
            "----------\n",
            "Training loss: 197.58710169792175\n",
            "Training accuracy: 0.8078211189913318\n",
            "Validation loss: 252.48366403579712\n",
            "Validation accuracy: 0.6910953506698188\n",
            "Epoch 111/599\n",
            "----------\n",
            "Training loss: 195.17801585793495\n",
            "Training accuracy: 0.8134357762017337\n",
            "Validation loss: 250.49625080823898\n",
            "Validation accuracy: 0.6970055161544523\n",
            "Epoch 112/599\n",
            "----------\n",
            "Training loss: 194.2475492656231\n",
            "Training accuracy: 0.814026792750197\n",
            "Validation loss: 254.20958092808723\n",
            "Validation accuracy: 0.6828211189913318\n",
            "Epoch 113/599\n",
            "----------\n",
            "Training loss: 192.72577613592148\n",
            "Training accuracy: 0.8176713947990544\n",
            "Validation loss: 253.1989426612854\n",
            "Validation accuracy: 0.6973995271867612\n",
            "Epoch 114/599\n",
            "----------\n",
            "Training loss: 192.13901966810226\n",
            "Training accuracy: 0.8207249802994484\n",
            "Validation loss: 250.1360071003437\n",
            "Validation accuracy: 0.6946414499605988\n",
            "Epoch 115/599\n",
            "----------\n",
            "Training loss: 191.8886987566948\n",
            "Training accuracy: 0.8186564223798266\n",
            "Validation loss: 248.21764108538628\n",
            "Validation accuracy: 0.7013396375098503\n",
            "Epoch 116/599\n",
            "----------\n",
            "Training loss: 189.91136839985847\n",
            "Training accuracy: 0.8230890464933018\n",
            "Validation loss: 245.29303920269012\n",
            "Validation accuracy: 0.7048857368006304\n",
            "Epoch 117/599\n",
            "----------\n",
            "Training loss: 188.8844069838524\n",
            "Training accuracy: 0.8269306540583137\n",
            "Validation loss: 243.5792820751667\n",
            "Validation accuracy: 0.710795902285264\n",
            "Epoch 118/599\n",
            "----------\n",
            "Training loss: 187.02382197976112\n",
            "Training accuracy: 0.8294917257683215\n",
            "Validation loss: 243.9747141301632\n",
            "Validation accuracy: 0.7100078802206462\n",
            "Epoch 119/599\n",
            "----------\n",
            "Training loss: 186.6781876385212\n",
            "Training accuracy: 0.8265366430260047\n",
            "Validation loss: 241.74587079882622\n",
            "Validation accuracy: 0.7131599684791174\n",
            "Epoch 120/599\n",
            "----------\n",
            "Training loss: 185.85770136117935\n",
            "Training accuracy: 0.8311662726556344\n",
            "Validation loss: 246.2536414861679\n",
            "Validation accuracy: 0.7115839243498818\n",
            "Epoch 121/599\n",
            "----------\n",
            "Training loss: 184.39184495806694\n",
            "Training accuracy: 0.8308707643814027\n",
            "Validation loss: 240.7174129486084\n",
            "Validation accuracy: 0.7151300236406619\n",
            "Epoch 122/599\n",
            "----------\n",
            "Training loss: 184.84765246510506\n",
            "Training accuracy: 0.8315602836879432\n",
            "Validation loss: 239.32621747255325\n",
            "Validation accuracy: 0.7171000788022065\n",
            "Epoch 123/599\n",
            "----------\n",
            "Training loss: 184.88445016741753\n",
            "Training accuracy: 0.8288022064617809\n",
            "Validation loss: 243.93244415521622\n",
            "Validation accuracy: 0.7072498029944838\n",
            "Epoch 124/599\n",
            "----------\n",
            "Training loss: 183.00253623723984\n",
            "Training accuracy: 0.8364854215918046\n",
            "Validation loss: 242.86860725283623\n",
            "Validation accuracy: 0.7115839243498818\n",
            "Epoch 125/599\n",
            "----------\n",
            "Training loss: 181.00934237241745\n",
            "Training accuracy: 0.8401300236406619\n",
            "Validation loss: 237.5946172773838\n",
            "Validation accuracy: 0.7155240346729709\n",
            "Epoch 126/599\n",
            "----------\n",
            "Training loss: 179.4930764734745\n",
            "Training accuracy: 0.8445626477541371\n",
            "Validation loss: 240.1163019835949\n",
            "Validation accuracy: 0.7127659574468085\n",
            "Epoch 127/599\n",
            "----------\n",
            "Training loss: 178.65527069568634\n",
            "Training accuracy: 0.8465327029156816\n",
            "Validation loss: 240.21163129806519\n",
            "Validation accuracy: 0.7194641449960599\n",
            "Epoch 128/599\n",
            "----------\n",
            "Training loss: 177.65632817149162\n",
            "Training accuracy: 0.8443656422379827\n",
            "Validation loss: 239.13609471917152\n",
            "Validation accuracy: 0.7100078802206462\n",
            "Epoch 129/599\n",
            "----------\n",
            "Training loss: 176.98782566189766\n",
            "Training accuracy: 0.8496847911741529\n",
            "Validation loss: 235.14016944169998\n",
            "Validation accuracy: 0.7206461780929866\n",
            "Epoch 130/599\n",
            "----------\n",
            "Training loss: 176.28184714913368\n",
            "Training accuracy: 0.8499802994483846\n",
            "Validation loss: 237.01130521297455\n",
            "Validation accuracy: 0.7171000788022065\n",
            "Epoch 131/599\n",
            "----------\n",
            "Training loss: 175.39197438955307\n",
            "Training accuracy: 0.8520488573680063\n",
            "Validation loss: 235.2917160987854\n",
            "Validation accuracy: 0.7301024428684003\n",
            "Epoch 132/599\n",
            "----------\n",
            "Training loss: 175.88279557228088\n",
            "Training accuracy: 0.8504728132387707\n",
            "Validation loss: 239.0116852223873\n",
            "Validation accuracy: 0.7182821118991332\n",
            "Epoch 133/599\n",
            "----------\n",
            "Training loss: 175.5044248998165\n",
            "Training accuracy: 0.8520488573680063\n",
            "Validation loss: 233.175220400095\n",
            "Validation accuracy: 0.7328605200945626\n",
            "Epoch 134/599\n",
            "----------\n",
            "Training loss: 172.88374304771423\n",
            "Training accuracy: 0.8532308904649331\n",
            "Validation loss: 236.6774625480175\n",
            "Validation accuracy: 0.7163120567375887\n",
            "Epoch 135/599\n",
            "----------\n",
            "Training loss: 171.5539870262146\n",
            "Training accuracy: 0.8608156028368794\n",
            "Validation loss: 232.23533236980438\n",
            "Validation accuracy: 0.7371946414499606\n",
            "Epoch 136/599\n",
            "----------\n",
            "Training loss: 172.14359691739082\n",
            "Training accuracy: 0.857565011820331\n",
            "Validation loss: 229.6141401231289\n",
            "Validation accuracy: 0.7375886524822695\n",
            "Epoch 137/599\n",
            "----------\n",
            "Training loss: 172.03798106312752\n",
            "Training accuracy: 0.8587470449172577\n",
            "Validation loss: 232.90256574749947\n",
            "Validation accuracy: 0.719070133963751\n",
            "Epoch 138/599\n",
            "----------\n",
            "Training loss: 170.51694869995117\n",
            "Training accuracy: 0.8603230890464934\n",
            "Validation loss: 230.05581119656563\n",
            "Validation accuracy: 0.7368006304176516\n",
            "Epoch 139/599\n",
            "----------\n",
            "Training loss: 169.0107645690441\n",
            "Training accuracy: 0.8573680063041765\n",
            "Validation loss: 227.8001381456852\n",
            "Validation accuracy: 0.7379826635145784\n",
            "Epoch 140/599\n",
            "----------\n",
            "Training loss: 169.14610332250595\n",
            "Training accuracy: 0.864558707643814\n",
            "Validation loss: 228.5473733842373\n",
            "Validation accuracy: 0.7391646966115051\n",
            "Epoch 141/599\n",
            "----------\n",
            "Training loss: 168.81896463036537\n",
            "Training accuracy: 0.864558707643814\n",
            "Validation loss: 227.54717974364758\n",
            "Validation accuracy: 0.7411347517730497\n",
            "Epoch 142/599\n",
            "----------\n",
            "Training loss: 167.0288937985897\n",
            "Training accuracy: 0.8622931442080378\n",
            "Validation loss: 227.88042357563972\n",
            "Validation accuracy: 0.7344365642237982\n",
            "Epoch 143/599\n",
            "----------\n",
            "Training loss: 167.3161191046238\n",
            "Training accuracy: 0.8690898345153665\n",
            "Validation loss: 223.60396349430084\n",
            "Validation accuracy: 0.739558707643814\n",
            "Epoch 144/599\n",
            "----------\n",
            "Training loss: 165.86142671108246\n",
            "Training accuracy: 0.8677107959022853\n",
            "Validation loss: 226.4520896077156\n",
            "Validation accuracy: 0.7486209613869188\n",
            "Epoch 145/599\n",
            "----------\n",
            "Training loss: 166.81537955999374\n",
            "Training accuracy: 0.8659377462568952\n",
            "Validation loss: 227.03103682398796\n",
            "Validation accuracy: 0.7462568951930654\n",
            "Epoch 146/599\n",
            "----------\n",
            "Training loss: 164.60933780670166\n",
            "Training accuracy: 0.8748029944838456\n",
            "Validation loss: 223.66670900583267\n",
            "Validation accuracy: 0.7529550827423168\n",
            "Epoch 147/599\n",
            "----------\n",
            "Training loss: 165.35318514704704\n",
            "Training accuracy: 0.8705673758865248\n",
            "Validation loss: 224.68401536345482\n",
            "Validation accuracy: 0.7431048069345941\n",
            "Epoch 148/599\n",
            "----------\n",
            "Training loss: 164.8981692492962\n",
            "Training accuracy: 0.8724389282899921\n",
            "Validation loss: 226.28462263941765\n",
            "Validation accuracy: 0.7415287628053585\n",
            "Epoch 149/599\n",
            "----------\n",
            "Training loss: 163.831360578537\n",
            "Training accuracy: 0.8745074862096138\n",
            "Validation loss: 223.4703816473484\n",
            "Validation accuracy: 0.7442868400315209\n",
            "Epoch 150/599\n",
            "----------\n",
            "Training loss: 165.06713232398033\n",
            "Training accuracy: 0.8707643814026793\n",
            "Validation loss: 227.4633949995041\n",
            "Validation accuracy: 0.7407407407407407\n",
            "Epoch 151/599\n",
            "----------\n",
            "Training loss: 163.82733571529388\n",
            "Training accuracy: 0.8743104806934594\n",
            "Validation loss: 219.356470271945\n",
            "Validation accuracy: 0.7580772261623325\n",
            "Epoch 152/599\n",
            "----------\n",
            "Training loss: 161.22241660952568\n",
            "Training accuracy: 0.8813041765169425\n",
            "Validation loss: 220.23968017101288\n",
            "Validation accuracy: 0.7576832151300237\n",
            "Epoch 153/599\n",
            "----------\n",
            "Training loss: 162.30976155400276\n",
            "Training accuracy: 0.8786446020488574\n",
            "Validation loss: 216.685054525733\n",
            "Validation accuracy: 0.7580772261623325\n",
            "Epoch 154/599\n",
            "----------\n",
            "Training loss: 160.9990657866001\n",
            "Training accuracy: 0.8816981875492513\n",
            "Validation loss: 218.86758342385292\n",
            "Validation accuracy: 0.7635933806146572\n",
            "Epoch 155/599\n",
            "----------\n",
            "Training loss: 159.8237218260765\n",
            "Training accuracy: 0.8804176516942475\n",
            "Validation loss: 219.21246686577797\n",
            "Validation accuracy: 0.7580772261623325\n",
            "Epoch 156/599\n",
            "----------\n",
            "Training loss: 159.37505573034286\n",
            "Training accuracy: 0.8821907013396375\n",
            "Validation loss: 216.42285099625587\n",
            "Validation accuracy: 0.764775413711584\n",
            "Epoch 157/599\n",
            "----------\n",
            "Training loss: 159.56711119413376\n",
            "Training accuracy: 0.8847517730496454\n",
            "Validation loss: 216.6108325868845\n",
            "Validation accuracy: 0.7580772261623325\n",
            "Epoch 158/599\n",
            "----------\n",
            "Training loss: 158.7674216926098\n",
            "Training accuracy: 0.8852442868400315\n",
            "Validation loss: 217.39984673261642\n",
            "Validation accuracy: 0.7663514578408196\n",
            "Epoch 159/599\n",
            "----------\n",
            "Training loss: 160.05473318696022\n",
            "Training accuracy: 0.8847517730496454\n",
            "Validation loss: 222.04992781579494\n",
            "Validation accuracy: 0.7494089834515366\n",
            "Epoch 160/599\n",
            "----------\n",
            "Training loss: 157.82657200098038\n",
            "Training accuracy: 0.8891843971631206\n",
            "Validation loss: 214.5524655431509\n",
            "Validation accuracy: 0.7730496453900709\n",
            "Epoch 161/599\n",
            "----------\n",
            "Training loss: 158.7164462506771\n",
            "Training accuracy: 0.8852442868400315\n",
            "Validation loss: 221.14915829896927\n",
            "Validation accuracy: 0.7663514578408196\n",
            "Epoch 162/599\n",
            "----------\n",
            "Training loss: 157.1835962831974\n",
            "Training accuracy: 0.8889873916469662\n",
            "Validation loss: 214.68011647462845\n",
            "Validation accuracy: 0.7710795902285263\n",
            "Epoch 163/599\n",
            "----------\n",
            "Training loss: 156.69365045428276\n",
            "Training accuracy: 0.89026792750197\n",
            "Validation loss: 215.53081792593002\n",
            "Validation accuracy: 0.7628053585500394\n",
            "Epoch 164/599\n",
            "----------\n",
            "Training loss: 157.3372803926468\n",
            "Training accuracy: 0.8870173364854216\n",
            "Validation loss: 216.304716065526\n",
            "Validation accuracy: 0.760441292356186\n",
            "Epoch 165/599\n",
            "----------\n",
            "Training loss: 156.32695934176445\n",
            "Training accuracy: 0.8899724192277384\n",
            "Validation loss: 212.76756624877453\n",
            "Validation accuracy: 0.7710795902285263\n",
            "Epoch 166/599\n",
            "----------\n",
            "Training loss: 156.10783848166466\n",
            "Training accuracy: 0.8919424743892829\n",
            "Validation loss: 220.4631388783455\n",
            "Validation accuracy: 0.747832939322301\n",
            "Epoch 167/599\n",
            "----------\n",
            "Training loss: 155.92266961932182\n",
            "Training accuracy: 0.8953900709219859\n",
            "Validation loss: 210.60359665751457\n",
            "Validation accuracy: 0.7754137115839244\n",
            "Epoch 168/599\n",
            "----------\n",
            "Training loss: 154.26287391781807\n",
            "Training accuracy: 0.9009062253743105\n",
            "Validation loss: 216.04202607274055\n",
            "Validation accuracy: 0.7667454688731284\n",
            "Epoch 169/599\n",
            "----------\n",
            "Training loss: 156.64673191308975\n",
            "Training accuracy: 0.8904649330181245\n",
            "Validation loss: 215.2409165352583\n",
            "Validation accuracy: 0.7702915681639085\n",
            "Epoch 170/599\n",
            "----------\n",
            "Training loss: 155.77634420990944\n",
            "Training accuracy: 0.8947990543735225\n",
            "Validation loss: 210.14427135884762\n",
            "Validation accuracy: 0.7805358550039401\n",
            "Epoch 171/599\n",
            "----------\n",
            "Training loss: 155.14263528585434\n",
            "Training accuracy: 0.894602048857368\n",
            "Validation loss: 209.90103797614574\n",
            "Validation accuracy: 0.7801418439716312\n",
            "Epoch 172/599\n",
            "----------\n",
            "Training loss: 155.56195649504662\n",
            "Training accuracy: 0.8959810874704491\n",
            "Validation loss: 211.9585818052292\n",
            "Validation accuracy: 0.7840819542947203\n",
            "Epoch 173/599\n",
            "----------\n",
            "Training loss: 154.82866320014\n",
            "Training accuracy: 0.8945035460992907\n",
            "Validation loss: 210.8312667310238\n",
            "Validation accuracy: 0.7793538219070134\n",
            "Epoch 174/599\n",
            "----------\n",
            "Training loss: 155.291515737772\n",
            "Training accuracy: 0.8955870764381403\n",
            "Validation loss: 212.16393944621086\n",
            "Validation accuracy: 0.7821118991331757\n",
            "Epoch 175/599\n",
            "----------\n",
            "Training loss: 154.43125542998314\n",
            "Training accuracy: 0.8984436564223798\n",
            "Validation loss: 211.59811183810234\n",
            "Validation accuracy: 0.7868400315208826\n",
            "Epoch 176/599\n",
            "----------\n",
            "Training loss: 154.117181122303\n",
            "Training accuracy: 0.9013987391646966\n",
            "Validation loss: 210.0751085728407\n",
            "Validation accuracy: 0.7718676122931442\n",
            "Epoch 177/599\n",
            "----------\n",
            "Training loss: 153.7065690755844\n",
            "Training accuracy: 0.8991331757289204\n",
            "Validation loss: 212.75294890999794\n",
            "Validation accuracy: 0.7852639873916469\n",
            "Epoch 178/599\n",
            "----------\n",
            "Training loss: 154.07511231303215\n",
            "Training accuracy: 0.9001182033096927\n",
            "Validation loss: 212.66187384724617\n",
            "Validation accuracy: 0.7722616233254531\n",
            "Epoch 179/599\n",
            "----------\n",
            "Training loss: 153.314116448164\n",
            "Training accuracy: 0.9014972419227738\n",
            "Validation loss: 208.6626964211464\n",
            "Validation accuracy: 0.7825059101654847\n",
            "Epoch 180/599\n",
            "----------\n",
            "Training loss: 152.43833044171333\n",
            "Training accuracy: 0.9039598108747045\n",
            "Validation loss: 208.3902260363102\n",
            "Validation accuracy: 0.7880220646178093\n",
            "Epoch 181/599\n",
            "----------\n",
            "Training loss: 153.15735587477684\n",
            "Training accuracy: 0.899822695035461\n",
            "Validation loss: 217.25654259324074\n",
            "Validation accuracy: 0.7596532702915682\n",
            "Epoch 182/599\n",
            "----------\n",
            "Training loss: 153.34743928909302\n",
            "Training accuracy: 0.9009062253743105\n",
            "Validation loss: 212.2237245440483\n",
            "Validation accuracy: 0.776595744680851\n",
            "Epoch 183/599\n",
            "----------\n",
            "Training loss: 153.18209040164948\n",
            "Training accuracy: 0.9018912529550828\n",
            "Validation loss: 206.31097263097763\n",
            "Validation accuracy: 0.7848699763593381\n",
            "Epoch 184/599\n",
            "----------\n",
            "Training loss: 153.91260319948196\n",
            "Training accuracy: 0.9017927501970056\n",
            "Validation loss: 209.2002558708191\n",
            "Validation accuracy: 0.7856579984239559\n",
            "Epoch 185/599\n",
            "----------\n",
            "Training loss: 153.57392343878746\n",
            "Training accuracy: 0.902876280535855\n",
            "Validation loss: 207.05199071764946\n",
            "Validation accuracy: 0.7927501970055162\n",
            "Epoch 186/599\n",
            "----------\n",
            "Training loss: 153.422657340765\n",
            "Training accuracy: 0.9070133963750985\n",
            "Validation loss: 208.76120428740978\n",
            "Validation accuracy: 0.7876280535855004\n",
            "Epoch 187/599\n",
            "----------\n",
            "Training loss: 152.34776186943054\n",
            "Training accuracy: 0.9078999211977935\n",
            "Validation loss: 216.93611705303192\n",
            "Validation accuracy: 0.772655634357762\n",
            "Epoch 188/599\n",
            "----------\n",
            "Training loss: 152.5370265841484\n",
            "Training accuracy: 0.905929866036249\n",
            "Validation loss: 208.11563235521317\n",
            "Validation accuracy: 0.7903861308116628\n",
            "Epoch 189/599\n",
            "----------\n",
            "Training loss: 152.4252572953701\n",
            "Training accuracy: 0.9044523246650906\n",
            "Validation loss: 206.83434304594994\n",
            "Validation accuracy: 0.7868400315208826\n",
            "Epoch 190/599\n",
            "----------\n",
            "Training loss: 153.12525817751884\n",
            "Training accuracy: 0.9076044129235619\n",
            "Validation loss: 204.92467819154263\n",
            "Validation accuracy: 0.7951142631993696\n",
            "Epoch 191/599\n",
            "----------\n",
            "Training loss: 153.19053629040718\n",
            "Training accuracy: 0.9051418439716312\n",
            "Validation loss: 205.95373100042343\n",
            "Validation accuracy: 0.7880220646178093\n",
            "Epoch 192/599\n",
            "----------\n",
            "Training loss: 151.94397735595703\n",
            "Training accuracy: 0.9071118991331757\n",
            "Validation loss: 206.27095015347004\n",
            "Validation accuracy: 0.797478329393223\n",
            "Epoch 193/599\n",
            "----------\n",
            "Training loss: 152.67205747961998\n",
            "Training accuracy: 0.9054373522458629\n",
            "Validation loss: 208.11024591326714\n",
            "Validation accuracy: 0.8002364066193853\n",
            "Epoch 194/599\n",
            "----------\n",
            "Training loss: 152.43349727988243\n",
            "Training accuracy: 0.9073089046493302\n",
            "Validation loss: 207.3236809372902\n",
            "Validation accuracy: 0.7911741528762806\n",
            "Epoch 195/599\n",
            "----------\n",
            "Training loss: 152.81227979063988\n",
            "Training accuracy: 0.9064223798266351\n",
            "Validation loss: 214.1224683225155\n",
            "Validation accuracy: 0.7750197005516154\n",
            "Epoch 196/599\n",
            "----------\n",
            "Training loss: 153.05812913179398\n",
            "Training accuracy: 0.9077029156816391\n",
            "Validation loss: 205.78760267794132\n",
            "Validation accuracy: 0.7923561859732072\n",
            "Epoch 197/599\n",
            "----------\n",
            "Training loss: 152.57603800296783\n",
            "Training accuracy: 0.911150512214342\n",
            "Validation loss: 206.940246373415\n",
            "Validation accuracy: 0.7970843183609141\n",
            "Epoch 198/599\n",
            "----------\n",
            "Training loss: 152.55651637911797\n",
            "Training accuracy: 0.9095744680851063\n",
            "Validation loss: 208.59579318761826\n",
            "Validation accuracy: 0.7978723404255319\n",
            "Epoch 199/599\n",
            "----------\n",
            "Training loss: 152.53078538179398\n",
            "Training accuracy: 0.9076044129235619\n",
            "Validation loss: 206.39331206679344\n",
            "Validation accuracy: 0.8033884948778566\n",
            "Epoch 200/599\n",
            "----------\n",
            "Training loss: 153.3791452050209\n",
            "Training accuracy: 0.9116430260047281\n",
            "Validation loss: 206.4351989030838\n",
            "Validation accuracy: 0.7982663514578409\n",
            "Epoch 201/599\n",
            "----------\n",
            "Training loss: 151.9212103188038\n",
            "Training accuracy: 0.9138100866824271\n",
            "Validation loss: 207.27691707015038\n",
            "Validation accuracy: 0.797478329393223\n",
            "Epoch 202/599\n",
            "----------\n",
            "Training loss: 153.2604888677597\n",
            "Training accuracy: 0.9120370370370371\n",
            "Validation loss: 205.29863266646862\n",
            "Validation accuracy: 0.7986603624901497\n",
            "Epoch 203/599\n",
            "----------\n",
            "Training loss: 152.1187863945961\n",
            "Training accuracy: 0.9130220646178093\n",
            "Validation loss: 205.54146476089954\n",
            "Validation accuracy: 0.7888100866824271\n",
            "Epoch 204/599\n",
            "----------\n",
            "Training loss: 152.5406901538372\n",
            "Training accuracy: 0.9118400315208826\n",
            "Validation loss: 209.27727097272873\n",
            "Validation accuracy: 0.8014184397163121\n",
            "Epoch 205/599\n",
            "----------\n",
            "Training loss: 152.6368641257286\n",
            "Training accuracy: 0.9101654846335697\n",
            "Validation loss: 206.33101227879524\n",
            "Validation accuracy: 0.7962962962962963\n",
            "Epoch 206/599\n",
            "----------\n",
            "Training loss: 152.21191933751106\n",
            "Training accuracy: 0.9178486997635934\n",
            "Validation loss: 205.7962791621685\n",
            "Validation accuracy: 0.7962962962962963\n",
            "Epoch 207/599\n",
            "----------\n",
            "Training loss: 152.56523963809013\n",
            "Training accuracy: 0.9141055949566588\n",
            "Validation loss: 208.24592897295952\n",
            "Validation accuracy: 0.7966903073286052\n",
            "Epoch 208/599\n",
            "----------\n",
            "Training loss: 152.75392550230026\n",
            "Training accuracy: 0.9125295508274232\n",
            "Validation loss: 206.82847261428833\n",
            "Validation accuracy: 0.8041765169424744\n",
            "Epoch 209/599\n",
            "----------\n",
            "Training loss: 154.14375239610672\n",
            "Training accuracy: 0.9102639873916469\n",
            "Validation loss: 208.44420590996742\n",
            "Validation accuracy: 0.7955082742316785\n",
            "Epoch 210/599\n",
            "----------\n",
            "Training loss: 152.9804943203926\n",
            "Training accuracy: 0.9109535066981875\n",
            "Validation loss: 211.6106490790844\n",
            "Validation accuracy: 0.7911741528762806\n",
            "Epoch 211/599\n",
            "----------\n",
            "Training loss: 153.80172899365425\n",
            "Training accuracy: 0.9132190701339638\n",
            "Validation loss: 205.546726167202\n",
            "Validation accuracy: 0.8112687155240347\n",
            "Epoch 212/599\n",
            "----------\n",
            "Training loss: 153.563177973032\n",
            "Training accuracy: 0.9146966115051222\n",
            "Validation loss: 203.78680089116096\n",
            "Validation accuracy: 0.8073286052009456\n",
            "Epoch 213/599\n",
            "----------\n",
            "Training loss: 153.76425909996033\n",
            "Training accuracy: 0.9148936170212766\n",
            "Validation loss: 210.470488935709\n",
            "Validation accuracy: 0.7876280535855004\n",
            "Epoch 214/599\n",
            "----------\n",
            "Training loss: 153.61962482333183\n",
            "Training accuracy: 0.9177501970055162\n",
            "Validation loss: 204.66625113785267\n",
            "Validation accuracy: 0.8065405831363278\n",
            "Epoch 215/599\n",
            "----------\n",
            "Training loss: 154.09277126193047\n",
            "Training accuracy: 0.9123325453112687\n",
            "Validation loss: 206.08225752413273\n",
            "Validation accuracy: 0.80575256107171\n",
            "Epoch 216/599\n",
            "----------\n",
            "Training loss: 154.68914419412613\n",
            "Training accuracy: 0.9161741528762806\n",
            "Validation loss: 207.59676778316498\n",
            "Validation accuracy: 0.7919621749408984\n",
            "Epoch 217/599\n",
            "----------\n",
            "Training loss: 154.70511057972908\n",
            "Training accuracy: 0.91725768321513\n",
            "Validation loss: 205.92251408100128\n",
            "Validation accuracy: 0.8053585500394012\n",
            "Epoch 218/599\n",
            "----------\n",
            "Training loss: 153.87666687369347\n",
            "Training accuracy: 0.91548463356974\n",
            "Validation loss: 206.03436101973057\n",
            "Validation accuracy: 0.8096926713947991\n",
            "Epoch 219/599\n",
            "----------\n",
            "Training loss: 154.4000320136547\n",
            "Training accuracy: 0.914204097714736\n",
            "Validation loss: 206.09747494757175\n",
            "Validation accuracy: 0.8022064617809299\n",
            "Epoch 220/599\n",
            "----------\n",
            "Training loss: 153.938475638628\n",
            "Training accuracy: 0.9193262411347518\n",
            "Validation loss: 205.9096802175045\n",
            "Validation accuracy: 0.8073286052009456\n",
            "Epoch 221/599\n",
            "----------\n",
            "Training loss: 155.41805145144463\n",
            "Training accuracy: 0.9130220646178093\n",
            "Validation loss: 204.65893849730492\n",
            "Validation accuracy: 0.8026004728132388\n",
            "Epoch 222/599\n",
            "----------\n",
            "Training loss: 155.99020206928253\n",
            "Training accuracy: 0.9144996059889677\n",
            "Validation loss: 203.3157747387886\n",
            "Validation accuracy: 0.8159968479117415\n",
            "Epoch 223/599\n",
            "----------\n",
            "Training loss: 155.57912376523018\n",
            "Training accuracy: 0.9158786446020488\n",
            "Validation loss: 206.3274861574173\n",
            "Validation accuracy: 0.8065405831363278\n",
            "Epoch 224/599\n",
            "----------\n",
            "Training loss: 154.86367148160934\n",
            "Training accuracy: 0.9160756501182034\n",
            "Validation loss: 205.59001085162163\n",
            "Validation accuracy: 0.8053585500394012\n",
            "Epoch 225/599\n",
            "----------\n",
            "Training loss: 155.89671558141708\n",
            "Training accuracy: 0.9137115839243499\n",
            "Validation loss: 223.21715474128723\n",
            "Validation accuracy: 0.7541371158392435\n",
            "Epoch 226/599\n",
            "----------\n",
            "Training loss: 155.31508231163025\n",
            "Training accuracy: 0.915090622537431\n",
            "Validation loss: 208.7369005382061\n",
            "Validation accuracy: 0.8010244286840031\n",
            "Epoch 227/599\n",
            "----------\n",
            "Training loss: 155.25001353025436\n",
            "Training accuracy: 0.9161741528762806\n",
            "Validation loss: 206.5186594426632\n",
            "Validation accuracy: 0.797478329393223\n",
            "Epoch 228/599\n",
            "----------\n",
            "Training loss: 155.6209997832775\n",
            "Training accuracy: 0.9166666666666666\n",
            "Validation loss: 209.45061720907688\n",
            "Validation accuracy: 0.8014184397163121\n",
            "Epoch 229/599\n",
            "----------\n",
            "Training loss: 155.65735992789268\n",
            "Training accuracy: 0.918144208037825\n",
            "Validation loss: 202.01018059253693\n",
            "Validation accuracy: 0.817966903073286\n",
            "Epoch 230/599\n",
            "----------\n",
            "Training loss: 156.72495466470718\n",
            "Training accuracy: 0.9151891252955082\n",
            "Validation loss: 203.37007024884224\n",
            "Validation accuracy: 0.8215130023640662\n",
            "Epoch 231/599\n",
            "----------\n",
            "Training loss: 156.98003220558167\n",
            "Training accuracy: 0.9165681639085894\n",
            "Validation loss: 204.97133088111877\n",
            "Validation accuracy: 0.8156028368794326\n",
            "Epoch 232/599\n",
            "----------\n",
            "Training loss: 155.83656615018845\n",
            "Training accuracy: 0.9166666666666666\n",
            "Validation loss: 208.87012873589993\n",
            "Validation accuracy: 0.7994483845547675\n",
            "Epoch 233/599\n",
            "----------\n",
            "Training loss: 156.43400064110756\n",
            "Training accuracy: 0.9174546887312844\n",
            "Validation loss: 206.80714318156242\n",
            "Validation accuracy: 0.8006304176516943\n",
            "Epoch 234/599\n",
            "----------\n",
            "Training loss: 156.8051005601883\n",
            "Training accuracy: 0.9146966115051222\n",
            "Validation loss: 203.96416905522346\n",
            "Validation accuracy: 0.8226950354609929\n",
            "Epoch 235/599\n",
            "----------\n",
            "Training loss: 157.32933369278908\n",
            "Training accuracy: 0.9164696611505122\n",
            "Validation loss: 204.4077154994011\n",
            "Validation accuracy: 0.8120567375886525\n",
            "Epoch 236/599\n",
            "----------\n",
            "Training loss: 157.72126412391663\n",
            "Training accuracy: 0.9160756501182034\n",
            "Validation loss: 202.56019991636276\n",
            "Validation accuracy: 0.8136327817178881\n",
            "Epoch 237/599\n",
            "----------\n",
            "Training loss: 157.26715525984764\n",
            "Training accuracy: 0.9192277383766746\n",
            "Validation loss: 207.1634946167469\n",
            "Validation accuracy: 0.8065405831363278\n",
            "Epoch 238/599\n",
            "----------\n",
            "Training loss: 156.93315488100052\n",
            "Training accuracy: 0.9210007880220646\n",
            "Validation loss: 206.890713468194\n",
            "Validation accuracy: 0.814026792750197\n",
            "Epoch 239/599\n",
            "----------\n",
            "Training loss: 158.67578506469727\n",
            "Training accuracy: 0.9199172576832151\n",
            "Validation loss: 204.08112034201622\n",
            "Validation accuracy: 0.8191489361702128\n",
            "Epoch 240/599\n",
            "----------\n",
            "Training loss: 157.43536520004272\n",
            "Training accuracy: 0.9182427107959023\n",
            "Validation loss: 205.86718878149986\n",
            "Validation accuracy: 0.8041765169424744\n",
            "Epoch 241/599\n",
            "----------\n",
            "Training loss: 156.7975831925869\n",
            "Training accuracy: 0.9191292356185973\n",
            "Validation loss: 205.6575448513031\n",
            "Validation accuracy: 0.8136327817178881\n",
            "Epoch 242/599\n",
            "----------\n",
            "Training loss: 157.08565506339073\n",
            "Training accuracy: 0.9189322301024428\n",
            "Validation loss: 205.3014045804739\n",
            "Validation accuracy: 0.8136327817178881\n",
            "Epoch 243/599\n",
            "----------\n",
            "Training loss: 158.24548852443695\n",
            "Training accuracy: 0.9177501970055162\n",
            "Validation loss: 209.5825493335724\n",
            "Validation accuracy: 0.8041765169424744\n",
            "Epoch 244/599\n",
            "----------\n",
            "Training loss: 158.04610416293144\n",
            "Training accuracy: 0.9187352245862884\n",
            "Validation loss: 205.11858010292053\n",
            "Validation accuracy: 0.8108747044917257\n",
            "Epoch 245/599\n",
            "----------\n",
            "Training loss: 158.20404621958733\n",
            "Training accuracy: 0.9168636721828212\n",
            "Validation loss: 205.91589123010635\n",
            "Validation accuracy: 0.814026792750197\n",
            "Epoch 246/599\n",
            "----------\n",
            "Training loss: 158.64146834611893\n",
            "Training accuracy: 0.9189322301024428\n",
            "Validation loss: 208.981615960598\n",
            "Validation accuracy: 0.8081166272655634\n",
            "Epoch 247/599\n",
            "----------\n",
            "Training loss: 158.22031128406525\n",
            "Training accuracy: 0.9202127659574468\n",
            "Validation loss: 203.09744273126125\n",
            "Validation accuracy: 0.8191489361702128\n",
            "Epoch 248/599\n",
            "----------\n",
            "Training loss: 159.26579162478447\n",
            "Training accuracy: 0.9151891252955082\n",
            "Validation loss: 204.8041330575943\n",
            "Validation accuracy: 0.8092986603624901\n",
            "Epoch 249/599\n",
            "----------\n",
            "Training loss: 159.27647417783737\n",
            "Training accuracy: 0.915090622537431\n",
            "Validation loss: 207.88455799221992\n",
            "Validation accuracy: 0.8116627265563435\n",
            "Epoch 250/599\n",
            "----------\n",
            "Training loss: 159.63377597928047\n",
            "Training accuracy: 0.9166666666666666\n",
            "Validation loss: 208.19841599464417\n",
            "Validation accuracy: 0.8116627265563435\n",
            "Epoch 251/599\n",
            "----------\n",
            "Training loss: 157.35595846176147\n",
            "Training accuracy: 0.9242513790386131\n",
            "Validation loss: 204.27769619226456\n",
            "Validation accuracy: 0.8230890464933018\n",
            "Epoch 252/599\n",
            "----------\n",
            "Training loss: 158.61925959587097\n",
            "Training accuracy: 0.9187352245862884\n",
            "Validation loss: 205.9693706035614\n",
            "Validation accuracy: 0.8234830575256107\n",
            "Epoch 253/599\n",
            "----------\n",
            "Training loss: 159.77562355995178\n",
            "Training accuracy: 0.9129235618597321\n",
            "Validation loss: 210.79000556468964\n",
            "Validation accuracy: 0.8022064617809299\n",
            "Epoch 254/599\n",
            "----------\n",
            "Training loss: 159.2767103612423\n",
            "Training accuracy: 0.9199172576832151\n",
            "Validation loss: 203.68132562935352\n",
            "Validation accuracy: 0.8242710795902285\n",
            "Epoch 255/599\n",
            "----------\n",
            "Training loss: 158.48525476455688\n",
            "Training accuracy: 0.9200157604412924\n",
            "Validation loss: 205.40222012996674\n",
            "Validation accuracy: 0.8238770685579196\n",
            "Epoch 256/599\n",
            "----------\n",
            "Training loss: 158.33615970611572\n",
            "Training accuracy: 0.9199172576832151\n",
            "Validation loss: 205.6964130103588\n",
            "Validation accuracy: 0.8262411347517731\n",
            "Epoch 257/599\n",
            "----------\n",
            "Training loss: 160.13695839047432\n",
            "Training accuracy: 0.9164696611505122\n",
            "Validation loss: 203.92051807045937\n",
            "Validation accuracy: 0.817966903073286\n",
            "Epoch 258/599\n",
            "----------\n",
            "Training loss: 159.64400079846382\n",
            "Training accuracy: 0.9174546887312844\n",
            "Validation loss: 205.55208417773247\n",
            "Validation accuracy: 0.8128447596532703\n",
            "Epoch 259/599\n",
            "----------\n",
            "Training loss: 159.4477232992649\n",
            "Training accuracy: 0.9183412135539795\n",
            "Validation loss: 205.99704721570015\n",
            "Validation accuracy: 0.8100866824271079\n",
            "Epoch 260/599\n",
            "----------\n",
            "Training loss: 159.380346596241\n",
            "Training accuracy: 0.917651694247439\n",
            "Validation loss: 229.2030768096447\n",
            "Validation accuracy: 0.7505910165484634\n",
            "Epoch 261/599\n",
            "----------\n",
            "Training loss: 159.51606798171997\n",
            "Training accuracy: 0.920311268715524\n",
            "Validation loss: 208.70949724316597\n",
            "Validation accuracy: 0.8215130023640662\n",
            "Epoch 262/599\n",
            "----------\n",
            "Training loss: 160.24715360999107\n",
            "Training accuracy: 0.9201142631993696\n",
            "Validation loss: 205.19872027635574\n",
            "Validation accuracy: 0.8171788810086682\n",
            "Epoch 263/599\n",
            "----------\n",
            "Training loss: 159.0212720632553\n",
            "Training accuracy: 0.9259259259259259\n",
            "Validation loss: 207.8226128667593\n",
            "Validation accuracy: 0.8175728920409772\n",
            "Epoch 264/599\n",
            "----------\n",
            "Training loss: 160.14427548646927\n",
            "Training accuracy: 0.9192277383766746\n",
            "Validation loss: 206.02136170864105\n",
            "Validation accuracy: 0.8226950354609929\n",
            "Epoch 265/599\n",
            "----------\n",
            "Training loss: 158.5550284087658\n",
            "Training accuracy: 0.9211977935382191\n",
            "Validation loss: 203.6695845425129\n",
            "Validation accuracy: 0.8132387706855791\n",
            "Epoch 266/599\n",
            "----------\n",
            "Training loss: 160.66871938109398\n",
            "Training accuracy: 0.920311268715524\n",
            "Validation loss: 209.89083728194237\n",
            "Validation accuracy: 0.7970843183609141\n",
            "Epoch 267/599\n",
            "----------\n",
            "Training loss: 160.4944381415844\n",
            "Training accuracy: 0.9193262411347518\n",
            "Validation loss: 205.38963210582733\n",
            "Validation accuracy: 0.8171788810086682\n",
            "Epoch 268/599\n",
            "----------\n",
            "Training loss: 158.28793480992317\n",
            "Training accuracy: 0.9243498817966903\n",
            "Validation loss: 205.4345659315586\n",
            "Validation accuracy: 0.8148148148148148\n",
            "Epoch 269/599\n",
            "----------\n",
            "Training loss: 159.69005152583122\n",
            "Training accuracy: 0.9209022852639874\n",
            "Validation loss: 206.19951079785824\n",
            "Validation accuracy: 0.8171788810086682\n",
            "Epoch 270/599\n",
            "----------\n",
            "Training loss: 159.97078689932823\n",
            "Training accuracy: 0.9202127659574468\n",
            "Validation loss: 206.31732994318008\n",
            "Validation accuracy: 0.8219070133963751\n",
            "Epoch 271/599\n",
            "----------\n",
            "Training loss: 159.7033044397831\n",
            "Training accuracy: 0.9204097714736013\n",
            "Validation loss: 203.5225104689598\n",
            "Validation accuracy: 0.8234830575256107\n",
            "Epoch 272/599\n",
            "----------\n",
            "Training loss: 159.87032470107079\n",
            "Training accuracy: 0.919424743892829\n",
            "Validation loss: 211.37560267746449\n",
            "Validation accuracy: 0.7919621749408984\n",
            "Epoch 273/599\n",
            "----------\n",
            "Training loss: 159.86470079421997\n",
            "Training accuracy: 0.9216903073286052\n",
            "Validation loss: 205.23884232342243\n",
            "Validation accuracy: 0.8136327817178881\n",
            "Epoch 274/599\n",
            "----------\n",
            "Training loss: 160.34635370969772\n",
            "Training accuracy: 0.9192277383766746\n",
            "Validation loss: 203.1898691803217\n",
            "Validation accuracy: 0.8226950354609929\n",
            "Epoch 275/599\n",
            "----------\n",
            "Training loss: 160.0274479985237\n",
            "Training accuracy: 0.9201142631993696\n",
            "Validation loss: 202.98615071177483\n",
            "Validation accuracy: 0.8353033884948778\n",
            "Epoch 276/599\n",
            "----------\n",
            "Training loss: 159.84331113100052\n",
            "Training accuracy: 0.9244483845547675\n",
            "Validation loss: 203.2762317210436\n",
            "Validation accuracy: 0.83451536643026\n",
            "Epoch 277/599\n",
            "----------\n",
            "Training loss: 158.96842661499977\n",
            "Training accuracy: 0.9226753349093775\n",
            "Validation loss: 203.8905318081379\n",
            "Validation accuracy: 0.8278171788810087\n",
            "Epoch 278/599\n",
            "----------\n",
            "Training loss: 159.71020290255547\n",
            "Training accuracy: 0.9219858156028369\n",
            "Validation loss: 204.62210008502007\n",
            "Validation accuracy: 0.8167848699763594\n",
            "Epoch 279/599\n",
            "----------\n",
            "Training loss: 160.47787243127823\n",
            "Training accuracy: 0.9210007880220646\n",
            "Validation loss: 203.8072113841772\n",
            "Validation accuracy: 0.8262411347517731\n",
            "Epoch 280/599\n",
            "----------\n",
            "Training loss: 159.84624794125557\n",
            "Training accuracy: 0.9216903073286052\n",
            "Validation loss: 210.11340636014938\n",
            "Validation accuracy: 0.7959022852639874\n",
            "Epoch 281/599\n",
            "----------\n",
            "Training loss: 159.217241615057\n",
            "Training accuracy: 0.9217888100866825\n",
            "Validation loss: 207.79890102148056\n",
            "Validation accuracy: 0.8100866824271079\n",
            "Epoch 282/599\n",
            "----------\n",
            "Training loss: 158.90095269680023\n",
            "Training accuracy: 0.9225768321513003\n",
            "Validation loss: 207.55526189506054\n",
            "Validation accuracy: 0.8112687155240347\n",
            "Epoch 283/599\n",
            "----------\n",
            "Training loss: 158.95609092712402\n",
            "Training accuracy: 0.9238573680063041\n",
            "Validation loss: 205.5895692706108\n",
            "Validation accuracy: 0.8148148148148148\n",
            "Epoch 284/599\n",
            "----------\n",
            "Training loss: 158.02468839287758\n",
            "Training accuracy: 0.9267139479905437\n",
            "Validation loss: 203.22517582774162\n",
            "Validation accuracy: 0.8266351457840819\n",
            "Epoch 285/599\n",
            "----------\n",
            "Training loss: 158.91381922364235\n",
            "Training accuracy: 0.9204097714736013\n",
            "Validation loss: 201.17715093493462\n",
            "Validation accuracy: 0.8376674546887313\n",
            "Epoch 286/599\n",
            "----------\n",
            "Training loss: 157.9250628054142\n",
            "Training accuracy: 0.9277974783293932\n",
            "Validation loss: 204.80194471776485\n",
            "Validation accuracy: 0.8195429472025216\n",
            "Epoch 287/599\n",
            "----------\n",
            "Training loss: 158.70871102809906\n",
            "Training accuracy: 0.9277974783293932\n",
            "Validation loss: 212.44184425473213\n",
            "Validation accuracy: 0.7876280535855004\n",
            "Epoch 288/599\n",
            "----------\n",
            "Training loss: 159.0001186132431\n",
            "Training accuracy: 0.9200157604412924\n",
            "Validation loss: 205.8827354311943\n",
            "Validation accuracy: 0.8163908589440504\n",
            "Epoch 289/599\n",
            "----------\n",
            "Training loss: 159.46027594804764\n",
            "Training accuracy: 0.925531914893617\n",
            "Validation loss: 203.89328472316265\n",
            "Validation accuracy: 0.8175728920409772\n",
            "Epoch 290/599\n",
            "----------\n",
            "Training loss: 159.60778081417084\n",
            "Training accuracy: 0.9187352245862884\n",
            "Validation loss: 202.9464572072029\n",
            "Validation accuracy: 0.8274231678486997\n",
            "Epoch 291/599\n",
            "----------\n",
            "Training loss: 158.41448625922203\n",
            "Training accuracy: 0.9244483845547675\n",
            "Validation loss: 210.87169101834297\n",
            "Validation accuracy: 0.7911741528762806\n",
            "Epoch 292/599\n",
            "----------\n",
            "Training loss: 158.03239020705223\n",
            "Training accuracy: 0.9272064617809299\n",
            "Validation loss: 204.99536223709583\n",
            "Validation accuracy: 0.8262411347517731\n",
            "Epoch 293/599\n",
            "----------\n",
            "Training loss: 158.1731597185135\n",
            "Training accuracy: 0.9242513790386131\n",
            "Validation loss: 212.83956399559975\n",
            "Validation accuracy: 0.7754137115839244\n",
            "Epoch 294/599\n",
            "----------\n",
            "Training loss: 158.91222846508026\n",
            "Training accuracy: 0.9226753349093775\n",
            "Validation loss: 204.72462172806263\n",
            "Validation accuracy: 0.8266351457840819\n",
            "Epoch 295/599\n",
            "----------\n",
            "Training loss: 159.1361929178238\n",
            "Training accuracy: 0.9207052797478329\n",
            "Validation loss: 203.72546127438545\n",
            "Validation accuracy: 0.8116627265563435\n",
            "Epoch 296/599\n",
            "----------\n",
            "Training loss: 159.52341958880424\n",
            "Training accuracy: 0.9225768321513003\n",
            "Validation loss: 198.05440019071102\n",
            "Validation accuracy: 0.8372734436564224\n",
            "Epoch 297/599\n",
            "----------\n",
            "Training loss: 158.88057774305344\n",
            "Training accuracy: 0.9249408983451537\n",
            "Validation loss: 203.3324075639248\n",
            "Validation accuracy: 0.818360914105595\n",
            "Epoch 298/599\n",
            "----------\n",
            "Training loss: 158.7090935409069\n",
            "Training accuracy: 0.9253349093774625\n",
            "Validation loss: 205.18455846607685\n",
            "Validation accuracy: 0.8159968479117415\n",
            "Epoch 299/599\n",
            "----------\n",
            "Training loss: 159.58336958289146\n",
            "Training accuracy: 0.9212962962962963\n",
            "Validation loss: 209.87558487057686\n",
            "Validation accuracy: 0.7982663514578409\n",
            "Epoch 300/599\n",
            "----------\n",
            "Training loss: 159.10835805535316\n",
            "Training accuracy: 0.9205082742316785\n",
            "Validation loss: 205.41353237628937\n",
            "Validation accuracy: 0.8053585500394012\n",
            "Epoch 301/599\n",
            "----------\n",
            "Training loss: 158.87563240528107\n",
            "Training accuracy: 0.9229708431836091\n",
            "Validation loss: 212.2395269870758\n",
            "Validation accuracy: 0.7927501970055162\n",
            "Epoch 302/599\n",
            "----------\n",
            "Training loss: 158.1338735818863\n",
            "Training accuracy: 0.9241528762805359\n",
            "Validation loss: 209.3488437384367\n",
            "Validation accuracy: 0.8112687155240347\n",
            "Epoch 303/599\n",
            "----------\n",
            "Training loss: 158.02739384770393\n",
            "Training accuracy: 0.924645390070922\n",
            "Validation loss: 207.13973005115986\n",
            "Validation accuracy: 0.801812450748621\n",
            "Epoch 304/599\n",
            "----------\n",
            "Training loss: 158.4017908871174\n",
            "Training accuracy: 0.9235618597320725\n",
            "Validation loss: 206.2935205101967\n",
            "Validation accuracy: 0.8100866824271079\n",
            "Epoch 305/599\n",
            "----------\n",
            "Training loss: 158.0632806122303\n",
            "Training accuracy: 0.9254334121355398\n",
            "Validation loss: 200.33843144774437\n",
            "Validation accuracy: 0.83451536643026\n",
            "Epoch 306/599\n",
            "----------\n",
            "Training loss: 157.515720307827\n",
            "Training accuracy: 0.9284869976359338\n",
            "Validation loss: 201.16933545470238\n",
            "Validation accuracy: 0.8384554767533491\n",
            "Epoch 307/599\n",
            "----------\n",
            "Training loss: 156.5399433374405\n",
            "Training accuracy: 0.9286840031520882\n",
            "Validation loss: 199.9247749298811\n",
            "Validation accuracy: 0.8321513002364066\n",
            "Epoch 308/599\n",
            "----------\n",
            "Training loss: 157.54777467250824\n",
            "Training accuracy: 0.9273049645390071\n",
            "Validation loss: 208.9196199476719\n",
            "Validation accuracy: 0.8175728920409772\n",
            "Epoch 309/599\n",
            "----------\n",
            "Training loss: 157.54313492774963\n",
            "Training accuracy: 0.9267139479905437\n",
            "Validation loss: 202.73558008670807\n",
            "Validation accuracy: 0.8226950354609929\n",
            "Epoch 310/599\n",
            "----------\n",
            "Training loss: 156.64225754141808\n",
            "Training accuracy: 0.9278959810874704\n",
            "Validation loss: 212.08264607191086\n",
            "Validation accuracy: 0.7966903073286052\n",
            "Epoch 311/599\n",
            "----------\n",
            "Training loss: 157.3926461338997\n",
            "Training accuracy: 0.9278959810874704\n",
            "Validation loss: 198.55364395678043\n",
            "Validation accuracy: 0.8427895981087471\n",
            "Epoch 312/599\n",
            "----------\n",
            "Training loss: 155.60204455256462\n",
            "Training accuracy: 0.929866036249015\n",
            "Validation loss: 206.5120630711317\n",
            "Validation accuracy: 0.8203309692671394\n",
            "Epoch 313/599\n",
            "----------\n",
            "Training loss: 154.7468638420105\n",
            "Training accuracy: 0.929866036249015\n",
            "Validation loss: 201.6379824578762\n",
            "Validation accuracy: 0.83451536643026\n",
            "Epoch 314/599\n",
            "----------\n",
            "Training loss: 156.1387076675892\n",
            "Training accuracy: 0.9283884948778566\n",
            "Validation loss: 199.96719893813133\n",
            "Validation accuracy: 0.8408195429472025\n",
            "Epoch 315/599\n",
            "----------\n",
            "Training loss: 156.80401495099068\n",
            "Training accuracy: 0.9284869976359338\n",
            "Validation loss: 201.07951107621193\n",
            "Validation accuracy: 0.8321513002364066\n",
            "Epoch 316/599\n",
            "----------\n",
            "Training loss: 155.51328578591347\n",
            "Training accuracy: 0.9296690307328606\n",
            "Validation loss: 198.03737071156502\n",
            "Validation accuracy: 0.847123719464145\n",
            "Epoch 317/599\n",
            "----------\n",
            "Training loss: 156.95202705264091\n",
            "Training accuracy: 0.926812450748621\n",
            "Validation loss: 201.85460904240608\n",
            "Validation accuracy: 0.8226950354609929\n",
            "Epoch 318/599\n",
            "----------\n",
            "Training loss: 156.08013287186623\n",
            "Training accuracy: 0.9256304176516943\n",
            "Validation loss: 199.23309375345707\n",
            "Validation accuracy: 0.8360914105594957\n",
            "Epoch 319/599\n",
            "----------\n",
            "Training loss: 154.72751808166504\n",
            "Training accuracy: 0.9293735224586288\n",
            "Validation loss: 199.77847062051296\n",
            "Validation accuracy: 0.8246650906225375\n",
            "Epoch 320/599\n",
            "----------\n",
            "Training loss: 155.80388259887695\n",
            "Training accuracy: 0.9266154452324665\n",
            "Validation loss: 202.67457503080368\n",
            "Validation accuracy: 0.8297872340425532\n",
            "Epoch 321/599\n",
            "----------\n",
            "Training loss: 154.36439967155457\n",
            "Training accuracy: 0.9344956658786446\n",
            "Validation loss: 198.62798845767975\n",
            "Validation accuracy: 0.8313632781717888\n",
            "Epoch 322/599\n",
            "----------\n",
            "Training loss: 155.7239287495613\n",
            "Training accuracy: 0.9275019700551616\n",
            "Validation loss: 200.4478690624237\n",
            "Validation accuracy: 0.8356973995271868\n",
            "Epoch 323/599\n",
            "----------\n",
            "Training loss: 155.47127771377563\n",
            "Training accuracy: 0.9315405831363278\n",
            "Validation loss: 203.38819241523743\n",
            "Validation accuracy: 0.822301024428684\n",
            "Epoch 324/599\n",
            "----------\n",
            "Training loss: 154.32889613509178\n",
            "Training accuracy: 0.9292750197005516\n",
            "Validation loss: 198.33119651675224\n",
            "Validation accuracy: 0.8443656422379827\n",
            "Epoch 325/599\n",
            "----------\n",
            "Training loss: 156.16592076420784\n",
            "Training accuracy: 0.927698975571316\n",
            "Validation loss: 201.39468176662922\n",
            "Validation accuracy: 0.8242710795902285\n",
            "Epoch 326/599\n",
            "----------\n",
            "Training loss: 155.58485972881317\n",
            "Training accuracy: 0.9291765169424744\n",
            "Validation loss: 204.55732260644436\n",
            "Validation accuracy: 0.80575256107171\n",
            "Epoch 327/599\n",
            "----------\n",
            "Training loss: 154.36653578281403\n",
            "Training accuracy: 0.9315405831363278\n",
            "Validation loss: 202.52735921740532\n",
            "Validation accuracy: 0.8120567375886525\n",
            "Epoch 328/599\n",
            "----------\n",
            "Training loss: 153.9919376373291\n",
            "Training accuracy: 0.9303585500394012\n",
            "Validation loss: 212.3127155303955\n",
            "Validation accuracy: 0.8049645390070922\n",
            "Epoch 329/599\n",
            "----------\n",
            "Training loss: 153.92253467440605\n",
            "Training accuracy: 0.9305555555555556\n",
            "Validation loss: 195.61270481348038\n",
            "Validation accuracy: 0.8475177304964538\n",
            "Epoch 330/599\n",
            "----------\n",
            "Training loss: 154.5663096010685\n",
            "Training accuracy: 0.9253349093774625\n",
            "Validation loss: 199.17925538122654\n",
            "Validation accuracy: 0.8321513002364066\n",
            "Epoch 331/599\n",
            "----------\n",
            "Training loss: 153.11307775974274\n",
            "Training accuracy: 0.9331166272655634\n",
            "Validation loss: 196.76126693189144\n",
            "Validation accuracy: 0.846729708431836\n",
            "Epoch 332/599\n",
            "----------\n",
            "Training loss: 152.46286031603813\n",
            "Training accuracy: 0.9323286052009456\n",
            "Validation loss: 197.14847412705421\n",
            "Validation accuracy: 0.8439716312056738\n",
            "Epoch 333/599\n",
            "----------\n",
            "Training loss: 153.27152860164642\n",
            "Training accuracy: 0.9309495665878644\n",
            "Validation loss: 195.7107337117195\n",
            "Validation accuracy: 0.851063829787234\n",
            "Epoch 334/599\n",
            "----------\n",
            "Training loss: 152.89840385317802\n",
            "Training accuracy: 0.9314420803782506\n",
            "Validation loss: 196.32341465353966\n",
            "Validation accuracy: 0.8337273443656422\n",
            "Epoch 335/599\n",
            "----------\n",
            "Training loss: 152.95563328266144\n",
            "Training accuracy: 0.9287825059101655\n",
            "Validation loss: 202.3511894494295\n",
            "Validation accuracy: 0.8341213553979512\n",
            "Epoch 336/599\n",
            "----------\n",
            "Training loss: 154.56439515948296\n",
            "Training accuracy: 0.9267139479905437\n",
            "Validation loss: 198.87029284238815\n",
            "Validation accuracy: 0.8372734436564224\n",
            "Epoch 337/599\n",
            "----------\n",
            "Training loss: 152.8624592423439\n",
            "Training accuracy: 0.9321315996847912\n",
            "Validation loss: 201.21286760270596\n",
            "Validation accuracy: 0.8317572892040977\n",
            "Epoch 338/599\n",
            "----------\n",
            "Training loss: 152.48627230525017\n",
            "Training accuracy: 0.9323286052009456\n",
            "Validation loss: 199.93101547658443\n",
            "Validation accuracy: 0.8242710795902285\n",
            "Epoch 339/599\n",
            "----------\n",
            "Training loss: 152.86531537771225\n",
            "Training accuracy: 0.9309495665878644\n",
            "Validation loss: 199.36630499362946\n",
            "Validation accuracy: 0.8423955870764381\n",
            "Epoch 340/599\n",
            "----------\n",
            "Training loss: 152.4325693845749\n",
            "Training accuracy: 0.9350866824271079\n",
            "Validation loss: 195.6773675084114\n",
            "Validation accuracy: 0.851063829787234\n",
            "Epoch 341/599\n",
            "----------\n",
            "Training loss: 152.15212684869766\n",
            "Training accuracy: 0.9303585500394012\n",
            "Validation loss: 199.3593747317791\n",
            "Validation accuracy: 0.8297872340425532\n",
            "Epoch 342/599\n",
            "----------\n",
            "Training loss: 152.6285322010517\n",
            "Training accuracy: 0.9323286052009456\n",
            "Validation loss: 194.14538103342056\n",
            "Validation accuracy: 0.8408195429472025\n",
            "Epoch 343/599\n",
            "----------\n",
            "Training loss: 151.69206964969635\n",
            "Training accuracy: 0.9310480693459416\n",
            "Validation loss: 196.09090349078178\n",
            "Validation accuracy: 0.8451536643026005\n",
            "Epoch 344/599\n",
            "----------\n",
            "Training loss: 150.45110949873924\n",
            "Training accuracy: 0.9377462568951931\n",
            "Validation loss: 195.48051936924458\n",
            "Validation accuracy: 0.8443656422379827\n",
            "Epoch 345/599\n",
            "----------\n",
            "Training loss: 151.27648413181305\n",
            "Training accuracy: 0.9349881796690307\n",
            "Validation loss: 197.45790749788284\n",
            "Validation accuracy: 0.8215130023640662\n",
            "Epoch 346/599\n",
            "----------\n",
            "Training loss: 150.99607500433922\n",
            "Training accuracy: 0.9345941686367218\n",
            "Validation loss: 197.87753619253635\n",
            "Validation accuracy: 0.8297872340425532\n",
            "Epoch 347/599\n",
            "----------\n",
            "Training loss: 151.02116578817368\n",
            "Training accuracy: 0.9356776989755713\n",
            "Validation loss: 196.4258030205965\n",
            "Validation accuracy: 0.8325453112687156\n",
            "Epoch 348/599\n",
            "----------\n",
            "Training loss: 150.8305163383484\n",
            "Training accuracy: 0.9348896769109535\n",
            "Validation loss: 195.1000416725874\n",
            "Validation accuracy: 0.8423955870764381\n",
            "Epoch 349/599\n",
            "----------\n",
            "Training loss: 150.92749497294426\n",
            "Training accuracy: 0.9331166272655634\n",
            "Validation loss: 193.75949701666832\n",
            "Validation accuracy: 0.8463356973995272\n",
            "Epoch 350/599\n",
            "----------\n",
            "Training loss: 149.42699497938156\n",
            "Training accuracy: 0.9361702127659575\n",
            "Validation loss: 191.31736707687378\n",
            "Validation accuracy: 0.8506698187549251\n",
            "Epoch 351/599\n",
            "----------\n",
            "Training loss: 150.3010269701481\n",
            "Training accuracy: 0.9367612293144209\n",
            "Validation loss: 198.8799715936184\n",
            "Validation accuracy: 0.8333333333333334\n",
            "Epoch 352/599\n",
            "----------\n",
            "Training loss: 150.26314797997475\n",
            "Training accuracy: 0.9352836879432624\n",
            "Validation loss: 198.7123483121395\n",
            "Validation accuracy: 0.8258471237194641\n",
            "Epoch 353/599\n",
            "----------\n",
            "Training loss: 150.44802936911583\n",
            "Training accuracy: 0.9377462568951931\n",
            "Validation loss: 202.07718129456043\n",
            "Validation accuracy: 0.8120567375886525\n",
            "Epoch 354/599\n",
            "----------\n",
            "Training loss: 150.146954536438\n",
            "Training accuracy: 0.9339046493301812\n",
            "Validation loss: 195.11483405530453\n",
            "Validation accuracy: 0.8376674546887313\n",
            "Epoch 355/599\n",
            "----------\n",
            "Training loss: 148.72101873159409\n",
            "Training accuracy: 0.9370567375886525\n",
            "Validation loss: 197.10226050019264\n",
            "Validation accuracy: 0.83451536643026\n",
            "Epoch 356/599\n",
            "----------\n",
            "Training loss: 149.79176905751228\n",
            "Training accuracy: 0.9364657210401891\n",
            "Validation loss: 192.55655604600906\n",
            "Validation accuracy: 0.8526398739164697\n",
            "Epoch 357/599\n",
            "----------\n",
            "Training loss: 149.54446059465408\n",
            "Training accuracy: 0.9346926713947991\n",
            "Validation loss: 195.91056941449642\n",
            "Validation accuracy: 0.8341213553979512\n",
            "Epoch 358/599\n",
            "----------\n",
            "Training loss: 149.23942789435387\n",
            "Training accuracy: 0.9342001576044129\n",
            "Validation loss: 192.60489593446255\n",
            "Validation accuracy: 0.8514578408195429\n",
            "Epoch 359/599\n",
            "----------\n",
            "Training loss: 150.16814202070236\n",
            "Training accuracy: 0.9349881796690307\n",
            "Validation loss: 197.33288253843784\n",
            "Validation accuracy: 0.8443656422379827\n",
            "Epoch 360/599\n",
            "----------\n",
            "Training loss: 148.42413878440857\n",
            "Training accuracy: 0.9382387706855791\n",
            "Validation loss: 192.25036619603634\n",
            "Validation accuracy: 0.8494877856579984\n",
            "Epoch 361/599\n",
            "----------\n",
            "Training loss: 147.66337111592293\n",
            "Training accuracy: 0.9395193065405831\n",
            "Validation loss: 189.65423776209354\n",
            "Validation accuracy: 0.8506698187549251\n",
            "Epoch 362/599\n",
            "----------\n",
            "Training loss: 148.6678196489811\n",
            "Training accuracy: 0.9335106382978723\n",
            "Validation loss: 198.03055407106876\n",
            "Validation accuracy: 0.8250591016548463\n",
            "Epoch 363/599\n",
            "----------\n",
            "Training loss: 149.5191788971424\n",
            "Training accuracy: 0.9306540583136328\n",
            "Validation loss: 202.90472534298897\n",
            "Validation accuracy: 0.8124507486209613\n",
            "Epoch 364/599\n",
            "----------\n",
            "Training loss: 146.61237767338753\n",
            "Training accuracy: 0.942966903073286\n",
            "Validation loss: 189.9182828962803\n",
            "Validation accuracy: 0.8486997635933806\n",
            "Epoch 365/599\n",
            "----------\n",
            "Training loss: 147.2469785809517\n",
            "Training accuracy: 0.9376477541371159\n",
            "Validation loss: 189.06536538898945\n",
            "Validation accuracy: 0.8617021276595744\n",
            "Epoch 366/599\n",
            "----------\n",
            "Training loss: 148.81873840093613\n",
            "Training accuracy: 0.9358747044917257\n",
            "Validation loss: 194.92156602442265\n",
            "Validation accuracy: 0.8396375098502759\n",
            "Epoch 367/599\n",
            "----------\n",
            "Training loss: 147.54588228464127\n",
            "Training accuracy: 0.9367612293144209\n",
            "Validation loss: 189.11278884112835\n",
            "Validation accuracy: 0.8585500394011032\n",
            "Epoch 368/599\n",
            "----------\n",
            "Training loss: 145.85376343131065\n",
            "Training accuracy: 0.9423758865248227\n",
            "Validation loss: 190.42315869033337\n",
            "Validation accuracy: 0.8443656422379827\n",
            "Epoch 369/599\n",
            "----------\n",
            "Training loss: 146.4522576034069\n",
            "Training accuracy: 0.9381402679275019\n",
            "Validation loss: 196.36859811842442\n",
            "Validation accuracy: 0.8238770685579196\n",
            "Epoch 370/599\n",
            "----------\n",
            "Training loss: 147.54173961281776\n",
            "Training accuracy: 0.9367612293144209\n",
            "Validation loss: 198.49324184656143\n",
            "Validation accuracy: 0.8104806934594169\n",
            "Epoch 371/599\n",
            "----------\n",
            "Training loss: 147.96796265244484\n",
            "Training accuracy: 0.9364657210401891\n",
            "Validation loss: 199.1339530646801\n",
            "Validation accuracy: 0.8136327817178881\n",
            "Epoch 372/599\n",
            "----------\n",
            "Training loss: 147.0185231566429\n",
            "Training accuracy: 0.9410953506698188\n",
            "Validation loss: 200.26721838116646\n",
            "Validation accuracy: 0.8234830575256107\n",
            "Epoch 373/599\n",
            "----------\n",
            "Training loss: 146.86819624900818\n",
            "Training accuracy: 0.9393223010244287\n",
            "Validation loss: 202.63703927397728\n",
            "Validation accuracy: 0.8112687155240347\n",
            "Epoch 374/599\n",
            "----------\n",
            "Training loss: 147.60085874795914\n",
            "Training accuracy: 0.9352836879432624\n",
            "Validation loss: 194.0954334884882\n",
            "Validation accuracy: 0.8353033884948778\n",
            "Epoch 375/599\n",
            "----------\n",
            "Training loss: 146.01165661215782\n",
            "Training accuracy: 0.9404058313632782\n",
            "Validation loss: 186.4827294945717\n",
            "Validation accuracy: 0.8581560283687943\n",
            "Epoch 376/599\n",
            "----------\n",
            "Training loss: 145.83316105604172\n",
            "Training accuracy: 0.9389282899921197\n",
            "Validation loss: 199.6902185678482\n",
            "Validation accuracy: 0.8274231678486997\n",
            "Epoch 377/599\n",
            "----------\n",
            "Training loss: 146.32371813058853\n",
            "Training accuracy: 0.9373522458628841\n",
            "Validation loss: 188.98569859564304\n",
            "Validation accuracy: 0.8561859732072498\n",
            "Epoch 378/599\n",
            "----------\n",
            "Training loss: 144.89697143435478\n",
            "Training accuracy: 0.9410953506698188\n",
            "Validation loss: 209.67023907601833\n",
            "Validation accuracy: 0.8006304176516943\n",
            "Epoch 379/599\n",
            "----------\n",
            "Training loss: 145.71802639961243\n",
            "Training accuracy: 0.9406028368794326\n",
            "Validation loss: 188.01826414465904\n",
            "Validation accuracy: 0.8613081166272656\n",
            "Epoch 380/599\n",
            "----------\n",
            "Training loss: 144.9754374921322\n",
            "Training accuracy: 0.941193853427896\n",
            "Validation loss: 184.17833942174911\n",
            "Validation accuracy: 0.8656422379826635\n",
            "Epoch 381/599\n",
            "----------\n",
            "Training loss: 146.23838180303574\n",
            "Training accuracy: 0.9370567375886525\n",
            "Validation loss: 184.49645203351974\n",
            "Validation accuracy: 0.8660362490149724\n",
            "Epoch 382/599\n",
            "----------\n",
            "Training loss: 146.06370708346367\n",
            "Training accuracy: 0.9385342789598109\n",
            "Validation loss: 195.45326307415962\n",
            "Validation accuracy: 0.83451536643026\n",
            "Epoch 383/599\n",
            "----------\n",
            "Training loss: 144.5397138595581\n",
            "Training accuracy: 0.9425728920409772\n",
            "Validation loss: 192.05675967037678\n",
            "Validation accuracy: 0.8301812450748621\n",
            "Epoch 384/599\n",
            "----------\n",
            "Training loss: 144.15060749650002\n",
            "Training accuracy: 0.9443459416863672\n",
            "Validation loss: 187.19553230702877\n",
            "Validation accuracy: 0.8609141055949566\n",
            "Epoch 385/599\n",
            "----------\n",
            "Training loss: 144.29545870423317\n",
            "Training accuracy: 0.9402088258471237\n",
            "Validation loss: 189.48588137328625\n",
            "Validation accuracy: 0.8490937746256895\n",
            "Epoch 386/599\n",
            "----------\n",
            "Training loss: 143.63153555989265\n",
            "Training accuracy: 0.9425728920409772\n",
            "Validation loss: 191.70619501173496\n",
            "Validation accuracy: 0.8396375098502759\n",
            "Epoch 387/599\n",
            "----------\n",
            "Training loss: 144.63766661286354\n",
            "Training accuracy: 0.9404058313632782\n",
            "Validation loss: 185.86718606948853\n",
            "Validation accuracy: 0.8644602048857368\n",
            "Epoch 388/599\n",
            "----------\n",
            "Training loss: 143.60920622944832\n",
            "Training accuracy: 0.9414893617021277\n",
            "Validation loss: 197.0603949725628\n",
            "Validation accuracy: 0.8238770685579196\n",
            "Epoch 389/599\n",
            "----------\n",
            "Training loss: 145.18989342451096\n",
            "Training accuracy: 0.9367612293144209\n",
            "Validation loss: 187.45340029895306\n",
            "Validation accuracy: 0.8546099290780141\n",
            "Epoch 390/599\n",
            "----------\n",
            "Training loss: 143.168527841568\n",
            "Training accuracy: 0.942966903073286\n",
            "Validation loss: 187.16862961649895\n",
            "Validation accuracy: 0.8620961386918834\n",
            "Epoch 391/599\n",
            "----------\n",
            "Training loss: 142.92518147826195\n",
            "Training accuracy: 0.9436564223798266\n",
            "Validation loss: 186.5427819788456\n",
            "Validation accuracy: 0.8668242710795903\n",
            "Epoch 392/599\n",
            "----------\n",
            "Training loss: 143.42571398615837\n",
            "Training accuracy: 0.9425728920409772\n",
            "Validation loss: 189.52135713398457\n",
            "Validation accuracy: 0.8514578408195429\n",
            "Epoch 393/599\n",
            "----------\n",
            "Training loss: 143.60910072922707\n",
            "Training accuracy: 0.9422773837667455\n",
            "Validation loss: 190.16495659947395\n",
            "Validation accuracy: 0.8333333333333334\n",
            "Epoch 394/599\n",
            "----------\n",
            "Training loss: 142.71305605769157\n",
            "Training accuracy: 0.9417848699763594\n",
            "Validation loss: 192.06871362030506\n",
            "Validation accuracy: 0.8420015760441293\n",
            "Epoch 395/599\n",
            "----------\n",
            "Training loss: 142.36239805817604\n",
            "Training accuracy: 0.9435579196217494\n",
            "Validation loss: 186.36044785380363\n",
            "Validation accuracy: 0.8644602048857368\n",
            "Epoch 396/599\n",
            "----------\n",
            "Training loss: 141.45723715424538\n",
            "Training accuracy: 0.9454294720252167\n",
            "Validation loss: 187.14368823170662\n",
            "Validation accuracy: 0.8439716312056738\n",
            "Epoch 397/599\n",
            "----------\n",
            "Training loss: 141.5924764573574\n",
            "Training accuracy: 0.9439519306540584\n",
            "Validation loss: 184.8366259932518\n",
            "Validation accuracy: 0.8605200945626478\n",
            "Epoch 398/599\n",
            "----------\n",
            "Training loss: 143.0229727625847\n",
            "Training accuracy: 0.9399133175728921\n",
            "Validation loss: 187.2982388138771\n",
            "Validation accuracy: 0.8451536643026005\n",
            "Epoch 399/599\n",
            "----------\n",
            "Training loss: 141.8571091592312\n",
            "Training accuracy: 0.9453309692671394\n",
            "Validation loss: 183.50969402492046\n",
            "Validation accuracy: 0.8672182821118991\n",
            "Epoch 400/599\n",
            "----------\n",
            "Training loss: 141.71962812542915\n",
            "Training accuracy: 0.9431639085894405\n",
            "Validation loss: 192.6953006386757\n",
            "Validation accuracy: 0.838849487785658\n",
            "Epoch 401/599\n",
            "----------\n",
            "Training loss: 141.47020810842514\n",
            "Training accuracy: 0.9445429472025216\n",
            "Validation loss: 188.7031005769968\n",
            "Validation accuracy: 0.8483057525610717\n",
            "Epoch 402/599\n",
            "----------\n",
            "Training loss: 140.20398220419884\n",
            "Training accuracy: 0.9474980299448384\n",
            "Validation loss: 183.43942135572433\n",
            "Validation accuracy: 0.8672182821118991\n",
            "Epoch 403/599\n",
            "----------\n",
            "Training loss: 140.8877914249897\n",
            "Training accuracy: 0.9445429472025216\n",
            "Validation loss: 183.44079540669918\n",
            "Validation accuracy: 0.855397951142632\n",
            "Epoch 404/599\n",
            "----------\n",
            "Training loss: 141.289407402277\n",
            "Training accuracy: 0.94424743892829\n",
            "Validation loss: 196.5662284195423\n",
            "Validation accuracy: 0.8175728920409772\n",
            "Epoch 405/599\n",
            "----------\n",
            "Training loss: 141.18534275889397\n",
            "Training accuracy: 0.9468085106382979\n",
            "Validation loss: 182.98462168872356\n",
            "Validation accuracy: 0.8605200945626478\n",
            "Epoch 406/599\n",
            "----------\n",
            "Training loss: 141.4266799390316\n",
            "Training accuracy: 0.9404058313632782\n",
            "Validation loss: 190.0822670161724\n",
            "Validation accuracy: 0.8502758077226162\n",
            "Epoch 407/599\n",
            "----------\n",
            "Training loss: 140.65493428707123\n",
            "Training accuracy: 0.9462174940898345\n",
            "Validation loss: 184.17599348723888\n",
            "Validation accuracy: 0.8644602048857368\n",
            "Epoch 408/599\n",
            "----------\n",
            "Training loss: 142.27565157413483\n",
            "Training accuracy: 0.9399133175728921\n",
            "Validation loss: 188.10160186886787\n",
            "Validation accuracy: 0.8573680063041765\n",
            "Epoch 409/599\n",
            "----------\n",
            "Training loss: 138.56588345766068\n",
            "Training accuracy: 0.9498620961386919\n",
            "Validation loss: 185.89984951913357\n",
            "Validation accuracy: 0.8581560283687943\n",
            "Epoch 410/599\n",
            "----------\n",
            "Training loss: 140.18168523907661\n",
            "Training accuracy: 0.945527974783294\n",
            "Validation loss: 191.90079081058502\n",
            "Validation accuracy: 0.8364854215918046\n",
            "Epoch 411/599\n",
            "----------\n",
            "Training loss: 139.9962118268013\n",
            "Training accuracy: 0.9434594168636722\n",
            "Validation loss: 186.24549305438995\n",
            "Validation accuracy: 0.8577620173364854\n",
            "Epoch 412/599\n",
            "----------\n",
            "Training loss: 140.39068180322647\n",
            "Training accuracy: 0.9445429472025216\n",
            "Validation loss: 182.53549541532993\n",
            "Validation accuracy: 0.8711583924349882\n",
            "Epoch 413/599\n",
            "----------\n",
            "Training loss: 138.86058163642883\n",
            "Training accuracy: 0.9493695823483057\n",
            "Validation loss: 181.59190541505814\n",
            "Validation accuracy: 0.8664302600472813\n",
            "Epoch 414/599\n",
            "----------\n",
            "Training loss: 138.76856356859207\n",
            "Training accuracy: 0.9492710795902285\n",
            "Validation loss: 184.22307592630386\n",
            "Validation accuracy: 0.8632781717888101\n",
            "Epoch 415/599\n",
            "----------\n",
            "Training loss: 138.94296616315842\n",
            "Training accuracy: 0.9478920409771474\n",
            "Validation loss: 183.54900996387005\n",
            "Validation accuracy: 0.8648542159180457\n",
            "Epoch 416/599\n",
            "----------\n",
            "Training loss: 138.115639179945\n",
            "Training accuracy: 0.9491725768321513\n",
            "Validation loss: 181.18388122320175\n",
            "Validation accuracy: 0.871946414499606\n",
            "Epoch 417/599\n",
            "----------\n",
            "Training loss: 138.42751601338387\n",
            "Training accuracy: 0.9488770685579196\n",
            "Validation loss: 183.67366859316826\n",
            "Validation accuracy: 0.8624901497241922\n",
            "Epoch 418/599\n",
            "----------\n",
            "Training loss: 139.10518383979797\n",
            "Training accuracy: 0.9480890464933018\n",
            "Validation loss: 180.56115636229515\n",
            "Validation accuracy: 0.8723404255319149\n",
            "Epoch 419/599\n",
            "----------\n",
            "Training loss: 137.45749592781067\n",
            "Training accuracy: 0.9498620961386919\n",
            "Validation loss: 183.92959807813168\n",
            "Validation accuracy: 0.8577620173364854\n",
            "Epoch 420/599\n",
            "----------\n",
            "Training loss: 137.8652022778988\n",
            "Training accuracy: 0.9473995271867612\n",
            "Validation loss: 183.78183762729168\n",
            "Validation accuracy: 0.8632781717888101\n",
            "Epoch 421/599\n",
            "----------\n",
            "Training loss: 137.91450548171997\n",
            "Training accuracy: 0.9478920409771474\n",
            "Validation loss: 183.0135597139597\n",
            "Validation accuracy: 0.8628841607565012\n",
            "Epoch 422/599\n",
            "----------\n",
            "Training loss: 138.95648783445358\n",
            "Training accuracy: 0.9447399527186762\n",
            "Validation loss: 183.35543824732304\n",
            "Validation accuracy: 0.855397951142632\n",
            "Epoch 423/599\n",
            "----------\n",
            "Training loss: 136.80480107665062\n",
            "Training accuracy: 0.9510441292356187\n",
            "Validation loss: 187.82200267910957\n",
            "Validation accuracy: 0.8455476753349094\n",
            "Epoch 424/599\n",
            "----------\n",
            "Training loss: 136.89550065994263\n",
            "Training accuracy: 0.950354609929078\n",
            "Validation loss: 181.96532249450684\n",
            "Validation accuracy: 0.875886524822695\n",
            "Epoch 425/599\n",
            "----------\n",
            "Training loss: 138.27279925346375\n",
            "Training accuracy: 0.9502561071710008\n",
            "Validation loss: 178.81303165853024\n",
            "Validation accuracy: 0.8672182821118991\n",
            "Epoch 426/599\n",
            "----------\n",
            "Training loss: 137.86255651712418\n",
            "Training accuracy: 0.9484830575256107\n",
            "Validation loss: 183.04099518060684\n",
            "Validation accuracy: 0.8624901497241922\n",
            "Epoch 427/599\n",
            "----------\n",
            "Training loss: 137.8246130645275\n",
            "Training accuracy: 0.947301024428684\n",
            "Validation loss: 178.6990745216608\n",
            "Validation accuracy: 0.8770685579196218\n",
            "Epoch 428/599\n",
            "----------\n",
            "Training loss: 136.15161871910095\n",
            "Training accuracy: 0.9521276595744681\n",
            "Validation loss: 178.93144264817238\n",
            "Validation accuracy: 0.8652482269503546\n",
            "Epoch 429/599\n",
            "----------\n",
            "Training loss: 135.88353565335274\n",
            "Training accuracy: 0.9501576044129235\n",
            "Validation loss: 181.0689553320408\n",
            "Validation accuracy: 0.8644602048857368\n",
            "Epoch 430/599\n",
            "----------\n",
            "Training loss: 135.5090297460556\n",
            "Training accuracy: 0.9521276595744681\n",
            "Validation loss: 179.30592696368694\n",
            "Validation accuracy: 0.8664302600472813\n",
            "Epoch 431/599\n",
            "----------\n",
            "Training loss: 136.51816511154175\n",
            "Training accuracy: 0.9487785657998424\n",
            "Validation loss: 183.203725785017\n",
            "Validation accuracy: 0.8664302600472813\n",
            "Epoch 432/599\n",
            "----------\n",
            "Training loss: 135.84745121002197\n",
            "Training accuracy: 0.9501576044129235\n",
            "Validation loss: 186.54632692039013\n",
            "Validation accuracy: 0.8459416863672183\n",
            "Epoch 433/599\n",
            "----------\n",
            "Training loss: 136.06027191877365\n",
            "Training accuracy: 0.952521670606777\n",
            "Validation loss: 180.98771534860134\n",
            "Validation accuracy: 0.855397951142632\n",
            "Epoch 434/599\n",
            "----------\n",
            "Training loss: 137.49910354614258\n",
            "Training accuracy: 0.9490740740740741\n",
            "Validation loss: 189.19268669188023\n",
            "Validation accuracy: 0.8420015760441293\n",
            "Epoch 435/599\n",
            "----------\n",
            "Training loss: 137.11132737994194\n",
            "Training accuracy: 0.9469070133963751\n",
            "Validation loss: 179.37633864581585\n",
            "Validation accuracy: 0.8782505910165485\n",
            "Epoch 436/599\n",
            "----------\n",
            "Training loss: 135.91334128379822\n",
            "Training accuracy: 0.9501576044129235\n",
            "Validation loss: 177.88849680125713\n",
            "Validation accuracy: 0.8747044917257684\n",
            "Epoch 437/599\n",
            "----------\n",
            "Training loss: 135.49690708518028\n",
            "Training accuracy: 0.9504531126871553\n",
            "Validation loss: 182.79144071042538\n",
            "Validation accuracy: 0.8506698187549251\n",
            "Epoch 438/599\n",
            "----------\n",
            "Training loss: 134.2962931394577\n",
            "Training accuracy: 0.9549842395587076\n",
            "Validation loss: 176.21147529780865\n",
            "Validation accuracy: 0.8798266351457841\n",
            "Epoch 439/599\n",
            "----------\n",
            "Training loss: 135.96643748879433\n",
            "Training accuracy: 0.9499605988967691\n",
            "Validation loss: 186.76076005399227\n",
            "Validation accuracy: 0.8506698187549251\n",
            "Epoch 440/599\n",
            "----------\n",
            "Training loss: 135.77230370044708\n",
            "Training accuracy: 0.9508471237194641\n",
            "Validation loss: 178.28638096153736\n",
            "Validation accuracy: 0.876280535855004\n",
            "Epoch 441/599\n",
            "----------\n",
            "Training loss: 135.2572572529316\n",
            "Training accuracy: 0.9545902285263987\n",
            "Validation loss: 182.0367888957262\n",
            "Validation accuracy: 0.8542159180457053\n",
            "Epoch 442/599\n",
            "----------\n",
            "Training loss: 135.3934482038021\n",
            "Training accuracy: 0.9490740740740741\n",
            "Validation loss: 177.8336592465639\n",
            "Validation accuracy: 0.8786446020488574\n",
            "Epoch 443/599\n",
            "----------\n",
            "Training loss: 134.10967755317688\n",
            "Training accuracy: 0.9544917257683215\n",
            "Validation loss: 176.84400540590286\n",
            "Validation accuracy: 0.8833727344365643\n",
            "Epoch 444/599\n",
            "----------\n",
            "Training loss: 135.26839539408684\n",
            "Training accuracy: 0.953408195429472\n",
            "Validation loss: 177.44500863552094\n",
            "Validation accuracy: 0.8814026792750197\n",
            "Epoch 445/599\n",
            "----------\n",
            "Training loss: 135.08169105648994\n",
            "Training accuracy: 0.9485815602836879\n",
            "Validation loss: 178.87140448391438\n",
            "Validation accuracy: 0.875886524822695\n",
            "Epoch 446/599\n",
            "----------\n",
            "Training loss: 133.37591060996056\n",
            "Training accuracy: 0.9545902285263987\n",
            "Validation loss: 177.9675455391407\n",
            "Validation accuracy: 0.8774625689519306\n",
            "Epoch 447/599\n",
            "----------\n",
            "Training loss: 133.20532527565956\n",
            "Training accuracy: 0.9528171788810087\n",
            "Validation loss: 174.93188513815403\n",
            "Validation accuracy: 0.8794326241134752\n",
            "Epoch 448/599\n",
            "----------\n",
            "Training loss: 133.41412419080734\n",
            "Training accuracy: 0.9512411347517731\n",
            "Validation loss: 174.1842495650053\n",
            "Validation accuracy: 0.8865248226950354\n",
            "Epoch 449/599\n",
            "----------\n",
            "Training loss: 133.60185649991035\n",
            "Training accuracy: 0.9531126871552403\n",
            "Validation loss: 179.03802025318146\n",
            "Validation accuracy: 0.8684003152088259\n",
            "Epoch 450/599\n",
            "----------\n",
            "Training loss: 132.7588317990303\n",
            "Training accuracy: 0.9558707643814027\n",
            "Validation loss: 180.63153198361397\n",
            "Validation accuracy: 0.8707643814026793\n",
            "Epoch 451/599\n",
            "----------\n",
            "Training loss: 133.8441841006279\n",
            "Training accuracy: 0.9539992119779354\n",
            "Validation loss: 182.13626177608967\n",
            "Validation accuracy: 0.8396375098502759\n",
            "Epoch 452/599\n",
            "----------\n",
            "Training loss: 133.1220920085907\n",
            "Training accuracy: 0.9541962174940898\n",
            "Validation loss: 177.29824142158031\n",
            "Validation accuracy: 0.8778565799842396\n",
            "Epoch 453/599\n",
            "----------\n",
            "Training loss: 132.14236426353455\n",
            "Training accuracy: 0.9580378250591016\n",
            "Validation loss: 182.38236938416958\n",
            "Validation accuracy: 0.8514578408195429\n",
            "Epoch 454/599\n",
            "----------\n",
            "Training loss: 132.32646158337593\n",
            "Training accuracy: 0.9539007092198581\n",
            "Validation loss: 181.26897226274014\n",
            "Validation accuracy: 0.8680063041765169\n",
            "Epoch 455/599\n",
            "----------\n",
            "Training loss: 132.183647274971\n",
            "Training accuracy: 0.953408195429472\n",
            "Validation loss: 177.297218978405\n",
            "Validation accuracy: 0.8750985027580772\n",
            "Epoch 456/599\n",
            "----------\n",
            "Training loss: 130.9106494486332\n",
            "Training accuracy: 0.9575453112687156\n",
            "Validation loss: 184.68011686205864\n",
            "Validation accuracy: 0.8329393223010244\n",
            "Epoch 457/599\n",
            "----------\n",
            "Training loss: 131.89776441454887\n",
            "Training accuracy: 0.9538022064617809\n",
            "Validation loss: 182.0044246017933\n",
            "Validation accuracy: 0.8447596532702916\n",
            "Epoch 458/599\n",
            "----------\n",
            "Training loss: 133.67241713404655\n",
            "Training accuracy: 0.9530141843971631\n",
            "Validation loss: 186.94039753079414\n",
            "Validation accuracy: 0.8246650906225375\n",
            "Epoch 459/599\n",
            "----------\n",
            "Training loss: 131.67285741865635\n",
            "Training accuracy: 0.9575453112687156\n",
            "Validation loss: 173.24653185904026\n",
            "Validation accuracy: 0.8825847123719465\n",
            "Epoch 460/599\n",
            "----------\n",
            "Training loss: 132.01213279366493\n",
            "Training accuracy: 0.9535066981875493\n",
            "Validation loss: 175.28287261724472\n",
            "Validation accuracy: 0.8750985027580772\n",
            "Epoch 461/599\n",
            "----------\n",
            "Training loss: 130.9600682258606\n",
            "Training accuracy: 0.9572498029944838\n",
            "Validation loss: 176.63895684480667\n",
            "Validation accuracy: 0.8810086682427108\n",
            "Epoch 462/599\n",
            "----------\n",
            "Training loss: 132.04238295555115\n",
            "Training accuracy: 0.9544917257683215\n",
            "Validation loss: 175.19488011300564\n",
            "Validation accuracy: 0.8873128447596532\n",
            "Epoch 463/599\n",
            "----------\n",
            "Training loss: 131.6388374567032\n",
            "Training accuracy: 0.9560677698975572\n",
            "Validation loss: 179.02740389108658\n",
            "Validation accuracy: 0.8648542159180457\n",
            "Epoch 464/599\n",
            "----------\n",
            "Training loss: 131.4017971456051\n",
            "Training accuracy: 0.9563632781717888\n",
            "Validation loss: 175.62221205234528\n",
            "Validation accuracy: 0.8806146572104019\n",
            "Epoch 465/599\n",
            "----------\n",
            "Training loss: 131.03879594802856\n",
            "Training accuracy: 0.9549842395587076\n",
            "Validation loss: 180.48916998505592\n",
            "Validation accuracy: 0.8546099290780141\n",
            "Epoch 466/599\n",
            "----------\n",
            "Training loss: 131.31100741028786\n",
            "Training accuracy: 0.9530141843971631\n",
            "Validation loss: 175.65737879276276\n",
            "Validation accuracy: 0.8589440504334122\n",
            "Epoch 467/599\n",
            "----------\n",
            "Training loss: 130.51809525489807\n",
            "Training accuracy: 0.9566587864460205\n",
            "Validation loss: 176.26564748585224\n",
            "Validation accuracy: 0.8668242710795903\n",
            "Epoch 468/599\n",
            "----------\n",
            "Training loss: 130.58069491386414\n",
            "Training accuracy: 0.9566587864460205\n",
            "Validation loss: 183.51330749690533\n",
            "Validation accuracy: 0.8534278959810875\n",
            "Epoch 469/599\n",
            "----------\n",
            "Training loss: 130.60694298148155\n",
            "Training accuracy: 0.9556737588652482\n",
            "Validation loss: 176.17230221629143\n",
            "Validation accuracy: 0.8754925137903862\n",
            "Epoch 470/599\n",
            "----------\n",
            "Training loss: 130.35797703266144\n",
            "Training accuracy: 0.9575453112687156\n",
            "Validation loss: 173.2792646586895\n",
            "Validation accuracy: 0.8853427895981087\n",
            "Epoch 471/599\n",
            "----------\n",
            "Training loss: 130.83535706996918\n",
            "Training accuracy: 0.9554767533490938\n",
            "Validation loss: 172.83904360234737\n",
            "Validation accuracy: 0.8845547675334909\n",
            "Epoch 472/599\n",
            "----------\n",
            "Training loss: 129.54874283075333\n",
            "Training accuracy: 0.9567572892040977\n",
            "Validation loss: 174.7951751500368\n",
            "Validation accuracy: 0.8691883372734437\n",
            "Epoch 473/599\n",
            "----------\n",
            "Training loss: 130.52519953250885\n",
            "Training accuracy: 0.9575453112687156\n",
            "Validation loss: 174.16059578955173\n",
            "Validation accuracy: 0.8845547675334909\n",
            "Epoch 474/599\n",
            "----------\n",
            "Training loss: 130.93967521190643\n",
            "Training accuracy: 0.9522261623325453\n",
            "Validation loss: 170.99258218705654\n",
            "Validation accuracy: 0.8857368006304176\n",
            "Epoch 475/599\n",
            "----------\n",
            "Training loss: 128.21775457262993\n",
            "Training accuracy: 0.9606973995271868\n",
            "Validation loss: 174.21827918291092\n",
            "Validation accuracy: 0.8703703703703703\n",
            "Epoch 476/599\n",
            "----------\n",
            "Training loss: 130.32865819334984\n",
            "Training accuracy: 0.9562647754137116\n",
            "Validation loss: 173.54236947000027\n",
            "Validation accuracy: 0.8865248226950354\n",
            "Epoch 477/599\n",
            "----------\n",
            "Training loss: 129.60466492176056\n",
            "Training accuracy: 0.959909377462569\n",
            "Validation loss: 174.19785423576832\n",
            "Validation accuracy: 0.8754925137903862\n",
            "Epoch 478/599\n",
            "----------\n",
            "Training loss: 129.97803622484207\n",
            "Training accuracy: 0.954688731284476\n",
            "Validation loss: 173.7245563864708\n",
            "Validation accuracy: 0.8731284475965327\n",
            "Epoch 479/599\n",
            "----------\n",
            "Training loss: 129.34636601805687\n",
            "Training accuracy: 0.9587273443656422\n",
            "Validation loss: 177.0766500234604\n",
            "Validation accuracy: 0.8613081166272656\n",
            "Epoch 480/599\n",
            "----------\n",
            "Training loss: 129.08603289723396\n",
            "Training accuracy: 0.95774231678487\n",
            "Validation loss: 172.320162281394\n",
            "Validation accuracy: 0.8778565799842396\n",
            "Epoch 481/599\n",
            "----------\n",
            "Training loss: 128.71625912189484\n",
            "Training accuracy: 0.9578408195429472\n",
            "Validation loss: 174.5028430968523\n",
            "Validation accuracy: 0.8739164696611506\n",
            "Epoch 482/599\n",
            "----------\n",
            "Training loss: 128.2837851345539\n",
            "Training accuracy: 0.9603033884948778\n",
            "Validation loss: 174.1389427036047\n",
            "Validation accuracy: 0.871946414499606\n",
            "Epoch 483/599\n",
            "----------\n",
            "Training loss: 129.26323944330215\n",
            "Training accuracy: 0.9538022064617809\n",
            "Validation loss: 172.79691262543201\n",
            "Validation accuracy: 0.8782505910165485\n",
            "Epoch 484/599\n",
            "----------\n",
            "Training loss: 127.37954896688461\n",
            "Training accuracy: 0.9615839243498818\n",
            "Validation loss: 169.35364291071892\n",
            "Validation accuracy: 0.8967691095350669\n",
            "Epoch 485/599\n",
            "----------\n",
            "Training loss: 127.76088678836823\n",
            "Training accuracy: 0.9627659574468085\n",
            "Validation loss: 168.27831204235554\n",
            "Validation accuracy: 0.8999211977935382\n",
            "Epoch 486/599\n",
            "----------\n",
            "Training loss: 127.01237457990646\n",
            "Training accuracy: 0.9593183609141056\n",
            "Validation loss: 169.54368436336517\n",
            "Validation accuracy: 0.8845547675334909\n",
            "Epoch 487/599\n",
            "----------\n",
            "Training loss: 128.3227921128273\n",
            "Training accuracy: 0.9605003940110323\n",
            "Validation loss: 173.39011271297932\n",
            "Validation accuracy: 0.8837667454688731\n",
            "Epoch 488/599\n",
            "----------\n",
            "Training loss: 128.3437382131815\n",
            "Training accuracy: 0.9584318360914106\n",
            "Validation loss: 169.48175109922886\n",
            "Validation accuracy: 0.8896769109535066\n",
            "Epoch 489/599\n",
            "----------\n",
            "Training loss: 127.85563695430756\n",
            "Training accuracy: 0.9575453112687156\n",
            "Validation loss: 175.90226013958454\n",
            "Validation accuracy: 0.8648542159180457\n",
            "Epoch 490/599\n",
            "----------\n",
            "Training loss: 127.85211232304573\n",
            "Training accuracy: 0.9596138691883372\n",
            "Validation loss: 172.25573100149632\n",
            "Validation accuracy: 0.8841607565011821\n",
            "Epoch 491/599\n",
            "----------\n",
            "Training loss: 127.90939888358116\n",
            "Training accuracy: 0.9589243498817966\n",
            "Validation loss: 175.57452341914177\n",
            "Validation accuracy: 0.8550039401103231\n",
            "Epoch 492/599\n",
            "----------\n",
            "Training loss: 128.06029868125916\n",
            "Training accuracy: 0.9582348305752562\n",
            "Validation loss: 172.7674060165882\n",
            "Validation accuracy: 0.8766745468873128\n",
            "Epoch 493/599\n",
            "----------\n",
            "Training loss: 128.78869742155075\n",
            "Training accuracy: 0.9561662726556344\n",
            "Validation loss: 173.53171019256115\n",
            "Validation accuracy: 0.8656422379826635\n",
            "Epoch 494/599\n",
            "----------\n",
            "Training loss: 127.03547763824463\n",
            "Training accuracy: 0.9598108747044918\n",
            "Validation loss: 168.96184591948986\n",
            "Validation accuracy: 0.8845547675334909\n",
            "Epoch 495/599\n",
            "----------\n",
            "Training loss: 126.78965750336647\n",
            "Training accuracy: 0.9600078802206462\n",
            "Validation loss: 170.47885255515575\n",
            "Validation accuracy: 0.8821907013396375\n",
            "Epoch 496/599\n",
            "----------\n",
            "Training loss: 126.95011991262436\n",
            "Training accuracy: 0.9608944050433412\n",
            "Validation loss: 173.37908858060837\n",
            "Validation accuracy: 0.8774625689519306\n",
            "Epoch 497/599\n",
            "----------\n",
            "Training loss: 127.29810965061188\n",
            "Training accuracy: 0.9598108747044918\n",
            "Validation loss: 168.48496960103512\n",
            "Validation accuracy: 0.8900709219858156\n",
            "Epoch 498/599\n",
            "----------\n",
            "Training loss: 126.78909632563591\n",
            "Training accuracy: 0.960795902285264\n",
            "Validation loss: 182.87502923607826\n",
            "Validation accuracy: 0.8254531126871553\n",
            "Epoch 499/599\n",
            "----------\n",
            "Training loss: 125.88021698594093\n",
            "Training accuracy: 0.9618794326241135\n",
            "Validation loss: 176.89603479206562\n",
            "Validation accuracy: 0.8668242710795903\n",
            "Epoch 500/599\n",
            "----------\n",
            "Training loss: 127.22306144237518\n",
            "Training accuracy: 0.95951536643026\n",
            "Validation loss: 170.33124923706055\n",
            "Validation accuracy: 0.8829787234042553\n",
            "Epoch 501/599\n",
            "----------\n",
            "Training loss: 126.09951934218407\n",
            "Training accuracy: 0.9602048857368006\n",
            "Validation loss: 170.5899163633585\n",
            "Validation accuracy: 0.8873128447596532\n",
            "Epoch 502/599\n",
            "----------\n",
            "Training loss: 127.92798236012459\n",
            "Training accuracy: 0.9552797478329393\n",
            "Validation loss: 168.1561494320631\n",
            "Validation accuracy: 0.8912529550827423\n",
            "Epoch 503/599\n",
            "----------\n",
            "Training loss: 126.69850879907608\n",
            "Training accuracy: 0.9617809298660362\n",
            "Validation loss: 171.19651921093464\n",
            "Validation accuracy: 0.888100866824271\n",
            "Epoch 504/599\n",
            "----------\n",
            "Training loss: 124.76660200953484\n",
            "Training accuracy: 0.9628644602048857\n",
            "Validation loss: 168.62309615314007\n",
            "Validation accuracy: 0.8951930654058313\n",
            "Epoch 505/599\n",
            "----------\n",
            "Training loss: 126.80748552083969\n",
            "Training accuracy: 0.956461780929866\n",
            "Validation loss: 172.47299475967884\n",
            "Validation accuracy: 0.8747044917257684\n",
            "Epoch 506/599\n",
            "----------\n",
            "Training loss: 125.27683961391449\n",
            "Training accuracy: 0.9614854215918046\n",
            "Validation loss: 173.09164732694626\n",
            "Validation accuracy: 0.871946414499606\n",
            "Epoch 507/599\n",
            "----------\n",
            "Training loss: 125.66931945085526\n",
            "Training accuracy: 0.9608944050433412\n",
            "Validation loss: 169.94133587181568\n",
            "Validation accuracy: 0.8849487785657998\n",
            "Epoch 508/599\n",
            "----------\n",
            "Training loss: 125.67439517378807\n",
            "Training accuracy: 0.959022852639874\n",
            "Validation loss: 173.53900948166847\n",
            "Validation accuracy: 0.8810086682427108\n",
            "Epoch 509/599\n",
            "----------\n",
            "Training loss: 124.74162793159485\n",
            "Training accuracy: 0.9642434988179669\n",
            "Validation loss: 170.42055355012417\n",
            "Validation accuracy: 0.8841607565011821\n",
            "Epoch 510/599\n",
            "----------\n",
            "Training loss: 125.16718226671219\n",
            "Training accuracy: 0.9612884160756501\n",
            "Validation loss: 182.41667072474957\n",
            "Validation accuracy: 0.8412135539795115\n",
            "Epoch 511/599\n",
            "----------\n",
            "Training loss: 126.26236289739609\n",
            "Training accuracy: 0.9594168636721828\n",
            "Validation loss: 165.5034753382206\n",
            "Validation accuracy: 0.9014972419227738\n",
            "Epoch 512/599\n",
            "----------\n",
            "Training loss: 124.41678044199944\n",
            "Training accuracy: 0.959909377462569\n",
            "Validation loss: 166.60741712152958\n",
            "Validation accuracy: 0.8869188337273444\n",
            "Epoch 513/599\n",
            "----------\n",
            "Training loss: 123.88207006454468\n",
            "Training accuracy: 0.9657210401891253\n",
            "Validation loss: 165.62316508591175\n",
            "Validation accuracy: 0.8892828999211978\n",
            "Epoch 514/599\n",
            "----------\n",
            "Training loss: 124.94857558608055\n",
            "Training accuracy: 0.9620764381402679\n",
            "Validation loss: 170.3376125395298\n",
            "Validation accuracy: 0.8841607565011821\n",
            "Epoch 515/599\n",
            "----------\n",
            "Training loss: 124.62900054454803\n",
            "Training accuracy: 0.9605988967691096\n",
            "Validation loss: 167.49256201088428\n",
            "Validation accuracy: 0.8877068557919622\n",
            "Epoch 516/599\n",
            "----------\n",
            "Training loss: 124.53731408715248\n",
            "Training accuracy: 0.9608944050433412\n",
            "Validation loss: 171.0337709635496\n",
            "Validation accuracy: 0.8743104806934594\n",
            "Epoch 517/599\n",
            "----------\n",
            "Training loss: 125.66287223994732\n",
            "Training accuracy: 0.959022852639874\n",
            "Validation loss: 167.82420717179775\n",
            "Validation accuracy: 0.8810086682427108\n",
            "Epoch 518/599\n",
            "----------\n",
            "Training loss: 125.03271368145943\n",
            "Training accuracy: 0.9596138691883372\n",
            "Validation loss: 164.36981339752674\n",
            "Validation accuracy: 0.88849487785658\n",
            "Epoch 519/599\n",
            "----------\n",
            "Training loss: 123.42173701524734\n",
            "Training accuracy: 0.9653270291568163\n",
            "Validation loss: 171.6818000227213\n",
            "Validation accuracy: 0.876280535855004\n",
            "Epoch 520/599\n",
            "----------\n",
            "Training loss: 123.93754360079765\n",
            "Training accuracy: 0.9624704491725768\n",
            "Validation loss: 165.22340305149555\n",
            "Validation accuracy: 0.8967691095350669\n",
            "Epoch 521/599\n",
            "----------\n",
            "Training loss: 122.85101667046547\n",
            "Training accuracy: 0.9668045705279747\n",
            "Validation loss: 171.09654019773006\n",
            "Validation accuracy: 0.8766745468873128\n",
            "Epoch 522/599\n",
            "----------\n",
            "Training loss: 123.98694917559624\n",
            "Training accuracy: 0.9643420015760441\n",
            "Validation loss: 166.33209942281246\n",
            "Validation accuracy: 0.8865248226950354\n",
            "Epoch 523/599\n",
            "----------\n",
            "Training loss: 125.09547090530396\n",
            "Training accuracy: 0.9605003940110323\n",
            "Validation loss: 170.49382863938808\n",
            "Validation accuracy: 0.8782505910165485\n",
            "Epoch 524/599\n",
            "----------\n",
            "Training loss: 124.02997681498528\n",
            "Training accuracy: 0.9644405043341213\n",
            "Validation loss: 169.8516816943884\n",
            "Validation accuracy: 0.8849487785657998\n",
            "Epoch 525/599\n",
            "----------\n",
            "Training loss: 123.6542287915945\n",
            "Training accuracy: 0.9648345153664303\n",
            "Validation loss: 167.9894973486662\n",
            "Validation accuracy: 0.8896769109535066\n",
            "Epoch 526/599\n",
            "----------\n",
            "Training loss: 124.01433598995209\n",
            "Training accuracy: 0.9609929078014184\n",
            "Validation loss: 168.85049480199814\n",
            "Validation accuracy: 0.8770685579196218\n",
            "Epoch 527/599\n",
            "----------\n",
            "Training loss: 123.60065920650959\n",
            "Training accuracy: 0.9625689519306541\n",
            "Validation loss: 170.94784566760063\n",
            "Validation accuracy: 0.8743104806934594\n",
            "Epoch 528/599\n",
            "----------\n",
            "Training loss: 123.15391626954079\n",
            "Training accuracy: 0.9602048857368006\n",
            "Validation loss: 166.31009462475777\n",
            "Validation accuracy: 0.8995271867612293\n",
            "Epoch 529/599\n",
            "----------\n",
            "Training loss: 123.01877623796463\n",
            "Training accuracy: 0.9653270291568163\n",
            "Validation loss: 169.36673633754253\n",
            "Validation accuracy: 0.8829787234042553\n",
            "Epoch 530/599\n",
            "----------\n",
            "Training loss: 123.2104902267456\n",
            "Training accuracy: 0.9618794326241135\n",
            "Validation loss: 168.05510778725147\n",
            "Validation accuracy: 0.8782505910165485\n",
            "Epoch 531/599\n",
            "----------\n",
            "Training loss: 122.4389680325985\n",
            "Training accuracy: 0.9671985815602837\n",
            "Validation loss: 164.52825343608856\n",
            "Validation accuracy: 0.8971631205673759\n",
            "Epoch 532/599\n",
            "----------\n",
            "Training loss: 122.01869462430477\n",
            "Training accuracy: 0.9677895981087471\n",
            "Validation loss: 165.1564304381609\n",
            "Validation accuracy: 0.8987391646966115\n",
            "Epoch 533/599\n",
            "----------\n",
            "Training loss: 122.1224901676178\n",
            "Training accuracy: 0.9654255319148937\n",
            "Validation loss: 169.1965519040823\n",
            "Validation accuracy: 0.8841607565011821\n",
            "Epoch 534/599\n",
            "----------\n",
            "Training loss: 122.116196423769\n",
            "Training accuracy: 0.9665090622537431\n",
            "Validation loss: 166.47021785378456\n",
            "Validation accuracy: 0.8810086682427108\n",
            "Epoch 535/599\n",
            "----------\n",
            "Training loss: 122.41362380981445\n",
            "Training accuracy: 0.9662135539795115\n",
            "Validation loss: 164.77828307449818\n",
            "Validation accuracy: 0.8904649330181245\n",
            "Epoch 536/599\n",
            "----------\n",
            "Training loss: 121.64644733071327\n",
            "Training accuracy: 0.9686761229314421\n",
            "Validation loss: 168.88198713958263\n",
            "Validation accuracy: 0.8739164696611506\n",
            "Epoch 537/599\n",
            "----------\n",
            "Training loss: 121.19212017953396\n",
            "Training accuracy: 0.9667060677698975\n",
            "Validation loss: 167.52800856530666\n",
            "Validation accuracy: 0.8861308116627266\n",
            "Epoch 538/599\n",
            "----------\n",
            "Training loss: 122.12288001179695\n",
            "Training accuracy: 0.9657210401891253\n",
            "Validation loss: 168.3670390546322\n",
            "Validation accuracy: 0.8912529550827423\n",
            "Epoch 539/599\n",
            "----------\n",
            "Training loss: 121.00989294052124\n",
            "Training accuracy: 0.9665090622537431\n",
            "Validation loss: 167.19241255521774\n",
            "Validation accuracy: 0.8896769109535066\n",
            "Epoch 540/599\n",
            "----------\n",
            "Training loss: 121.10566285252571\n",
            "Training accuracy: 0.9676910953506698\n",
            "Validation loss: 170.04195392131805\n",
            "Validation accuracy: 0.8782505910165485\n",
            "Epoch 541/599\n",
            "----------\n",
            "Training loss: 121.08136388659477\n",
            "Training accuracy: 0.9665090622537431\n",
            "Validation loss: 165.35541075468063\n",
            "Validation accuracy: 0.8869188337273444\n",
            "Epoch 542/599\n",
            "----------\n",
            "Training loss: 121.00825071334839\n",
            "Training accuracy: 0.9671000788022065\n",
            "Validation loss: 166.430508852005\n",
            "Validation accuracy: 0.8944050433412135\n",
            "Epoch 543/599\n",
            "----------\n",
            "Training loss: 121.60190451145172\n",
            "Training accuracy: 0.9656225374310481\n",
            "Validation loss: 163.9595287144184\n",
            "Validation accuracy: 0.8971631205673759\n",
            "Epoch 544/599\n",
            "----------\n",
            "Training loss: 119.60118073225021\n",
            "Training accuracy: 0.9692671394799054\n",
            "Validation loss: 170.63510525226593\n",
            "Validation accuracy: 0.8644602048857368\n",
            "Epoch 545/599\n",
            "----------\n",
            "Training loss: 120.29871481657028\n",
            "Training accuracy: 0.9667060677698975\n",
            "Validation loss: 163.95581567287445\n",
            "Validation accuracy: 0.900709219858156\n",
            "Epoch 546/599\n",
            "----------\n",
            "Training loss: 120.10312648117542\n",
            "Training accuracy: 0.9662135539795115\n",
            "Validation loss: 168.31659318506718\n",
            "Validation accuracy: 0.8727344365642238\n",
            "Epoch 547/599\n",
            "----------\n",
            "Training loss: 121.83303661644459\n",
            "Training accuracy: 0.9634554767533491\n",
            "Validation loss: 169.92862124741077\n",
            "Validation accuracy: 0.8798266351457841\n",
            "Epoch 548/599\n",
            "----------\n",
            "Training loss: 118.71551299095154\n",
            "Training accuracy: 0.969956658786446\n",
            "Validation loss: 162.74657994508743\n",
            "Validation accuracy: 0.8955870764381403\n",
            "Epoch 549/599\n",
            "----------\n",
            "Training loss: 120.74846091866493\n",
            "Training accuracy: 0.9671985815602837\n",
            "Validation loss: 167.54881265759468\n",
            "Validation accuracy: 0.8912529550827423\n",
            "Epoch 550/599\n",
            "----------\n",
            "Training loss: 119.52987933158875\n",
            "Training accuracy: 0.9695626477541371\n",
            "Validation loss: 164.46876202523708\n",
            "Validation accuracy: 0.8951930654058313\n",
            "Epoch 551/599\n",
            "----------\n",
            "Training loss: 119.77571633458138\n",
            "Training accuracy: 0.9691686367218282\n",
            "Validation loss: 166.79331082105637\n",
            "Validation accuracy: 0.8766745468873128\n",
            "Epoch 552/599\n",
            "----------\n",
            "Training loss: 121.01689553260803\n",
            "Training accuracy: 0.9648345153664303\n",
            "Validation loss: 168.17475166916847\n",
            "Validation accuracy: 0.8814026792750197\n",
            "Epoch 553/599\n",
            "----------\n",
            "Training loss: 119.34092152118683\n",
            "Training accuracy: 0.9692671394799054\n",
            "Validation loss: 166.0255352705717\n",
            "Validation accuracy: 0.8853427895981087\n",
            "Epoch 554/599\n",
            "----------\n",
            "Training loss: 119.67231191694736\n",
            "Training accuracy: 0.9685776201733649\n",
            "Validation loss: 164.57176081836224\n",
            "Validation accuracy: 0.8912529550827423\n",
            "Epoch 555/599\n",
            "----------\n",
            "Training loss: 120.21668282151222\n",
            "Training accuracy: 0.9664105594956659\n",
            "Validation loss: 164.184659704566\n",
            "Validation accuracy: 0.8782505910165485\n",
            "Epoch 556/599\n",
            "----------\n",
            "Training loss: 119.64784073829651\n",
            "Training accuracy: 0.9665090622537431\n",
            "Validation loss: 162.71926660835743\n",
            "Validation accuracy: 0.892434988179669\n",
            "Epoch 557/599\n",
            "----------\n",
            "Training loss: 120.74662777781487\n",
            "Training accuracy: 0.966903073286052\n",
            "Validation loss: 160.83516769111156\n",
            "Validation accuracy: 0.901103230890465\n",
            "Epoch 558/599\n",
            "----------\n",
            "Training loss: 120.53982543945312\n",
            "Training accuracy: 0.9650315208825847\n",
            "Validation loss: 163.66876745224\n",
            "Validation accuracy: 0.892434988179669\n",
            "Epoch 559/599\n",
            "----------\n",
            "Training loss: 118.3490501344204\n",
            "Training accuracy: 0.9724192277383766\n",
            "Validation loss: 163.9525783956051\n",
            "Validation accuracy: 0.8912529550827423\n",
            "Epoch 560/599\n",
            "----------\n",
            "Training loss: 119.46989242732525\n",
            "Training accuracy: 0.9691686367218282\n",
            "Validation loss: 163.52804201841354\n",
            "Validation accuracy: 0.8979511426319937\n",
            "Epoch 561/599\n",
            "----------\n",
            "Training loss: 119.94554995000362\n",
            "Training accuracy: 0.968183609141056\n",
            "Validation loss: 162.18026338517666\n",
            "Validation accuracy: 0.9070133963750985\n",
            "Epoch 562/599\n",
            "----------\n",
            "Training loss: 118.60213503241539\n",
            "Training accuracy: 0.9707446808510638\n",
            "Validation loss: 169.72350144386292\n",
            "Validation accuracy: 0.8727344365642238\n",
            "Epoch 563/599\n",
            "----------\n",
            "Training loss: 119.40935611724854\n",
            "Training accuracy: 0.9700551615445232\n",
            "Validation loss: 166.50838436186314\n",
            "Validation accuracy: 0.8849487785657998\n",
            "Epoch 564/599\n",
            "----------\n",
            "Training loss: 118.71966898441315\n",
            "Training accuracy: 0.9673955870764381\n",
            "Validation loss: 165.05083948373795\n",
            "Validation accuracy: 0.888100866824271\n",
            "Epoch 565/599\n",
            "----------\n",
            "Training loss: 118.28482896089554\n",
            "Training accuracy: 0.9683806146572104\n",
            "Validation loss: 161.303425475955\n",
            "Validation accuracy: 0.9018912529550828\n",
            "Epoch 566/599\n",
            "----------\n",
            "Training loss: 118.70939832925797\n",
            "Training accuracy: 0.9686761229314421\n",
            "Validation loss: 162.35738299787045\n",
            "Validation accuracy: 0.9030732860520094\n",
            "Epoch 567/599\n",
            "----------\n",
            "Training loss: 118.83070217072964\n",
            "Training accuracy: 0.9686761229314421\n",
            "Validation loss: 158.6159994751215\n",
            "Validation accuracy: 0.9070133963750985\n",
            "Epoch 568/599\n",
            "----------\n",
            "Training loss: 117.40011098980904\n",
            "Training accuracy: 0.9679866036249015\n",
            "Validation loss: 169.0982265919447\n",
            "Validation accuracy: 0.875886524822695\n",
            "Epoch 569/599\n",
            "----------\n",
            "Training loss: 118.79095712304115\n",
            "Training accuracy: 0.9696611505122144\n",
            "Validation loss: 165.41201801598072\n",
            "Validation accuracy: 0.8798266351457841\n",
            "Epoch 570/599\n",
            "----------\n",
            "Training loss: 117.30224800109863\n",
            "Training accuracy: 0.968183609141056\n",
            "Validation loss: 161.75240376591682\n",
            "Validation accuracy: 0.8963750985027581\n",
            "Epoch 571/599\n",
            "----------\n",
            "Training loss: 117.4814101755619\n",
            "Training accuracy: 0.9711386918833728\n",
            "Validation loss: 169.62887187302113\n",
            "Validation accuracy: 0.8644602048857368\n",
            "Epoch 572/599\n",
            "----------\n",
            "Training loss: 117.60422487556934\n",
            "Training accuracy: 0.970350669818755\n",
            "Validation loss: 166.635717228055\n",
            "Validation accuracy: 0.8849487785657998\n",
            "Epoch 573/599\n",
            "----------\n",
            "Training loss: 117.9432101547718\n",
            "Training accuracy: 0.9677895981087471\n",
            "Validation loss: 162.0469161272049\n",
            "Validation accuracy: 0.8908589440504334\n",
            "Epoch 574/599\n",
            "----------\n",
            "Training loss: 118.10883116722107\n",
            "Training accuracy: 0.9673955870764381\n",
            "Validation loss: 160.39494687318802\n",
            "Validation accuracy: 0.901103230890465\n",
            "Epoch 575/599\n",
            "----------\n",
            "Training loss: 118.79048585891724\n",
            "Training accuracy: 0.9676910953506698\n",
            "Validation loss: 160.1902922540903\n",
            "Validation accuracy: 0.904649330181245\n",
            "Epoch 576/599\n",
            "----------\n",
            "Training loss: 118.09609976410866\n",
            "Training accuracy: 0.9691686367218282\n",
            "Validation loss: 160.76295112073421\n",
            "Validation accuracy: 0.8987391646966115\n",
            "Epoch 577/599\n",
            "----------\n",
            "Training loss: 115.8837898671627\n",
            "Training accuracy: 0.9723207249802994\n",
            "Validation loss: 170.21061186492443\n",
            "Validation accuracy: 0.8707643814026793\n",
            "Epoch 578/599\n",
            "----------\n",
            "Training loss: 116.57217293977737\n",
            "Training accuracy: 0.9714342001576044\n",
            "Validation loss: 164.87946727871895\n",
            "Validation accuracy: 0.8837667454688731\n",
            "Epoch 579/599\n",
            "----------\n",
            "Training loss: 116.21881340444088\n",
            "Training accuracy: 0.9713356973995272\n",
            "Validation loss: 160.4646074473858\n",
            "Validation accuracy: 0.900709219858156\n",
            "Epoch 580/599\n",
            "----------\n",
            "Training loss: 117.25072444975376\n",
            "Training accuracy: 0.9709416863672183\n",
            "Validation loss: 162.25448894500732\n",
            "Validation accuracy: 0.8814026792750197\n",
            "Epoch 581/599\n",
            "----------\n",
            "Training loss: 117.78777286410332\n",
            "Training accuracy: 0.9688731284475965\n",
            "Validation loss: 159.33378161489964\n",
            "Validation accuracy: 0.9113475177304965\n",
            "Epoch 582/599\n",
            "----------\n",
            "Training loss: 116.27852994203568\n",
            "Training accuracy: 0.971729708431836\n",
            "Validation loss: 163.2079713344574\n",
            "Validation accuracy: 0.8963750985027581\n",
            "Epoch 583/599\n",
            "----------\n",
            "Training loss: 117.01729698479176\n",
            "Training accuracy: 0.97123719464145\n",
            "Validation loss: 165.42285306751728\n",
            "Validation accuracy: 0.892434988179669\n",
            "Epoch 584/599\n",
            "----------\n",
            "Training loss: 116.50771822035313\n",
            "Training accuracy: 0.9714342001576044\n",
            "Validation loss: 158.4894377142191\n",
            "Validation accuracy: 0.9058313632781718\n",
            "Epoch 585/599\n",
            "----------\n",
            "Training loss: 116.79948368668556\n",
            "Training accuracy: 0.9710401891252955\n",
            "Validation loss: 161.71454086899757\n",
            "Validation accuracy: 0.8916469661150512\n",
            "Epoch 586/599\n",
            "----------\n",
            "Training loss: 116.50700387358665\n",
            "Training accuracy: 0.97123719464145\n",
            "Validation loss: 167.50738462805748\n",
            "Validation accuracy: 0.8873128447596532\n",
            "Epoch 587/599\n",
            "----------\n",
            "Training loss: 117.19802650809288\n",
            "Training accuracy: 0.9695626477541371\n",
            "Validation loss: 164.93064035475254\n",
            "Validation accuracy: 0.8829787234042553\n",
            "Epoch 588/599\n",
            "----------\n",
            "Training loss: 116.99429523944855\n",
            "Training accuracy: 0.9665090622537431\n",
            "Validation loss: 158.93216466903687\n",
            "Validation accuracy: 0.9062253743104807\n",
            "Epoch 589/599\n",
            "----------\n",
            "Training loss: 116.85513386130333\n",
            "Training accuracy: 0.9710401891252955\n",
            "Validation loss: 161.66779586672783\n",
            "Validation accuracy: 0.892434988179669\n",
            "Epoch 590/599\n",
            "----------\n",
            "Training loss: 117.18125839531422\n",
            "Training accuracy: 0.969070133963751\n",
            "Validation loss: 167.66588066518307\n",
            "Validation accuracy: 0.8782505910165485\n",
            "Epoch 591/599\n",
            "----------\n",
            "Training loss: 116.57842734456062\n",
            "Training accuracy: 0.9710401891252955\n",
            "Validation loss: 158.88496893644333\n",
            "Validation accuracy: 0.9026792750197006\n",
            "Epoch 592/599\n",
            "----------\n",
            "Training loss: 116.43788632750511\n",
            "Training accuracy: 0.9713356973995272\n",
            "Validation loss: 160.04617117345333\n",
            "Validation accuracy: 0.9003152088258471\n",
            "Epoch 593/599\n",
            "----------\n",
            "Training loss: 114.91826002299786\n",
            "Training accuracy: 0.9716312056737588\n",
            "Validation loss: 162.16221196949482\n",
            "Validation accuracy: 0.8888888888888888\n",
            "Epoch 594/599\n",
            "----------\n",
            "Training loss: 115.09499441087246\n",
            "Training accuracy: 0.973404255319149\n",
            "Validation loss: 160.72544640302658\n",
            "Validation accuracy: 0.8987391646966115\n",
            "Epoch 595/599\n",
            "----------\n",
            "Training loss: 114.1037253588438\n",
            "Training accuracy: 0.9741922773837668\n",
            "Validation loss: 157.73168356716633\n",
            "Validation accuracy: 0.9109535066981875\n",
            "Epoch 596/599\n",
            "----------\n",
            "Training loss: 115.34859521687031\n",
            "Training accuracy: 0.9706461780929866\n",
            "Validation loss: 159.916859716177\n",
            "Validation accuracy: 0.9034672970843184\n",
            "Epoch 597/599\n",
            "----------\n",
            "Training loss: 116.22640573978424\n",
            "Training accuracy: 0.969956658786446\n",
            "Validation loss: 159.92002944648266\n",
            "Validation accuracy: 0.8975571315996848\n",
            "Epoch 598/599\n",
            "----------\n",
            "Training loss: 115.20905143022537\n",
            "Training accuracy: 0.9705476753349094\n",
            "Validation loss: 159.32293625175953\n",
            "Validation accuracy: 0.8975571315996848\n",
            "Epoch 599/599\n",
            "----------\n",
            "Training loss: 115.96913474798203\n",
            "Training accuracy: 0.9711386918833728\n",
            "Validation loss: 159.1123557537794\n",
            "Validation accuracy: 0.8975571315996848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVUXzZGuvQe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "a762d6eb-2043-4292-b229-c908580cc51f"
      },
      "source": [
        "# Plotting the training and validation history\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(v_a)\n",
        "plt.plot(range(epoch),t_a)\n",
        "plt.plot(range(epoch),v_a)\n",
        "plt.title('ShallowConv model accuracy with num_samples = 500')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(range(epoch),t_l)\n",
        "plt.plot(range(epoch),v_l)\n",
        "plt.title('ShallowConv model loss with num_samples = 500')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.2777777777777778, 0.2970843183609141, 0.3073286052009456, 0.3195429472025217, 0.32978723404255317, 0.34948778565799843, 0.3605200945626478, 0.3731284475965327, 0.3908589440504334, 0.3979511426319937, 0.40583136327817176, 0.4176516942474389, 0.42710795902285265, 0.43656422379826637, 0.44759653270291566, 0.44720252167060676, 0.45547675334909377, 0.4657210401891253, 0.4672970843183609, 0.4661150512214342, 0.47675334909377465, 0.4799054373522459, 0.48187549251379036, 0.4842395587076438, 0.48266351457840817, 0.49724192277383766, 0.49684791174152876, 0.5015760441292356, 0.5031520882584712, 0.49724192277383766, 0.5043341213553979, 0.5070921985815603, 0.5090622537431048, 0.5169424743892829, 0.5197005516154453, 0.5149724192277384, 0.5240346729708432, 0.5224586288416075, 0.5240346729708432, 0.5437352245862884, 0.5370370370370371, 0.5350669818754925, 0.5386130811662726, 0.5472813238770685, 0.5445232466509062, 0.55397951142632, 0.5480693459416863, 0.5614657210401891, 0.5575256107171, 0.5563435776201734, 0.5654058313632782, 0.5634357762017337, 0.5650118203309693, 0.5689519306540584, 0.5732860520094563, 0.5697399527186762, 0.5646178092986603, 0.5811662726556344, 0.5819542947202522, 0.582348305752561, 0.5788022064617809, 0.5973207249802994, 0.586682427107959, 0.5921985815602837, 0.5795902285263987, 0.594956658786446, 0.5957446808510638, 0.5981087470449172, 0.5981087470449172, 0.5973207249802994, 0.598896769109535, 0.6103230890464934, 0.6083530338849488, 0.6055949566587865, 0.611899133175729, 0.6154452324665091, 0.6154452324665091, 0.6103230890464934, 0.6170212765957447, 0.6142631993695824, 0.6339637509850276, 0.6225374310480694, 0.6315996847911741, 0.6335697399527187, 0.636327817178881, 0.6410559495665878, 0.6497241922773838, 0.6146572104018913, 0.6449960598896769, 0.644602048857368, 0.6442080378250591, 0.6544523246650906, 0.6619385342789598, 0.6576044129235619, 0.6623325453112687, 0.6599684791174153, 0.6607565011820331, 0.6674546887312844, 0.6670606776989756, 0.6662726556343578, 0.6792750197005516, 0.6769109535066982, 0.6737588652482269, 0.6513002364066194, 0.6843971631205674, 0.6824271079590228, 0.6863672182821119, 0.6836091410559496, 0.6784869976359338, 0.7005516154452325, 0.6910953506698188, 0.6970055161544523, 0.6828211189913318, 0.6973995271867612, 0.6946414499605988, 0.7013396375098503, 0.7048857368006304, 0.710795902285264, 0.7100078802206462, 0.7131599684791174, 0.7115839243498818, 0.7151300236406619, 0.7171000788022065, 0.7072498029944838, 0.7115839243498818, 0.7155240346729709, 0.7127659574468085, 0.7194641449960599, 0.7100078802206462, 0.7206461780929866, 0.7171000788022065, 0.7301024428684003, 0.7182821118991332, 0.7328605200945626, 0.7163120567375887, 0.7371946414499606, 0.7375886524822695, 0.719070133963751, 0.7368006304176516, 0.7379826635145784, 0.7391646966115051, 0.7411347517730497, 0.7344365642237982, 0.739558707643814, 0.7486209613869188, 0.7462568951930654, 0.7529550827423168, 0.7431048069345941, 0.7415287628053585, 0.7442868400315209, 0.7407407407407407, 0.7580772261623325, 0.7576832151300237, 0.7580772261623325, 0.7635933806146572, 0.7580772261623325, 0.764775413711584, 0.7580772261623325, 0.7663514578408196, 0.7494089834515366, 0.7730496453900709, 0.7663514578408196, 0.7710795902285263, 0.7628053585500394, 0.760441292356186, 0.7710795902285263, 0.747832939322301, 0.7754137115839244, 0.7667454688731284, 0.7702915681639085, 0.7805358550039401, 0.7801418439716312, 0.7840819542947203, 0.7793538219070134, 0.7821118991331757, 0.7868400315208826, 0.7718676122931442, 0.7852639873916469, 0.7722616233254531, 0.7825059101654847, 0.7880220646178093, 0.7596532702915682, 0.776595744680851, 0.7848699763593381, 0.7856579984239559, 0.7927501970055162, 0.7876280535855004, 0.772655634357762, 0.7903861308116628, 0.7868400315208826, 0.7951142631993696, 0.7880220646178093, 0.797478329393223, 0.8002364066193853, 0.7911741528762806, 0.7750197005516154, 0.7923561859732072, 0.7970843183609141, 0.7978723404255319, 0.8033884948778566, 0.7982663514578409, 0.797478329393223, 0.7986603624901497, 0.7888100866824271, 0.8014184397163121, 0.7962962962962963, 0.7962962962962963, 0.7966903073286052, 0.8041765169424744, 0.7955082742316785, 0.7911741528762806, 0.8112687155240347, 0.8073286052009456, 0.7876280535855004, 0.8065405831363278, 0.80575256107171, 0.7919621749408984, 0.8053585500394012, 0.8096926713947991, 0.8022064617809299, 0.8073286052009456, 0.8026004728132388, 0.8159968479117415, 0.8065405831363278, 0.8053585500394012, 0.7541371158392435, 0.8010244286840031, 0.797478329393223, 0.8014184397163121, 0.817966903073286, 0.8215130023640662, 0.8156028368794326, 0.7994483845547675, 0.8006304176516943, 0.8226950354609929, 0.8120567375886525, 0.8136327817178881, 0.8065405831363278, 0.814026792750197, 0.8191489361702128, 0.8041765169424744, 0.8136327817178881, 0.8136327817178881, 0.8041765169424744, 0.8108747044917257, 0.814026792750197, 0.8081166272655634, 0.8191489361702128, 0.8092986603624901, 0.8116627265563435, 0.8116627265563435, 0.8230890464933018, 0.8234830575256107, 0.8022064617809299, 0.8242710795902285, 0.8238770685579196, 0.8262411347517731, 0.817966903073286, 0.8128447596532703, 0.8100866824271079, 0.7505910165484634, 0.8215130023640662, 0.8171788810086682, 0.8175728920409772, 0.8226950354609929, 0.8132387706855791, 0.7970843183609141, 0.8171788810086682, 0.8148148148148148, 0.8171788810086682, 0.8219070133963751, 0.8234830575256107, 0.7919621749408984, 0.8136327817178881, 0.8226950354609929, 0.8353033884948778, 0.83451536643026, 0.8278171788810087, 0.8167848699763594, 0.8262411347517731, 0.7959022852639874, 0.8100866824271079, 0.8112687155240347, 0.8148148148148148, 0.8266351457840819, 0.8376674546887313, 0.8195429472025216, 0.7876280535855004, 0.8163908589440504, 0.8175728920409772, 0.8274231678486997, 0.7911741528762806, 0.8262411347517731, 0.7754137115839244, 0.8266351457840819, 0.8116627265563435, 0.8372734436564224, 0.818360914105595, 0.8159968479117415, 0.7982663514578409, 0.8053585500394012, 0.7927501970055162, 0.8112687155240347, 0.801812450748621, 0.8100866824271079, 0.83451536643026, 0.8384554767533491, 0.8321513002364066, 0.8175728920409772, 0.8226950354609929, 0.7966903073286052, 0.8427895981087471, 0.8203309692671394, 0.83451536643026, 0.8408195429472025, 0.8321513002364066, 0.847123719464145, 0.8226950354609929, 0.8360914105594957, 0.8246650906225375, 0.8297872340425532, 0.8313632781717888, 0.8356973995271868, 0.822301024428684, 0.8443656422379827, 0.8242710795902285, 0.80575256107171, 0.8120567375886525, 0.8049645390070922, 0.8475177304964538, 0.8321513002364066, 0.846729708431836, 0.8439716312056738, 0.851063829787234, 0.8337273443656422, 0.8341213553979512, 0.8372734436564224, 0.8317572892040977, 0.8242710795902285, 0.8423955870764381, 0.851063829787234, 0.8297872340425532, 0.8408195429472025, 0.8451536643026005, 0.8443656422379827, 0.8215130023640662, 0.8297872340425532, 0.8325453112687156, 0.8423955870764381, 0.8463356973995272, 0.8506698187549251, 0.8333333333333334, 0.8258471237194641, 0.8120567375886525, 0.8376674546887313, 0.83451536643026, 0.8526398739164697, 0.8341213553979512, 0.8514578408195429, 0.8443656422379827, 0.8494877856579984, 0.8506698187549251, 0.8250591016548463, 0.8124507486209613, 0.8486997635933806, 0.8617021276595744, 0.8396375098502759, 0.8585500394011032, 0.8443656422379827, 0.8238770685579196, 0.8104806934594169, 0.8136327817178881, 0.8234830575256107, 0.8112687155240347, 0.8353033884948778, 0.8581560283687943, 0.8274231678486997, 0.8561859732072498, 0.8006304176516943, 0.8613081166272656, 0.8656422379826635, 0.8660362490149724, 0.83451536643026, 0.8301812450748621, 0.8609141055949566, 0.8490937746256895, 0.8396375098502759, 0.8644602048857368, 0.8238770685579196, 0.8546099290780141, 0.8620961386918834, 0.8668242710795903, 0.8514578408195429, 0.8333333333333334, 0.8420015760441293, 0.8644602048857368, 0.8439716312056738, 0.8605200945626478, 0.8451536643026005, 0.8672182821118991, 0.838849487785658, 0.8483057525610717, 0.8672182821118991, 0.855397951142632, 0.8175728920409772, 0.8605200945626478, 0.8502758077226162, 0.8644602048857368, 0.8573680063041765, 0.8581560283687943, 0.8364854215918046, 0.8577620173364854, 0.8711583924349882, 0.8664302600472813, 0.8632781717888101, 0.8648542159180457, 0.871946414499606, 0.8624901497241922, 0.8723404255319149, 0.8577620173364854, 0.8632781717888101, 0.8628841607565012, 0.855397951142632, 0.8455476753349094, 0.875886524822695, 0.8672182821118991, 0.8624901497241922, 0.8770685579196218, 0.8652482269503546, 0.8644602048857368, 0.8664302600472813, 0.8664302600472813, 0.8459416863672183, 0.855397951142632, 0.8420015760441293, 0.8782505910165485, 0.8747044917257684, 0.8506698187549251, 0.8798266351457841, 0.8506698187549251, 0.876280535855004, 0.8542159180457053, 0.8786446020488574, 0.8833727344365643, 0.8814026792750197, 0.875886524822695, 0.8774625689519306, 0.8794326241134752, 0.8865248226950354, 0.8684003152088259, 0.8707643814026793, 0.8396375098502759, 0.8778565799842396, 0.8514578408195429, 0.8680063041765169, 0.8750985027580772, 0.8329393223010244, 0.8447596532702916, 0.8246650906225375, 0.8825847123719465, 0.8750985027580772, 0.8810086682427108, 0.8873128447596532, 0.8648542159180457, 0.8806146572104019, 0.8546099290780141, 0.8589440504334122, 0.8668242710795903, 0.8534278959810875, 0.8754925137903862, 0.8853427895981087, 0.8845547675334909, 0.8691883372734437, 0.8845547675334909, 0.8857368006304176, 0.8703703703703703, 0.8865248226950354, 0.8754925137903862, 0.8731284475965327, 0.8613081166272656, 0.8778565799842396, 0.8739164696611506, 0.871946414499606, 0.8782505910165485, 0.8967691095350669, 0.8999211977935382, 0.8845547675334909, 0.8837667454688731, 0.8896769109535066, 0.8648542159180457, 0.8841607565011821, 0.8550039401103231, 0.8766745468873128, 0.8656422379826635, 0.8845547675334909, 0.8821907013396375, 0.8774625689519306, 0.8900709219858156, 0.8254531126871553, 0.8668242710795903, 0.8829787234042553, 0.8873128447596532, 0.8912529550827423, 0.888100866824271, 0.8951930654058313, 0.8747044917257684, 0.871946414499606, 0.8849487785657998, 0.8810086682427108, 0.8841607565011821, 0.8412135539795115, 0.9014972419227738, 0.8869188337273444, 0.8892828999211978, 0.8841607565011821, 0.8877068557919622, 0.8743104806934594, 0.8810086682427108, 0.88849487785658, 0.876280535855004, 0.8967691095350669, 0.8766745468873128, 0.8865248226950354, 0.8782505910165485, 0.8849487785657998, 0.8896769109535066, 0.8770685579196218, 0.8743104806934594, 0.8995271867612293, 0.8829787234042553, 0.8782505910165485, 0.8971631205673759, 0.8987391646966115, 0.8841607565011821, 0.8810086682427108, 0.8904649330181245, 0.8739164696611506, 0.8861308116627266, 0.8912529550827423, 0.8896769109535066, 0.8782505910165485, 0.8869188337273444, 0.8944050433412135, 0.8971631205673759, 0.8644602048857368, 0.900709219858156, 0.8727344365642238, 0.8798266351457841, 0.8955870764381403, 0.8912529550827423, 0.8951930654058313, 0.8766745468873128, 0.8814026792750197, 0.8853427895981087, 0.8912529550827423, 0.8782505910165485, 0.892434988179669, 0.901103230890465, 0.892434988179669, 0.8912529550827423, 0.8979511426319937, 0.9070133963750985, 0.8727344365642238, 0.8849487785657998, 0.888100866824271, 0.9018912529550828, 0.9030732860520094, 0.9070133963750985, 0.875886524822695, 0.8798266351457841, 0.8963750985027581, 0.8644602048857368, 0.8849487785657998, 0.8908589440504334, 0.901103230890465, 0.904649330181245, 0.8987391646966115, 0.8707643814026793, 0.8837667454688731, 0.900709219858156, 0.8814026792750197, 0.9113475177304965, 0.8963750985027581, 0.892434988179669, 0.9058313632781718, 0.8916469661150512, 0.8873128447596532, 0.8829787234042553, 0.9062253743104807, 0.892434988179669, 0.8782505910165485, 0.9026792750197006, 0.9003152088258471, 0.8888888888888888, 0.8987391646966115, 0.9109535066981875, 0.9034672970843184, 0.8975571315996848, 0.8975571315996848, 0.8975571315996848]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey8BTy9yvQe2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e26f9e2-3e82-4387-8a02-fc0ceb73f544"
      },
      "source": [
        "# Testing the model\n",
        "\n",
        "num_samples_frame = 500\n",
        "stride = 100\n",
        "X_test_win,y_test_win = make_win_data_pipeline(X_test,y_test,num_samples_frame,stride)\n",
        "\n",
        "# Preparing the test dataset\n",
        "X_test_tensor = torch.from_numpy(X_test_win).float().to(device)\n",
        "y_test_tensor = torch.from_numpy(y_test_win).float().long().to(device) \n",
        "    \n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor) \n",
        "    \n",
        "test_data = EEGDataset(test_dataset, transform=None)\n",
        "\n",
        "test_a = test_model(shallow_model,test_data,criterion)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss tensor(1.7838, device='cuda:0')\n",
            "Test accuracy 48.23175319789315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74DOGXZKvQe2"
      },
      "source": [
        "## Training,validating and testing the model with 300 samples per trial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sVNBaP9vQe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5a1119-8dc4-42a8-c354-31e6c9605454"
      },
      "source": [
        "## Preparing the training and validation data\n",
        "\n",
        "num_samples_frame = 300\n",
        "stride = 60\n",
        "X_train_win,y_train_win = make_win_data_pipeline(X_train_valid,y_train_valid,num_samples_frame,stride)\n",
        "\n",
        "print ('Windowed Training/Valid data shape: {}'.format(X_train_win.shape))\n",
        "print ('Windowed Training/Valid label shape: {}'.format(y_train_win.shape))\n",
        "\n",
        "# Converting the numpy data to torch tensors\n",
        "\n",
        "X_train_valid_tensor = torch.from_numpy(X_train_win).float().to(device)\n",
        "y_train_valid_tensor = torch.from_numpy(y_train_win).float().long().to(device) \n",
        "\n",
        "print ('Training/Valid tensor shape: {}'.format(X_train_valid_tensor.shape))\n",
        "print ('Training/Valid target tensor shape: {}'.format(y_train_valid_tensor.shape))\n",
        "\n",
        "init_dataset = TensorDataset(X_train_valid_tensor, y_train_valid_tensor) \n",
        "\n",
        "# Spliting the dataset into training and validation\n",
        "\n",
        "lengths = [int(len(init_dataset)*0.8), int(len(init_dataset)*0.2)] \n",
        "subset_train, subset_val = random_split(init_dataset, lengths) \n",
        "\n",
        "train_data = EEGDataset(subset_train, transform=None)\n",
        "val_data = EEGDataset(subset_val, transform=None)\n",
        "\n",
        "# Constructing the training and validation dataloaders\n",
        "\n",
        "dataloaders = {\n",
        "    'train': torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True, num_workers=0),\n",
        "    'val': torch.utils.data.DataLoader(val_data, batch_size=8, shuffle=False, num_workers=0)\n",
        "}\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Windowed Training/Valid data shape: (25380, 22, 300)\n",
            "Windowed Training/Valid label shape: (25380,)\n",
            "Training/Valid tensor shape: torch.Size([25380, 22, 300])\n",
            "Training/Valid target tensor shape: torch.Size([25380])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdlLTmAvvQe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e81b1c-c4cc-48c5-d14b-17ea67bec35f"
      },
      "source": [
        "# Defining the parameters for model training\n",
        "\n",
        "\n",
        "weight_decay = 0.15  # weight decay to alleviate overfiting\n",
        "shallow_model = ShallowConv(in_channels=1, num_conv_filters=40,num_samples_frame=300,num_eeg_channels=22,classes=4).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(shallow_model.parameters(), lr = 1e-5, weight_decay=weight_decay)\n",
        "epoch=500\n",
        "# Training and validating the model\n",
        "\n",
        "shallow_model,t_l,t_a,v_l,v_a=train_val(shallow_model, optimizer, criterion, num_epochs=epoch)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/499\n",
            "----------\n",
            "Training loss: 899.4559819698334\n",
            "Training accuracy: 0.2649724192277384\n",
            "Validation loss: 886.546524643898\n",
            "Validation accuracy: 0.27698975571316\n",
            "Epoch 1/499\n",
            "----------\n",
            "Training loss: 879.5671920776367\n",
            "Training accuracy: 0.28669227738376674\n",
            "Validation loss: 876.7317409515381\n",
            "Validation accuracy: 0.2929472025216706\n",
            "Epoch 2/499\n",
            "----------\n",
            "Training loss: 869.9990636110306\n",
            "Training accuracy: 0.30629432624113473\n",
            "Validation loss: 870.6666556596756\n",
            "Validation accuracy: 0.30437352245862886\n",
            "Epoch 3/499\n",
            "----------\n",
            "Training loss: 862.591507434845\n",
            "Training accuracy: 0.3182131599684791\n",
            "Validation loss: 863.6851269006729\n",
            "Validation accuracy: 0.3195429472025217\n",
            "Epoch 4/499\n",
            "----------\n",
            "Training loss: 855.5161664485931\n",
            "Training accuracy: 0.33712568951930655\n",
            "Validation loss: 858.0314284563065\n",
            "Validation accuracy: 0.32959022852639874\n",
            "Epoch 5/499\n",
            "----------\n",
            "Training loss: 846.7213417291641\n",
            "Training accuracy: 0.35224586288416077\n",
            "Validation loss: 850.2422803640366\n",
            "Validation accuracy: 0.347123719464145\n",
            "Epoch 6/499\n",
            "----------\n",
            "Training loss: 837.6319081783295\n",
            "Training accuracy: 0.3690898345153664\n",
            "Validation loss: 841.803927063942\n",
            "Validation accuracy: 0.3605200945626478\n",
            "Epoch 7/499\n",
            "----------\n",
            "Training loss: 828.4913729429245\n",
            "Training accuracy: 0.38682033096926716\n",
            "Validation loss: 834.4604389071465\n",
            "Validation accuracy: 0.38081166272655637\n",
            "Epoch 8/499\n",
            "----------\n",
            "Training loss: 818.9421311616898\n",
            "Training accuracy: 0.4016449960598897\n",
            "Validation loss: 826.356302678585\n",
            "Validation accuracy: 0.38987391646966113\n",
            "Epoch 9/499\n",
            "----------\n",
            "Training loss: 810.9916808605194\n",
            "Training accuracy: 0.4091804570527975\n",
            "Validation loss: 818.2188478708267\n",
            "Validation accuracy: 0.3983451536643026\n",
            "Epoch 10/499\n",
            "----------\n",
            "Training loss: 801.2684011459351\n",
            "Training accuracy: 0.423364854215918\n",
            "Validation loss: 811.615027487278\n",
            "Validation accuracy: 0.4083924349881797\n",
            "Epoch 11/499\n",
            "----------\n",
            "Training loss: 793.4627207517624\n",
            "Training accuracy: 0.4325748620961387\n",
            "Validation loss: 803.7846044301987\n",
            "Validation accuracy: 0.42257683215130026\n",
            "Epoch 12/499\n",
            "----------\n",
            "Training loss: 785.2965948581696\n",
            "Training accuracy: 0.442720646178093\n",
            "Validation loss: 799.4660549163818\n",
            "Validation accuracy: 0.42139479905437355\n",
            "Epoch 13/499\n",
            "----------\n",
            "Training loss: 778.1139982938766\n",
            "Training accuracy: 0.4515858944050433\n",
            "Validation loss: 791.0524717569351\n",
            "Validation accuracy: 0.435973207249803\n",
            "Epoch 14/499\n",
            "----------\n",
            "Training loss: 770.9042885303497\n",
            "Training accuracy: 0.4590228526398739\n",
            "Validation loss: 787.0993139743805\n",
            "Validation accuracy: 0.44188337273443656\n",
            "Epoch 15/499\n",
            "----------\n",
            "Training loss: 764.9126752614975\n",
            "Training accuracy: 0.4671985815602837\n",
            "Validation loss: 781.852910220623\n",
            "Validation accuracy: 0.4466115051221434\n",
            "Epoch 16/499\n",
            "----------\n",
            "Training loss: 758.2484594583511\n",
            "Training accuracy: 0.47424152876280534\n",
            "Validation loss: 776.1404087543488\n",
            "Validation accuracy: 0.4517336485421592\n",
            "Epoch 17/499\n",
            "----------\n",
            "Training loss: 752.8053367137909\n",
            "Training accuracy: 0.4787726556343578\n",
            "Validation loss: 771.5117927193642\n",
            "Validation accuracy: 0.45468873128447596\n",
            "Epoch 18/499\n",
            "----------\n",
            "Training loss: 747.0305169224739\n",
            "Training accuracy: 0.48699763593380613\n",
            "Validation loss: 767.2105919718742\n",
            "Validation accuracy: 0.4643420015760441\n",
            "Epoch 19/499\n",
            "----------\n",
            "Training loss: 739.5493912100792\n",
            "Training accuracy: 0.49497635933806144\n",
            "Validation loss: 766.1529052257538\n",
            "Validation accuracy: 0.45488573680063044\n",
            "Epoch 20/499\n",
            "----------\n",
            "Training loss: 734.931048810482\n",
            "Training accuracy: 0.499359732072498\n",
            "Validation loss: 760.451469540596\n",
            "Validation accuracy: 0.4649330181245075\n",
            "Epoch 21/499\n",
            "----------\n",
            "Training loss: 730.3654528856277\n",
            "Training accuracy: 0.5023640661938534\n",
            "Validation loss: 755.3427395224571\n",
            "Validation accuracy: 0.475177304964539\n",
            "Epoch 22/499\n",
            "----------\n",
            "Training loss: 724.0131282806396\n",
            "Training accuracy: 0.5131501182033097\n",
            "Validation loss: 748.5158064365387\n",
            "Validation accuracy: 0.48187549251379036\n",
            "Epoch 23/499\n",
            "----------\n",
            "Training loss: 720.303979575634\n",
            "Training accuracy: 0.5142336485421591\n",
            "Validation loss: 749.5686259269714\n",
            "Validation accuracy: 0.47832939322301027\n",
            "Epoch 24/499\n",
            "----------\n",
            "Training loss: 714.9560806155205\n",
            "Training accuracy: 0.523936170212766\n",
            "Validation loss: 744.5134080052376\n",
            "Validation accuracy: 0.48699763593380613\n",
            "Epoch 25/499\n",
            "----------\n",
            "Training loss: 710.5368409752846\n",
            "Training accuracy: 0.5279747832939322\n",
            "Validation loss: 739.6684055328369\n",
            "Validation accuracy: 0.48955870764381404\n",
            "Epoch 26/499\n",
            "----------\n",
            "Training loss: 704.9834077954292\n",
            "Training accuracy: 0.5299940898345153\n",
            "Validation loss: 731.6535188555717\n",
            "Validation accuracy: 0.49527186761229314\n",
            "Epoch 27/499\n",
            "----------\n",
            "Training loss: 699.8830136656761\n",
            "Training accuracy: 0.5374802994483846\n",
            "Validation loss: 729.4790198206902\n",
            "Validation accuracy: 0.49901497241922776\n",
            "Epoch 28/499\n",
            "----------\n",
            "Training loss: 694.7851551175117\n",
            "Training accuracy: 0.5438829787234043\n",
            "Validation loss: 726.4195687770844\n",
            "Validation accuracy: 0.49645390070921985\n",
            "Epoch 29/499\n",
            "----------\n",
            "Training loss: 690.6096325516701\n",
            "Training accuracy: 0.5470843183609141\n",
            "Validation loss: 721.8598940372467\n",
            "Validation accuracy: 0.49940898345153667\n",
            "Epoch 30/499\n",
            "----------\n",
            "Training loss: 685.4703099131584\n",
            "Training accuracy: 0.5526004728132388\n",
            "Validation loss: 724.6833743453026\n",
            "Validation accuracy: 0.4992119779353822\n",
            "Epoch 31/499\n",
            "----------\n",
            "Training loss: 682.6125947833061\n",
            "Training accuracy: 0.5578211189913318\n",
            "Validation loss: 718.8009845614433\n",
            "Validation accuracy: 0.5078802206461781\n",
            "Epoch 32/499\n",
            "----------\n",
            "Training loss: 678.8174774646759\n",
            "Training accuracy: 0.5545212765957447\n",
            "Validation loss: 712.0149776339531\n",
            "Validation accuracy: 0.5110323089046493\n",
            "Epoch 33/499\n",
            "----------\n",
            "Training loss: 673.9950044751167\n",
            "Training accuracy: 0.5627462568951931\n",
            "Validation loss: 712.2189411520958\n",
            "Validation accuracy: 0.5141843971631206\n",
            "Epoch 34/499\n",
            "----------\n",
            "Training loss: 670.8102373480797\n",
            "Training accuracy: 0.5653073286052009\n",
            "Validation loss: 706.7282371520996\n",
            "Validation accuracy: 0.5173364854215918\n",
            "Epoch 35/499\n",
            "----------\n",
            "Training loss: 665.6846486926079\n",
            "Training accuracy: 0.571414499605989\n",
            "Validation loss: 700.147948205471\n",
            "Validation accuracy: 0.5244286840031521\n",
            "Epoch 36/499\n",
            "----------\n",
            "Training loss: 661.7363646030426\n",
            "Training accuracy: 0.5742218282111899\n",
            "Validation loss: 695.8991354703903\n",
            "Validation accuracy: 0.5262017336485422\n",
            "Epoch 37/499\n",
            "----------\n",
            "Training loss: 657.7055652141571\n",
            "Training accuracy: 0.5787037037037037\n",
            "Validation loss: 693.7996144890785\n",
            "Validation accuracy: 0.5323089046493302\n",
            "Epoch 38/499\n",
            "----------\n",
            "Training loss: 655.1307064890862\n",
            "Training accuracy: 0.5799842395587076\n",
            "Validation loss: 690.235519528389\n",
            "Validation accuracy: 0.5372340425531915\n",
            "Epoch 39/499\n",
            "----------\n",
            "Training loss: 649.668265402317\n",
            "Training accuracy: 0.5851063829787234\n",
            "Validation loss: 685.523556470871\n",
            "Validation accuracy: 0.539598108747045\n",
            "Epoch 40/499\n",
            "----------\n",
            "Training loss: 646.2896332740784\n",
            "Training accuracy: 0.5920508274231678\n",
            "Validation loss: 685.4401231408119\n",
            "Validation accuracy: 0.5411741528762806\n",
            "Epoch 41/499\n",
            "----------\n",
            "Training loss: 642.2699934840202\n",
            "Training accuracy: 0.5940208825847124\n",
            "Validation loss: 682.7564816176891\n",
            "Validation accuracy: 0.5425531914893617\n",
            "Epoch 42/499\n",
            "----------\n",
            "Training loss: 637.9043377637863\n",
            "Training accuracy: 0.5967789598108747\n",
            "Validation loss: 676.758053779602\n",
            "Validation accuracy: 0.5468873128447597\n",
            "Epoch 43/499\n",
            "----------\n",
            "Training loss: 633.9534971117973\n",
            "Training accuracy: 0.6011130811662726\n",
            "Validation loss: 673.4098082482815\n",
            "Validation accuracy: 0.5514184397163121\n",
            "Epoch 44/499\n",
            "----------\n",
            "Training loss: 631.1113365888596\n",
            "Training accuracy: 0.6046099290780141\n",
            "Validation loss: 671.8982301354408\n",
            "Validation accuracy: 0.553585500394011\n",
            "Epoch 45/499\n",
            "----------\n",
            "Training loss: 628.2734862565994\n",
            "Training accuracy: 0.6076635145784082\n",
            "Validation loss: 671.0113890767097\n",
            "Validation accuracy: 0.5522064617809299\n",
            "Epoch 46/499\n",
            "----------\n",
            "Training loss: 623.2670444846153\n",
            "Training accuracy: 0.6101753349093775\n",
            "Validation loss: 662.385567009449\n",
            "Validation accuracy: 0.5709219858156028\n",
            "Epoch 47/499\n",
            "----------\n",
            "Training loss: 618.6593621969223\n",
            "Training accuracy: 0.6138199369582348\n",
            "Validation loss: 662.5571652054787\n",
            "Validation accuracy: 0.5606776989755713\n",
            "Epoch 48/499\n",
            "----------\n",
            "Training loss: 615.3480221033096\n",
            "Training accuracy: 0.6129334121355398\n",
            "Validation loss: 664.3501012325287\n",
            "Validation accuracy: 0.5567375886524822\n",
            "Epoch 49/499\n",
            "----------\n",
            "Training loss: 612.502833545208\n",
            "Training accuracy: 0.6206658786446021\n",
            "Validation loss: 661.1897420287132\n",
            "Validation accuracy: 0.5596926713947991\n",
            "Epoch 50/499\n",
            "----------\n",
            "Training loss: 609.1270151734352\n",
            "Training accuracy: 0.6244089834515366\n",
            "Validation loss: 649.9485419988632\n",
            "Validation accuracy: 0.5829393223010244\n",
            "Epoch 51/499\n",
            "----------\n",
            "Training loss: 605.5589299201965\n",
            "Training accuracy: 0.6316489361702128\n",
            "Validation loss: 647.4052281975746\n",
            "Validation accuracy: 0.5815602836879432\n",
            "Epoch 52/499\n",
            "----------\n",
            "Training loss: 601.5609865188599\n",
            "Training accuracy: 0.6306146572104019\n",
            "Validation loss: 651.4878928661346\n",
            "Validation accuracy: 0.5746650906225375\n",
            "Epoch 53/499\n",
            "----------\n",
            "Training loss: 596.082682967186\n",
            "Training accuracy: 0.6388396375098503\n",
            "Validation loss: 642.7362978458405\n",
            "Validation accuracy: 0.5979117415287628\n",
            "Epoch 54/499\n",
            "----------\n",
            "Training loss: 595.5024600028992\n",
            "Training accuracy: 0.6370665878644602\n",
            "Validation loss: 635.8503004014492\n",
            "Validation accuracy: 0.5977147360126084\n",
            "Epoch 55/499\n",
            "----------\n",
            "Training loss: 588.8600587844849\n",
            "Training accuracy: 0.6453408195429472\n",
            "Validation loss: 635.0727000534534\n",
            "Validation accuracy: 0.6014578408195429\n",
            "Epoch 56/499\n",
            "----------\n",
            "Training loss: 587.2624432444572\n",
            "Training accuracy: 0.6450453112687156\n",
            "Validation loss: 629.4775486886501\n",
            "Validation accuracy: 0.6038219070133963\n",
            "Epoch 57/499\n",
            "----------\n",
            "Training loss: 583.3396049141884\n",
            "Training accuracy: 0.6490839243498818\n",
            "Validation loss: 637.2217475175858\n",
            "Validation accuracy: 0.5884554767533491\n",
            "Epoch 58/499\n",
            "----------\n",
            "Training loss: 580.3675522208214\n",
            "Training accuracy: 0.6546985815602837\n",
            "Validation loss: 629.7260431051254\n",
            "Validation accuracy: 0.5973207249802994\n",
            "Epoch 59/499\n",
            "----------\n",
            "Training loss: 577.2758415341377\n",
            "Training accuracy: 0.6605594956658787\n",
            "Validation loss: 626.8596734106541\n",
            "Validation accuracy: 0.5961386918833728\n",
            "Epoch 60/499\n",
            "----------\n",
            "Training loss: 572.289079785347\n",
            "Training accuracy: 0.6593774625689519\n",
            "Validation loss: 624.530046582222\n",
            "Validation accuracy: 0.6122931442080378\n",
            "Epoch 61/499\n",
            "----------\n",
            "Training loss: 571.0398460626602\n",
            "Training accuracy: 0.6619385342789598\n",
            "Validation loss: 628.3673835098743\n",
            "Validation accuracy: 0.6089440504334122\n",
            "Epoch 62/499\n",
            "----------\n",
            "Training loss: 566.3292611241341\n",
            "Training accuracy: 0.6679964539007093\n",
            "Validation loss: 624.8192111551762\n",
            "Validation accuracy: 0.6065799842395587\n",
            "Epoch 63/499\n",
            "----------\n",
            "Training loss: 562.5104603767395\n",
            "Training accuracy: 0.67400512214342\n",
            "Validation loss: 611.4475102424622\n",
            "Validation accuracy: 0.619779353821907\n",
            "Epoch 64/499\n",
            "----------\n",
            "Training loss: 560.0258237123489\n",
            "Training accuracy: 0.6753841607565012\n",
            "Validation loss: 609.7443168461323\n",
            "Validation accuracy: 0.6184003152088259\n",
            "Epoch 65/499\n",
            "----------\n",
            "Training loss: 558.6087119579315\n",
            "Training accuracy: 0.6742021276595744\n",
            "Validation loss: 613.1659715175629\n",
            "Validation accuracy: 0.6176122931442081\n",
            "Epoch 66/499\n",
            "----------\n",
            "Training loss: 555.0277020931244\n",
            "Training accuracy: 0.6813435776201734\n",
            "Validation loss: 619.3463386595249\n",
            "Validation accuracy: 0.611899133175729\n",
            "Epoch 67/499\n",
            "----------\n",
            "Training loss: 551.2122428417206\n",
            "Training accuracy: 0.6870567375886525\n",
            "Validation loss: 602.4071199893951\n",
            "Validation accuracy: 0.6312056737588653\n",
            "Epoch 68/499\n",
            "----------\n",
            "Training loss: 548.6293024420738\n",
            "Training accuracy: 0.6883372734436565\n",
            "Validation loss: 606.6248398125172\n",
            "Validation accuracy: 0.6286446020488574\n",
            "Epoch 69/499\n",
            "----------\n",
            "Training loss: 544.9961100816727\n",
            "Training accuracy: 0.690553585500394\n",
            "Validation loss: 598.8204921782017\n",
            "Validation accuracy: 0.6341607565011821\n",
            "Epoch 70/499\n",
            "----------\n",
            "Training loss: 544.9880242943764\n",
            "Training accuracy: 0.6917848699763594\n",
            "Validation loss: 603.4386829733849\n",
            "Validation accuracy: 0.6227344365642238\n",
            "Epoch 71/499\n",
            "----------\n",
            "Training loss: 540.039734005928\n",
            "Training accuracy: 0.6975472813238771\n",
            "Validation loss: 596.0736956298351\n",
            "Validation accuracy: 0.6369188337273444\n",
            "Epoch 72/499\n",
            "----------\n",
            "Training loss: 536.802859723568\n",
            "Training accuracy: 0.6996158392434988\n",
            "Validation loss: 597.6664289832115\n",
            "Validation accuracy: 0.6245074862096138\n",
            "Epoch 73/499\n",
            "----------\n",
            "Training loss: 535.7019258737564\n",
            "Training accuracy: 0.7019306540583137\n",
            "Validation loss: 593.7779844105244\n",
            "Validation accuracy: 0.6266745468873128\n",
            "Epoch 74/499\n",
            "----------\n",
            "Training loss: 531.8997077941895\n",
            "Training accuracy: 0.7072990543735225\n",
            "Validation loss: 588.511678725481\n",
            "Validation accuracy: 0.6379038613081166\n",
            "Epoch 75/499\n",
            "----------\n",
            "Training loss: 532.2609636187553\n",
            "Training accuracy: 0.7067080378250591\n",
            "Validation loss: 597.9657163918018\n",
            "Validation accuracy: 0.6337667454688731\n",
            "Epoch 76/499\n",
            "----------\n",
            "Training loss: 527.7852739095688\n",
            "Training accuracy: 0.7128152088258471\n",
            "Validation loss: 582.5133117437363\n",
            "Validation accuracy: 0.6501182033096927\n",
            "Epoch 77/499\n",
            "----------\n",
            "Training loss: 525.146619617939\n",
            "Training accuracy: 0.7158687943262412\n",
            "Validation loss: 587.6482756137848\n",
            "Validation accuracy: 0.6442080378250591\n",
            "Epoch 78/499\n",
            "----------\n",
            "Training loss: 522.406445145607\n",
            "Training accuracy: 0.7192178881008668\n",
            "Validation loss: 577.2825577557087\n",
            "Validation accuracy: 0.6483451536643026\n",
            "Epoch 79/499\n",
            "----------\n",
            "Training loss: 519.6549762487411\n",
            "Training accuracy: 0.72301024428684\n",
            "Validation loss: 575.71281260252\n",
            "Validation accuracy: 0.6599684791174153\n",
            "Epoch 80/499\n",
            "----------\n",
            "Training loss: 518.8776516914368\n",
            "Training accuracy: 0.7262608353033885\n",
            "Validation loss: 571.1000602841377\n",
            "Validation accuracy: 0.6593774625689519\n",
            "Epoch 81/499\n",
            "----------\n",
            "Training loss: 517.7881898283958\n",
            "Training accuracy: 0.724290780141844\n",
            "Validation loss: 576.9047334194183\n",
            "Validation accuracy: 0.6497241922773838\n",
            "Epoch 82/499\n",
            "----------\n",
            "Training loss: 514.8109012842178\n",
            "Training accuracy: 0.7271966115051222\n",
            "Validation loss: 588.0276273787022\n",
            "Validation accuracy: 0.6422379826635146\n",
            "Epoch 83/499\n",
            "----------\n",
            "Training loss: 513.6632812619209\n",
            "Training accuracy: 0.7277876280535855\n",
            "Validation loss: 571.0443754792213\n",
            "Validation accuracy: 0.6603624901497241\n",
            "Epoch 84/499\n",
            "----------\n",
            "Training loss: 511.31034219264984\n",
            "Training accuracy: 0.730397951142632\n",
            "Validation loss: 574.5727339088917\n",
            "Validation accuracy: 0.6585894405043341\n",
            "Epoch 85/499\n",
            "----------\n",
            "Training loss: 509.92264330387115\n",
            "Training accuracy: 0.737145390070922\n",
            "Validation loss: 568.0112561881542\n",
            "Validation accuracy: 0.6662726556343578\n",
            "Epoch 86/499\n",
            "----------\n",
            "Training loss: 508.61843687295914\n",
            "Training accuracy: 0.7354708431836091\n",
            "Validation loss: 576.9784489870071\n",
            "Validation accuracy: 0.6538613081166272\n",
            "Epoch 87/499\n",
            "----------\n",
            "Training loss: 508.8489249944687\n",
            "Training accuracy: 0.7378841607565012\n",
            "Validation loss: 575.4139266908169\n",
            "Validation accuracy: 0.6631205673758865\n",
            "Epoch 88/499\n",
            "----------\n",
            "Training loss: 506.01766788959503\n",
            "Training accuracy: 0.7409869976359338\n",
            "Validation loss: 576.46276730299\n",
            "Validation accuracy: 0.6451930654058313\n",
            "Epoch 89/499\n",
            "----------\n",
            "Training loss: 505.4581781029701\n",
            "Training accuracy: 0.746306146572104\n",
            "Validation loss: 572.2659975290298\n",
            "Validation accuracy: 0.6499211977935382\n",
            "Epoch 90/499\n",
            "----------\n",
            "Training loss: 504.4371432065964\n",
            "Training accuracy: 0.7435480693459416\n",
            "Validation loss: 566.2718650400639\n",
            "Validation accuracy: 0.6666666666666666\n",
            "Epoch 91/499\n",
            "----------\n",
            "Training loss: 502.4010001420975\n",
            "Training accuracy: 0.7480299448384555\n",
            "Validation loss: 565.5511888861656\n",
            "Validation accuracy: 0.6727738376674547\n",
            "Epoch 92/499\n",
            "----------\n",
            "Training loss: 502.01341903209686\n",
            "Training accuracy: 0.7509850275807722\n",
            "Validation loss: 560.8681748509407\n",
            "Validation accuracy: 0.6782899921197794\n",
            "Epoch 93/499\n",
            "----------\n",
            "Training loss: 502.5594498515129\n",
            "Training accuracy: 0.748473207249803\n",
            "Validation loss: 564.7839979231358\n",
            "Validation accuracy: 0.6745468873128447\n",
            "Epoch 94/499\n",
            "----------\n",
            "Training loss: 501.93580108880997\n",
            "Training accuracy: 0.7486209613869188\n",
            "Validation loss: 566.2094820141792\n",
            "Validation accuracy: 0.6745468873128447\n",
            "Epoch 95/499\n",
            "----------\n",
            "Training loss: 499.28245371580124\n",
            "Training accuracy: 0.7564519306540584\n",
            "Validation loss: 560.1832413077354\n",
            "Validation accuracy: 0.6818360914105595\n",
            "Epoch 96/499\n",
            "----------\n",
            "Training loss: 498.17187601327896\n",
            "Training accuracy: 0.7539893617021277\n",
            "Validation loss: 562.514705747366\n",
            "Validation accuracy: 0.6743498817966903\n",
            "Epoch 97/499\n",
            "----------\n",
            "Training loss: 499.0931850671768\n",
            "Training accuracy: 0.7560579196217494\n",
            "Validation loss: 562.7631570696831\n",
            "Validation accuracy: 0.6733648542159181\n",
            "Epoch 98/499\n",
            "----------\n",
            "Training loss: 497.66271579265594\n",
            "Training accuracy: 0.75852048857368\n",
            "Validation loss: 557.0040983855724\n",
            "Validation accuracy: 0.6849881796690307\n",
            "Epoch 99/499\n",
            "----------\n",
            "Training loss: 497.1274164915085\n",
            "Training accuracy: 0.7598995271867612\n",
            "Validation loss: 560.532081246376\n",
            "Validation accuracy: 0.6851851851851852\n",
            "Epoch 100/499\n",
            "----------\n",
            "Training loss: 498.3818576335907\n",
            "Training accuracy: 0.7574862096138691\n",
            "Validation loss: 556.344634860754\n",
            "Validation accuracy: 0.6903073286052009\n",
            "Epoch 101/499\n",
            "----------\n",
            "Training loss: 497.8662229180336\n",
            "Training accuracy: 0.7565504334121356\n",
            "Validation loss: 556.4352154135704\n",
            "Validation accuracy: 0.6936564223798266\n",
            "Epoch 102/499\n",
            "----------\n",
            "Training loss: 499.183008313179\n",
            "Training accuracy: 0.7551713947990544\n",
            "Validation loss: 570.2033178210258\n",
            "Validation accuracy: 0.6623325453112687\n",
            "Epoch 103/499\n",
            "----------\n",
            "Training loss: 498.63418585062027\n",
            "Training accuracy: 0.7591115051221434\n",
            "Validation loss: 561.5196672677994\n",
            "Validation accuracy: 0.681639085894405\n",
            "Epoch 104/499\n",
            "----------\n",
            "Training loss: 498.17507553100586\n",
            "Training accuracy: 0.76349487785658\n",
            "Validation loss: 558.249096095562\n",
            "Validation accuracy: 0.6863672182821119\n",
            "Epoch 105/499\n",
            "----------\n",
            "Training loss: 496.0969668030739\n",
            "Training accuracy: 0.765021670606777\n",
            "Validation loss: 562.1119840145111\n",
            "Validation accuracy: 0.6792750197005516\n",
            "Epoch 106/499\n",
            "----------\n",
            "Training loss: 497.12022191286087\n",
            "Training accuracy: 0.767434988179669\n",
            "Validation loss: 559.312190502882\n",
            "Validation accuracy: 0.6830181245074862\n",
            "Epoch 107/499\n",
            "----------\n",
            "Training loss: 498.08546298742294\n",
            "Training accuracy: 0.7638888888888888\n",
            "Validation loss: 560.3645160198212\n",
            "Validation accuracy: 0.6853821907013397\n",
            "Epoch 108/499\n",
            "----------\n",
            "Training loss: 498.78021931648254\n",
            "Training accuracy: 0.7644306540583137\n",
            "Validation loss: 565.3603311181068\n",
            "Validation accuracy: 0.6723798266351458\n",
            "Epoch 109/499\n",
            "----------\n",
            "Training loss: 498.66239607334137\n",
            "Training accuracy: 0.7662037037037037\n",
            "Validation loss: 556.0559033453465\n",
            "Validation accuracy: 0.69424743892829\n",
            "Epoch 110/499\n",
            "----------\n",
            "Training loss: 499.6584716439247\n",
            "Training accuracy: 0.7640366430260047\n",
            "Validation loss: 567.7260027229786\n",
            "Validation accuracy: 0.6711977935382191\n",
            "Epoch 111/499\n",
            "----------\n",
            "Training loss: 498.7528346180916\n",
            "Training accuracy: 0.7685185185185185\n",
            "Validation loss: 557.9120875597\n",
            "Validation accuracy: 0.6845941686367218\n",
            "Epoch 112/499\n",
            "----------\n",
            "Training loss: 500.3868425488472\n",
            "Training accuracy: 0.7660559495665878\n",
            "Validation loss: 561.8741263151169\n",
            "Validation accuracy: 0.6897163120567376\n",
            "Epoch 113/499\n",
            "----------\n",
            "Training loss: 499.848137319088\n",
            "Training accuracy: 0.7694542947202522\n",
            "Validation loss: 562.2096188664436\n",
            "Validation accuracy: 0.6806540583136328\n",
            "Epoch 114/499\n",
            "----------\n",
            "Training loss: 500.6213455796242\n",
            "Training accuracy: 0.7700453112687156\n",
            "Validation loss: 557.7875738143921\n",
            "Validation accuracy: 0.6946414499605988\n",
            "Epoch 115/499\n",
            "----------\n",
            "Training loss: 501.10497134923935\n",
            "Training accuracy: 0.7670409771473601\n",
            "Validation loss: 557.2629959881306\n",
            "Validation accuracy: 0.6958234830575256\n",
            "Epoch 116/499\n",
            "----------\n",
            "Training loss: 502.19127583503723\n",
            "Training accuracy: 0.7680260047281324\n",
            "Validation loss: 568.2103944122791\n",
            "Validation accuracy: 0.6903073286052009\n",
            "Epoch 117/499\n",
            "----------\n",
            "Training loss: 501.763229906559\n",
            "Training accuracy: 0.7727048857368006\n",
            "Validation loss: 563.2085538506508\n",
            "Validation accuracy: 0.6847911741528763\n",
            "Epoch 118/499\n",
            "----------\n",
            "Training loss: 502.84893745183945\n",
            "Training accuracy: 0.7710303388494878\n",
            "Validation loss: 566.2192176878452\n",
            "Validation accuracy: 0.6903073286052009\n",
            "Epoch 119/499\n",
            "----------\n",
            "Training loss: 501.89399766921997\n",
            "Training accuracy: 0.772409377462569\n",
            "Validation loss: 562.0754597783089\n",
            "Validation accuracy: 0.6907013396375099\n",
            "Epoch 120/499\n",
            "----------\n",
            "Training loss: 504.08015155792236\n",
            "Training accuracy: 0.77201536643026\n",
            "Validation loss: 566.9924803078175\n",
            "Validation accuracy: 0.6877462568951931\n",
            "Epoch 121/499\n",
            "----------\n",
            "Training loss: 505.3538071513176\n",
            "Training accuracy: 0.7691587864460205\n",
            "Validation loss: 560.9434882700443\n",
            "Validation accuracy: 0.6993695823483057\n",
            "Epoch 122/499\n",
            "----------\n",
            "Training loss: 504.1826205253601\n",
            "Training accuracy: 0.7716706067769897\n",
            "Validation loss: 561.6311225891113\n",
            "Validation accuracy: 0.6830181245074862\n",
            "Epoch 123/499\n",
            "----------\n",
            "Training loss: 504.92412769794464\n",
            "Training accuracy: 0.7695035460992907\n",
            "Validation loss: 583.0786299407482\n",
            "Validation accuracy: 0.6564223798266351\n",
            "Epoch 124/499\n",
            "----------\n",
            "Training loss: 506.13086998462677\n",
            "Training accuracy: 0.7712273443656422\n",
            "Validation loss: 566.7621351480484\n",
            "Validation accuracy: 0.6849881796690307\n",
            "Epoch 125/499\n",
            "----------\n",
            "Training loss: 505.0134263038635\n",
            "Training accuracy: 0.7735914105594957\n",
            "Validation loss: 567.8519570231438\n",
            "Validation accuracy: 0.6991725768321513\n",
            "Epoch 126/499\n",
            "----------\n",
            "Training loss: 505.96704053878784\n",
            "Training accuracy: 0.7747241922773838\n",
            "Validation loss: 564.7839968204498\n",
            "Validation accuracy: 0.6952324665090622\n",
            "Epoch 127/499\n",
            "----------\n",
            "Training loss: 506.20265674591064\n",
            "Training accuracy: 0.7733451536643026\n",
            "Validation loss: 561.2401742935181\n",
            "Validation accuracy: 0.6881402679275019\n",
            "Epoch 128/499\n",
            "----------\n",
            "Training loss: 506.34230917692184\n",
            "Training accuracy: 0.7731973995271868\n",
            "Validation loss: 569.9412365555763\n",
            "Validation accuracy: 0.6796690307328606\n",
            "Epoch 129/499\n",
            "----------\n",
            "Training loss: 509.54038113355637\n",
            "Training accuracy: 0.7710795902285263\n",
            "Validation loss: 564.7234519720078\n",
            "Validation accuracy: 0.6926713947990544\n",
            "Epoch 130/499\n",
            "----------\n",
            "Training loss: 508.6866310238838\n",
            "Training accuracy: 0.7735914105594957\n",
            "Validation loss: 568.3433372080326\n",
            "Validation accuracy: 0.682033096926714\n",
            "Epoch 131/499\n",
            "----------\n",
            "Training loss: 507.81499660015106\n",
            "Training accuracy: 0.7780240346729709\n",
            "Validation loss: 567.1253787875175\n",
            "Validation accuracy: 0.6954294720252167\n",
            "Epoch 132/499\n",
            "----------\n",
            "Training loss: 509.3716804385185\n",
            "Training accuracy: 0.7747241922773838\n",
            "Validation loss: 587.6469223201275\n",
            "Validation accuracy: 0.6605594956658787\n",
            "Epoch 133/499\n",
            "----------\n",
            "Training loss: 512.0276710987091\n",
            "Training accuracy: 0.769355791962175\n",
            "Validation loss: 568.0351911187172\n",
            "Validation accuracy: 0.6847911741528763\n",
            "Epoch 134/499\n",
            "----------\n",
            "Training loss: 509.3816451430321\n",
            "Training accuracy: 0.77876280535855\n",
            "Validation loss: 571.35521286726\n",
            "Validation accuracy: 0.6719858156028369\n",
            "Epoch 135/499\n",
            "----------\n",
            "Training loss: 509.3369746208191\n",
            "Training accuracy: 0.7743794326241135\n",
            "Validation loss: 566.6870625913143\n",
            "Validation accuracy: 0.6889282899921197\n",
            "Epoch 136/499\n",
            "----------\n",
            "Training loss: 510.3156305551529\n",
            "Training accuracy: 0.7763002364066194\n",
            "Validation loss: 573.1399212777615\n",
            "Validation accuracy: 0.6710007880220646\n",
            "Epoch 137/499\n",
            "----------\n",
            "Training loss: 510.238196849823\n",
            "Training accuracy: 0.7764479905437353\n",
            "Validation loss: 569.3437187075615\n",
            "Validation accuracy: 0.6824271079590228\n",
            "Epoch 138/499\n",
            "----------\n",
            "Training loss: 511.113527238369\n",
            "Training accuracy: 0.7744286840031521\n",
            "Validation loss: 583.2042438983917\n",
            "Validation accuracy: 0.652876280535855\n",
            "Epoch 139/499\n",
            "----------\n",
            "Training loss: 512.2045519351959\n",
            "Training accuracy: 0.7753644602048857\n",
            "Validation loss: 567.2990629673004\n",
            "Validation accuracy: 0.7011426319936959\n",
            "Epoch 140/499\n",
            "----------\n",
            "Training loss: 510.6826651096344\n",
            "Training accuracy: 0.7760539795114263\n",
            "Validation loss: 571.6206076145172\n",
            "Validation accuracy: 0.6759259259259259\n",
            "Epoch 141/499\n",
            "----------\n",
            "Training loss: 512.2755269408226\n",
            "Training accuracy: 0.7718183609141056\n",
            "Validation loss: 569.4357912540436\n",
            "Validation accuracy: 0.696414499605989\n",
            "Epoch 142/499\n",
            "----------\n",
            "Training loss: 511.471244931221\n",
            "Training accuracy: 0.7765464933018125\n",
            "Validation loss: 572.0037549138069\n",
            "Validation accuracy: 0.6924743892829\n",
            "Epoch 143/499\n",
            "----------\n",
            "Training loss: 510.2470339536667\n",
            "Training accuracy: 0.7784672970843184\n",
            "Validation loss: 570.8328424096107\n",
            "Validation accuracy: 0.685973207249803\n",
            "Epoch 144/499\n",
            "----------\n",
            "Training loss: 509.8445617556572\n",
            "Training accuracy: 0.7811761229314421\n",
            "Validation loss: 562.9105769991875\n",
            "Validation accuracy: 0.7070527974783294\n",
            "Epoch 145/499\n",
            "----------\n",
            "Training loss: 512.2276058793068\n",
            "Training accuracy: 0.7773837667454688\n",
            "Validation loss: 576.3548234403133\n",
            "Validation accuracy: 0.6692277383766746\n",
            "Epoch 146/499\n",
            "----------\n",
            "Training loss: 511.44281953573227\n",
            "Training accuracy: 0.7794523246650906\n",
            "Validation loss: 576.3849191367626\n",
            "Validation accuracy: 0.6806540583136328\n",
            "Epoch 147/499\n",
            "----------\n",
            "Training loss: 512.4798237681389\n",
            "Training accuracy: 0.7773345153664303\n",
            "Validation loss: 565.0797551870346\n",
            "Validation accuracy: 0.7011426319936959\n",
            "Epoch 148/499\n",
            "----------\n",
            "Training loss: 512.0762388110161\n",
            "Training accuracy: 0.7788613081166272\n",
            "Validation loss: 575.3245884180069\n",
            "Validation accuracy: 0.6830181245074862\n",
            "Epoch 149/499\n",
            "----------\n",
            "Training loss: 511.1910737156868\n",
            "Training accuracy: 0.780043341213554\n",
            "Validation loss: 569.6548791527748\n",
            "Validation accuracy: 0.7070527974783294\n",
            "Epoch 150/499\n",
            "----------\n",
            "Training loss: 510.02650624513626\n",
            "Training accuracy: 0.7835401891252955\n",
            "Validation loss: 567.2548358440399\n",
            "Validation accuracy: 0.6881402679275019\n",
            "Epoch 151/499\n",
            "----------\n",
            "Training loss: 511.8923277258873\n",
            "Training accuracy: 0.7804866036249015\n",
            "Validation loss: 568.6467007398605\n",
            "Validation accuracy: 0.681639085894405\n",
            "Epoch 152/499\n",
            "----------\n",
            "Training loss: 509.86470383405685\n",
            "Training accuracy: 0.7827521670606777\n",
            "Validation loss: 566.041530251503\n",
            "Validation accuracy: 0.7076438140267928\n",
            "Epoch 153/499\n",
            "----------\n",
            "Training loss: 512.266578733921\n",
            "Training accuracy: 0.776103230890465\n",
            "Validation loss: 562.4578883051872\n",
            "Validation accuracy: 0.7062647754137116\n",
            "Epoch 154/499\n",
            "----------\n",
            "Training loss: 509.66858744621277\n",
            "Training accuracy: 0.7832446808510638\n",
            "Validation loss: 577.9124563634396\n",
            "Validation accuracy: 0.6627265563435776\n",
            "Epoch 155/499\n",
            "----------\n",
            "Training loss: 511.15196788311005\n",
            "Training accuracy: 0.7786150512214342\n",
            "Validation loss: 564.3355162143707\n",
            "Validation accuracy: 0.7117809298660362\n",
            "Epoch 156/499\n",
            "----------\n",
            "Training loss: 508.9263595342636\n",
            "Training accuracy: 0.7837864460204885\n",
            "Validation loss: 567.7243480682373\n",
            "Validation accuracy: 0.7013396375098503\n",
            "Epoch 157/499\n",
            "----------\n",
            "Training loss: 508.7930933237076\n",
            "Training accuracy: 0.7845252167060678\n",
            "Validation loss: 563.376629948616\n",
            "Validation accuracy: 0.7115839243498818\n",
            "Epoch 158/499\n",
            "----------\n",
            "Training loss: 509.4860268831253\n",
            "Training accuracy: 0.7834416863672183\n",
            "Validation loss: 565.0655206739902\n",
            "Validation accuracy: 0.7019306540583137\n",
            "Epoch 159/499\n",
            "----------\n",
            "Training loss: 508.9133851528168\n",
            "Training accuracy: 0.7838849487785658\n",
            "Validation loss: 568.0275005996227\n",
            "Validation accuracy: 0.7019306540583137\n",
            "Epoch 160/499\n",
            "----------\n",
            "Training loss: 508.9948678612709\n",
            "Training accuracy: 0.7824074074074074\n",
            "Validation loss: 575.8033282756805\n",
            "Validation accuracy: 0.6767139479905437\n",
            "Epoch 161/499\n",
            "----------\n",
            "Training loss: 508.1658959388733\n",
            "Training accuracy: 0.7837864460204885\n",
            "Validation loss: 571.3963178396225\n",
            "Validation accuracy: 0.6934594168636722\n",
            "Epoch 162/499\n",
            "----------\n",
            "Training loss: 506.97825342416763\n",
            "Training accuracy: 0.78373719464145\n",
            "Validation loss: 571.900042116642\n",
            "Validation accuracy: 0.6851851851851852\n",
            "Epoch 163/499\n",
            "----------\n",
            "Training loss: 506.1941946744919\n",
            "Training accuracy: 0.7875788022064618\n",
            "Validation loss: 566.8974464535713\n",
            "Validation accuracy: 0.6881402679275019\n",
            "Epoch 164/499\n",
            "----------\n",
            "Training loss: 505.48737478256226\n",
            "Training accuracy: 0.7875295508274232\n",
            "Validation loss: 566.0497371554375\n",
            "Validation accuracy: 0.7037037037037037\n",
            "Epoch 165/499\n",
            "----------\n",
            "Training loss: 506.4577516913414\n",
            "Training accuracy: 0.783343183609141\n",
            "Validation loss: 564.1405143737793\n",
            "Validation accuracy: 0.7127659574468085\n",
            "Epoch 166/499\n",
            "----------\n",
            "Training loss: 504.98883777856827\n",
            "Training accuracy: 0.7857565011820331\n",
            "Validation loss: 565.7686103880405\n",
            "Validation accuracy: 0.6865642237982663\n",
            "Epoch 167/499\n",
            "----------\n",
            "Training loss: 505.15880078077316\n",
            "Training accuracy: 0.7880713159968479\n",
            "Validation loss: 559.52589148283\n",
            "Validation accuracy: 0.7147360126083531\n",
            "Epoch 168/499\n",
            "----------\n",
            "Training loss: 504.338027715683\n",
            "Training accuracy: 0.7862982663514578\n",
            "Validation loss: 562.0765859484673\n",
            "Validation accuracy: 0.7113869188337274\n",
            "Epoch 169/499\n",
            "----------\n",
            "Training loss: 503.6956768631935\n",
            "Training accuracy: 0.7875788022064618\n",
            "Validation loss: 583.6290165781975\n",
            "Validation accuracy: 0.6526792750197006\n",
            "Epoch 170/499\n",
            "----------\n",
            "Training loss: 502.40145033597946\n",
            "Training accuracy: 0.7903368794326241\n",
            "Validation loss: 570.0297570228577\n",
            "Validation accuracy: 0.6983845547675335\n",
            "Epoch 171/499\n",
            "----------\n",
            "Training loss: 502.005548119545\n",
            "Training accuracy: 0.7907308904649331\n",
            "Validation loss: 562.2647938728333\n",
            "Validation accuracy: 0.7113869188337274\n",
            "Epoch 172/499\n",
            "----------\n",
            "Training loss: 501.6042755842209\n",
            "Training accuracy: 0.7911249014972419\n",
            "Validation loss: 563.8953056931496\n",
            "Validation accuracy: 0.7054767533490938\n",
            "Epoch 173/499\n",
            "----------\n",
            "Training loss: 501.0522844195366\n",
            "Training accuracy: 0.7894011032308904\n",
            "Validation loss: 556.5104767680168\n",
            "Validation accuracy: 0.7214342001576044\n",
            "Epoch 174/499\n",
            "----------\n",
            "Training loss: 498.9356484413147\n",
            "Training accuracy: 0.7948680063041765\n",
            "Validation loss: 553.688941180706\n",
            "Validation accuracy: 0.7127659574468085\n",
            "Epoch 175/499\n",
            "----------\n",
            "Training loss: 498.41731506586075\n",
            "Training accuracy: 0.7955082742316785\n",
            "Validation loss: 560.3272156715393\n",
            "Validation accuracy: 0.7019306540583137\n",
            "Epoch 176/499\n",
            "----------\n",
            "Training loss: 497.3560149073601\n",
            "Training accuracy: 0.7921591804570528\n",
            "Validation loss: 553.7192384302616\n",
            "Validation accuracy: 0.7218282111899134\n",
            "Epoch 177/499\n",
            "----------\n",
            "Training loss: 497.188145339489\n",
            "Training accuracy: 0.7929472025216706\n",
            "Validation loss: 563.5992374122143\n",
            "Validation accuracy: 0.7019306540583137\n",
            "Epoch 178/499\n",
            "----------\n",
            "Training loss: 496.46527552604675\n",
            "Training accuracy: 0.7927501970055162\n",
            "Validation loss: 556.7113540172577\n",
            "Validation accuracy: 0.7066587864460205\n",
            "Epoch 179/499\n",
            "----------\n",
            "Training loss: 495.5064498782158\n",
            "Training accuracy: 0.7975275807722616\n",
            "Validation loss: 554.2931078970432\n",
            "Validation accuracy: 0.7184791174152876\n",
            "Epoch 180/499\n",
            "----------\n",
            "Training loss: 496.10549610853195\n",
            "Training accuracy: 0.7971335697399528\n",
            "Validation loss: 576.5108000934124\n",
            "Validation accuracy: 0.6581954294720253\n",
            "Epoch 181/499\n",
            "----------\n",
            "Training loss: 494.00236308574677\n",
            "Training accuracy: 0.7932919621749409\n",
            "Validation loss: 561.7084849774837\n",
            "Validation accuracy: 0.7007486209613869\n",
            "Epoch 182/499\n",
            "----------\n",
            "Training loss: 493.32255631685257\n",
            "Training accuracy: 0.7987588652482269\n",
            "Validation loss: 550.7743684947491\n",
            "Validation accuracy: 0.7241922773837668\n",
            "Epoch 183/499\n",
            "----------\n",
            "Training loss: 493.4552324414253\n",
            "Training accuracy: 0.8001379038613081\n",
            "Validation loss: 545.552387535572\n",
            "Validation accuracy: 0.7263593380614657\n",
            "Epoch 184/499\n",
            "----------\n",
            "Training loss: 490.796248793602\n",
            "Training accuracy: 0.8023542159180457\n",
            "Validation loss: 553.6987083554268\n",
            "Validation accuracy: 0.7178881008668243\n",
            "Epoch 185/499\n",
            "----------\n",
            "Training loss: 491.5506739616394\n",
            "Training accuracy: 0.7967395587076438\n",
            "Validation loss: 552.0348832905293\n",
            "Validation accuracy: 0.7129629629629629\n",
            "Epoch 186/499\n",
            "----------\n",
            "Training loss: 491.3342750072479\n",
            "Training accuracy: 0.7993498817966903\n",
            "Validation loss: 544.9805982708931\n",
            "Validation accuracy: 0.7330575256107171\n",
            "Epoch 187/499\n",
            "----------\n",
            "Training loss: 488.6167216897011\n",
            "Training accuracy: 0.8028467297084318\n",
            "Validation loss: 547.4550825059414\n",
            "Validation accuracy: 0.7259653270291568\n",
            "Epoch 188/499\n",
            "----------\n",
            "Training loss: 489.12731182575226\n",
            "Training accuracy: 0.8026004728132388\n",
            "Validation loss: 546.2434070408344\n",
            "Validation accuracy: 0.7186761229314421\n",
            "Epoch 189/499\n",
            "----------\n",
            "Training loss: 488.86713033914566\n",
            "Training accuracy: 0.8029452324665091\n",
            "Validation loss: 546.621832370758\n",
            "Validation accuracy: 0.7202521670606777\n",
            "Epoch 190/499\n",
            "----------\n",
            "Training loss: 487.93176966905594\n",
            "Training accuracy: 0.8006304176516943\n",
            "Validation loss: 545.4782878160477\n",
            "Validation accuracy: 0.710795902285264\n",
            "Epoch 191/499\n",
            "----------\n",
            "Training loss: 484.68262588977814\n",
            "Training accuracy: 0.8060973207249803\n",
            "Validation loss: 545.6795735359192\n",
            "Validation accuracy: 0.7265563435776202\n",
            "Epoch 192/499\n",
            "----------\n",
            "Training loss: 483.63120490312576\n",
            "Training accuracy: 0.8071808510638298\n",
            "Validation loss: 555.1917463243008\n",
            "Validation accuracy: 0.7145390070921985\n",
            "Epoch 193/499\n",
            "----------\n",
            "Training loss: 484.6024894118309\n",
            "Training accuracy: 0.8044227738376675\n",
            "Validation loss: 551.8308734893799\n",
            "Validation accuracy: 0.7035066981875493\n",
            "Epoch 194/499\n",
            "----------\n",
            "Training loss: 482.8943893313408\n",
            "Training accuracy: 0.8052600472813238\n",
            "Validation loss: 550.2448191046715\n",
            "Validation accuracy: 0.708628841607565\n",
            "Epoch 195/499\n",
            "----------\n",
            "Training loss: 482.7741740345955\n",
            "Training accuracy: 0.8065405831363278\n",
            "Validation loss: 546.3224042654037\n",
            "Validation accuracy: 0.7198581560283688\n",
            "Epoch 196/499\n",
            "----------\n",
            "Training loss: 482.5688933134079\n",
            "Training accuracy: 0.8100374310480694\n",
            "Validation loss: 548.4788248836994\n",
            "Validation accuracy: 0.7257683215130024\n",
            "Epoch 197/499\n",
            "----------\n",
            "Training loss: 481.3595053553581\n",
            "Training accuracy: 0.8095449172576832\n",
            "Validation loss: 549.4838953018188\n",
            "Validation accuracy: 0.7092198581560284\n",
            "Epoch 198/499\n",
            "----------\n",
            "Training loss: 479.96770632267\n",
            "Training accuracy: 0.8058018124507487\n",
            "Validation loss: 545.3560833632946\n",
            "Validation accuracy: 0.7157210401891253\n",
            "Epoch 199/499\n",
            "----------\n",
            "Training loss: 479.95355278253555\n",
            "Training accuracy: 0.8096926713947991\n",
            "Validation loss: 549.5161278545856\n",
            "Validation accuracy: 0.72123719464145\n",
            "Epoch 200/499\n",
            "----------\n",
            "Training loss: 478.6014786660671\n",
            "Training accuracy: 0.8114657210401891\n",
            "Validation loss: 537.6605253219604\n",
            "Validation accuracy: 0.7328605200945626\n",
            "Epoch 201/499\n",
            "----------\n",
            "Training loss: 478.77658545970917\n",
            "Training accuracy: 0.8092494089834515\n",
            "Validation loss: 551.0114530622959\n",
            "Validation accuracy: 0.7062647754137116\n",
            "Epoch 202/499\n",
            "----------\n",
            "Training loss: 478.12135124206543\n",
            "Training accuracy: 0.8085106382978723\n",
            "Validation loss: 539.9788758456707\n",
            "Validation accuracy: 0.7287234042553191\n",
            "Epoch 203/499\n",
            "----------\n",
            "Training loss: 477.35948222875595\n",
            "Training accuracy: 0.8132880220646178\n",
            "Validation loss: 533.7258696258068\n",
            "Validation accuracy: 0.7391646966115051\n",
            "Epoch 204/499\n",
            "----------\n",
            "Training loss: 474.5648327469826\n",
            "Training accuracy: 0.8117612293144209\n",
            "Validation loss: 534.0165899991989\n",
            "Validation accuracy: 0.7336485421591804\n",
            "Epoch 205/499\n",
            "----------\n",
            "Training loss: 473.6439602971077\n",
            "Training accuracy: 0.8162431048069346\n",
            "Validation loss: 536.3327178061008\n",
            "Validation accuracy: 0.7198581560283688\n",
            "Epoch 206/499\n",
            "----------\n",
            "Training loss: 473.7045890688896\n",
            "Training accuracy: 0.8145193065405831\n",
            "Validation loss: 535.3778930306435\n",
            "Validation accuracy: 0.7338455476753349\n",
            "Epoch 207/499\n",
            "----------\n",
            "Training loss: 473.24922716617584\n",
            "Training accuracy: 0.8155043341213554\n",
            "Validation loss: 539.5839733481407\n",
            "Validation accuracy: 0.7310874704491725\n",
            "Epoch 208/499\n",
            "----------\n",
            "Training loss: 471.4906949400902\n",
            "Training accuracy: 0.8164893617021277\n",
            "Validation loss: 543.7576771080494\n",
            "Validation accuracy: 0.7062647754137116\n",
            "Epoch 209/499\n",
            "----------\n",
            "Training loss: 471.27670949697495\n",
            "Training accuracy: 0.8180161544523247\n",
            "Validation loss: 538.212881475687\n",
            "Validation accuracy: 0.7176910953506698\n",
            "Epoch 210/499\n",
            "----------\n",
            "Training loss: 467.8294190764427\n",
            "Training accuracy: 0.8200847123719465\n",
            "Validation loss: 540.5943593382835\n",
            "Validation accuracy: 0.7127659574468085\n",
            "Epoch 211/499\n",
            "----------\n",
            "Training loss: 467.79520148038864\n",
            "Training accuracy: 0.8182131599684791\n",
            "Validation loss: 530.1267357170582\n",
            "Validation accuracy: 0.737391646966115\n",
            "Epoch 212/499\n",
            "----------\n",
            "Training loss: 470.29171735048294\n",
            "Training accuracy: 0.8167356185973207\n",
            "Validation loss: 532.104976028204\n",
            "Validation accuracy: 0.7456658786446021\n",
            "Epoch 213/499\n",
            "----------\n",
            "Training loss: 468.12807816267014\n",
            "Training accuracy: 0.8187056737588653\n",
            "Validation loss: 526.8019596040249\n",
            "Validation accuracy: 0.7348305752561072\n",
            "Epoch 214/499\n",
            "----------\n",
            "Training loss: 466.23734879493713\n",
            "Training accuracy: 0.8227442868400315\n",
            "Validation loss: 532.7279663980007\n",
            "Validation accuracy: 0.7301024428684003\n",
            "Epoch 215/499\n",
            "----------\n",
            "Training loss: 465.62579399347305\n",
            "Training accuracy: 0.8209219858156028\n",
            "Validation loss: 538.1011740267277\n",
            "Validation accuracy: 0.7174940898345153\n",
            "Epoch 216/499\n",
            "----------\n",
            "Training loss: 463.96661776304245\n",
            "Training accuracy: 0.8245665878644602\n",
            "Validation loss: 525.9539850354195\n",
            "Validation accuracy: 0.7379826635145784\n",
            "Epoch 217/499\n",
            "----------\n",
            "Training loss: 462.0489813089371\n",
            "Training accuracy: 0.8219070133963751\n",
            "Validation loss: 533.708684951067\n",
            "Validation accuracy: 0.7338455476753349\n",
            "Epoch 218/499\n",
            "----------\n",
            "Training loss: 463.80760407447815\n",
            "Training accuracy: 0.8222517730496454\n",
            "Validation loss: 532.1802774369717\n",
            "Validation accuracy: 0.7202521670606777\n",
            "Epoch 219/499\n",
            "----------\n",
            "Training loss: 460.1763363480568\n",
            "Training accuracy: 0.8255023640661938\n",
            "Validation loss: 534.723001152277\n",
            "Validation accuracy: 0.7285263987391647\n",
            "Epoch 220/499\n",
            "----------\n",
            "Training loss: 459.974452316761\n",
            "Training accuracy: 0.8259456264775413\n",
            "Validation loss: 525.1207421123981\n",
            "Validation accuracy: 0.7338455476753349\n",
            "Epoch 221/499\n",
            "----------\n",
            "Training loss: 459.15942192077637\n",
            "Training accuracy: 0.8283589440504334\n",
            "Validation loss: 527.3517107665539\n",
            "Validation accuracy: 0.7411347517730497\n",
            "Epoch 222/499\n",
            "----------\n",
            "Training loss: 458.7430698275566\n",
            "Training accuracy: 0.8284574468085106\n",
            "Validation loss: 527.7911671996117\n",
            "Validation accuracy: 0.7263593380614657\n",
            "Epoch 223/499\n",
            "----------\n",
            "Training loss: 457.7173346877098\n",
            "Training accuracy: 0.8265858944050434\n",
            "Validation loss: 529.7659328579903\n",
            "Validation accuracy: 0.7324665090622537\n",
            "Epoch 224/499\n",
            "----------\n",
            "Training loss: 458.6184408068657\n",
            "Training accuracy: 0.8277186761229315\n",
            "Validation loss: 530.1398867070675\n",
            "Validation accuracy: 0.7133569739952719\n",
            "Epoch 225/499\n",
            "----------\n",
            "Training loss: 456.08482271432877\n",
            "Training accuracy: 0.8319542947202522\n",
            "Validation loss: 527.4545878767967\n",
            "Validation accuracy: 0.7344365642237982\n",
            "Epoch 226/499\n",
            "----------\n",
            "Training loss: 454.83630234003067\n",
            "Training accuracy: 0.8304275019700552\n",
            "Validation loss: 517.1683530211449\n",
            "Validation accuracy: 0.7570921985815603\n",
            "Epoch 227/499\n",
            "----------\n",
            "Training loss: 454.7799437046051\n",
            "Training accuracy: 0.8313140267927502\n",
            "Validation loss: 524.6471902430058\n",
            "Validation accuracy: 0.7438928289992119\n",
            "Epoch 228/499\n",
            "----------\n",
            "Training loss: 453.2648341655731\n",
            "Training accuracy: 0.8333825847123719\n",
            "Validation loss: 519.5854704976082\n",
            "Validation accuracy: 0.739558707643814\n",
            "Epoch 229/499\n",
            "----------\n",
            "Training loss: 452.50301402807236\n",
            "Training accuracy: 0.8324468085106383\n",
            "Validation loss: 516.3530253469944\n",
            "Validation accuracy: 0.7450748620961387\n",
            "Epoch 230/499\n",
            "----------\n",
            "Training loss: 452.4248616695404\n",
            "Training accuracy: 0.8320035460992907\n",
            "Validation loss: 520.4772046506405\n",
            "Validation accuracy: 0.7397557131599685\n",
            "Epoch 231/499\n",
            "----------\n",
            "Training loss: 451.3394070863724\n",
            "Training accuracy: 0.835155634357762\n",
            "Validation loss: 519.298879802227\n",
            "Validation accuracy: 0.737391646966115\n",
            "Epoch 232/499\n",
            "----------\n",
            "Training loss: 450.6641846895218\n",
            "Training accuracy: 0.8346138691883372\n",
            "Validation loss: 514.2443652749062\n",
            "Validation accuracy: 0.7598502758077226\n",
            "Epoch 233/499\n",
            "----------\n",
            "Training loss: 450.8273402750492\n",
            "Training accuracy: 0.8313632781717888\n",
            "Validation loss: 517.5978736877441\n",
            "Validation accuracy: 0.7523640661938534\n",
            "Epoch 234/499\n",
            "----------\n",
            "Training loss: 450.0970419347286\n",
            "Training accuracy: 0.8326930654058313\n",
            "Validation loss: 520.6037091612816\n",
            "Validation accuracy: 0.7454688731284476\n",
            "Epoch 235/499\n",
            "----------\n",
            "Training loss: 448.62297028303146\n",
            "Training accuracy: 0.8333825847123719\n",
            "Validation loss: 518.0695961117744\n",
            "Validation accuracy: 0.7360126083530338\n",
            "Epoch 236/499\n",
            "----------\n",
            "Training loss: 447.74692982435226\n",
            "Training accuracy: 0.8357466509062254\n",
            "Validation loss: 511.25278812646866\n",
            "Validation accuracy: 0.7551221434200157\n",
            "Epoch 237/499\n",
            "----------\n",
            "Training loss: 446.9399490058422\n",
            "Training accuracy: 0.8381599684791174\n",
            "Validation loss: 510.3414452075958\n",
            "Validation accuracy: 0.7667454688731284\n",
            "Epoch 238/499\n",
            "----------\n",
            "Training loss: 445.77236610651016\n",
            "Training accuracy: 0.834909377462569\n",
            "Validation loss: 523.4226426184177\n",
            "Validation accuracy: 0.7259653270291568\n",
            "Epoch 239/499\n",
            "----------\n",
            "Training loss: 446.45453733205795\n",
            "Training accuracy: 0.8362391646966115\n",
            "Validation loss: 506.45398861169815\n",
            "Validation accuracy: 0.7669424743892829\n",
            "Epoch 240/499\n",
            "----------\n",
            "Training loss: 443.25078520178795\n",
            "Training accuracy: 0.8387509850275807\n",
            "Validation loss: 514.8402308523655\n",
            "Validation accuracy: 0.7371946414499606\n",
            "Epoch 241/499\n",
            "----------\n",
            "Training loss: 443.3434648215771\n",
            "Training accuracy: 0.8380122143420016\n",
            "Validation loss: 511.1770294010639\n",
            "Validation accuracy: 0.7549251379038613\n",
            "Epoch 242/499\n",
            "----------\n",
            "Training loss: 442.91064631938934\n",
            "Training accuracy: 0.8424448384554768\n",
            "Validation loss: 509.1249885559082\n",
            "Validation accuracy: 0.7486209613869188\n",
            "Epoch 243/499\n",
            "----------\n",
            "Training loss: 440.8474350273609\n",
            "Training accuracy: 0.8428388494877856\n",
            "Validation loss: 510.4149657189846\n",
            "Validation accuracy: 0.7590622537431048\n",
            "Epoch 244/499\n",
            "----------\n",
            "Training loss: 439.0941545367241\n",
            "Training accuracy: 0.844316390858944\n",
            "Validation loss: 504.7426072359085\n",
            "Validation accuracy: 0.7616233254531127\n",
            "Epoch 245/499\n",
            "----------\n",
            "Training loss: 440.68575140833855\n",
            "Training accuracy: 0.8459416863672183\n",
            "Validation loss: 512.1563400030136\n",
            "Validation accuracy: 0.758274231678487\n",
            "Epoch 246/499\n",
            "----------\n",
            "Training loss: 439.59195107221603\n",
            "Training accuracy: 0.8438238770685579\n",
            "Validation loss: 507.74767592549324\n",
            "Validation accuracy: 0.7618203309692672\n",
            "Epoch 247/499\n",
            "----------\n",
            "Training loss: 437.65076768398285\n",
            "Training accuracy: 0.845350669818755\n",
            "Validation loss: 501.903672426939\n",
            "Validation accuracy: 0.7730496453900709\n",
            "Epoch 248/499\n",
            "----------\n",
            "Training loss: 437.65955048799515\n",
            "Training accuracy: 0.8428388494877856\n",
            "Validation loss: 510.8526089191437\n",
            "Validation accuracy: 0.752167060677699\n",
            "Epoch 249/499\n",
            "----------\n",
            "Training loss: 438.57373413443565\n",
            "Training accuracy: 0.8427403467297084\n",
            "Validation loss: 511.96438923478127\n",
            "Validation accuracy: 0.7283293932230103\n",
            "Epoch 250/499\n",
            "----------\n",
            "Training loss: 435.76820063591003\n",
            "Training accuracy: 0.8468774625689519\n",
            "Validation loss: 505.77740627527237\n",
            "Validation accuracy: 0.7594562647754137\n",
            "Epoch 251/499\n",
            "----------\n",
            "Training loss: 434.5507515966892\n",
            "Training accuracy: 0.8470744680851063\n",
            "Validation loss: 503.7693921327591\n",
            "Validation accuracy: 0.7624113475177305\n",
            "Epoch 252/499\n",
            "----------\n",
            "Training loss: 433.792028516531\n",
            "Training accuracy: 0.8501280535855004\n",
            "Validation loss: 502.7690519094467\n",
            "Validation accuracy: 0.7586682427107959\n",
            "Epoch 253/499\n",
            "----------\n",
            "Training loss: 433.60276490449905\n",
            "Training accuracy: 0.8485520094562647\n",
            "Validation loss: 503.7156063914299\n",
            "Validation accuracy: 0.7616233254531127\n",
            "Epoch 254/499\n",
            "----------\n",
            "Training loss: 433.46342515945435\n",
            "Training accuracy: 0.8486997635933806\n",
            "Validation loss: 504.04415729641914\n",
            "Validation accuracy: 0.7630023640661938\n",
            "Epoch 255/499\n",
            "----------\n",
            "Training loss: 432.3447554707527\n",
            "Training accuracy: 0.8486012608353034\n",
            "Validation loss: 497.9744337797165\n",
            "Validation accuracy: 0.7637903861308116\n",
            "Epoch 256/499\n",
            "----------\n",
            "Training loss: 430.0342754125595\n",
            "Training accuracy: 0.8536249014972419\n",
            "Validation loss: 502.7435610592365\n",
            "Validation accuracy: 0.7596532702915682\n",
            "Epoch 257/499\n",
            "----------\n",
            "Training loss: 431.8216690123081\n",
            "Training accuracy: 0.851063829787234\n",
            "Validation loss: 501.3975954055786\n",
            "Validation accuracy: 0.7659574468085106\n",
            "Epoch 258/499\n",
            "----------\n",
            "Training loss: 430.76185035705566\n",
            "Training accuracy: 0.8499802994483846\n",
            "Validation loss: 502.8390756249428\n",
            "Validation accuracy: 0.7525610717100079\n",
            "Epoch 259/499\n",
            "----------\n",
            "Training loss: 430.09391537308693\n",
            "Training accuracy: 0.850817572892041\n",
            "Validation loss: 497.76857855916023\n",
            "Validation accuracy: 0.7767927501970056\n",
            "Epoch 260/499\n",
            "----------\n",
            "Training loss: 428.7844041585922\n",
            "Training accuracy: 0.8498325453112687\n",
            "Validation loss: 504.20254507660866\n",
            "Validation accuracy: 0.7590622537431048\n",
            "Epoch 261/499\n",
            "----------\n",
            "Training loss: 429.0793876349926\n",
            "Training accuracy: 0.852344365642238\n",
            "Validation loss: 499.25350600481033\n",
            "Validation accuracy: 0.7702915681639085\n",
            "Epoch 262/499\n",
            "----------\n",
            "Training loss: 428.137603700161\n",
            "Training accuracy: 0.8531323877068558\n",
            "Validation loss: 495.015850931406\n",
            "Validation accuracy: 0.7669424743892829\n",
            "Epoch 263/499\n",
            "----------\n",
            "Training loss: 426.60526061058044\n",
            "Training accuracy: 0.8555457052797478\n",
            "Validation loss: 493.910602837801\n",
            "Validation accuracy: 0.7693065405831363\n",
            "Epoch 264/499\n",
            "----------\n",
            "Training loss: 423.4275623559952\n",
            "Training accuracy: 0.8570232466509062\n",
            "Validation loss: 489.9037743806839\n",
            "Validation accuracy: 0.77698975571316\n",
            "Epoch 265/499\n",
            "----------\n",
            "Training loss: 426.73614659905434\n",
            "Training accuracy: 0.8531816390858944\n",
            "Validation loss: 495.9993160367012\n",
            "Validation accuracy: 0.7663514578408196\n",
            "Epoch 266/499\n",
            "----------\n",
            "Training loss: 424.82962891459465\n",
            "Training accuracy: 0.8536249014972419\n",
            "Validation loss: 492.529817789793\n",
            "Validation accuracy: 0.7762017336485422\n",
            "Epoch 267/499\n",
            "----------\n",
            "Training loss: 423.54738038778305\n",
            "Training accuracy: 0.856924743892829\n",
            "Validation loss: 498.1290464103222\n",
            "Validation accuracy: 0.7649724192277384\n",
            "Epoch 268/499\n",
            "----------\n",
            "Training loss: 422.47917327284813\n",
            "Training accuracy: 0.8552501970055162\n",
            "Validation loss: 492.6778319478035\n",
            "Validation accuracy: 0.7738376674546887\n",
            "Epoch 269/499\n",
            "----------\n",
            "Training loss: 422.19260492920876\n",
            "Training accuracy: 0.8581067769897557\n",
            "Validation loss: 489.4334739744663\n",
            "Validation accuracy: 0.7724586288416075\n",
            "Epoch 270/499\n",
            "----------\n",
            "Training loss: 420.7952024638653\n",
            "Training accuracy: 0.8579590228526399\n",
            "Validation loss: 493.1871559023857\n",
            "Validation accuracy: 0.7691095350669819\n",
            "Epoch 271/499\n",
            "----------\n",
            "Training loss: 420.45392370224\n",
            "Training accuracy: 0.8622438928289992\n",
            "Validation loss: 494.9522000551224\n",
            "Validation accuracy: 0.7568951930654059\n",
            "Epoch 272/499\n",
            "----------\n",
            "Training loss: 420.18871104717255\n",
            "Training accuracy: 0.8561367218282112\n",
            "Validation loss: 490.0145475268364\n",
            "Validation accuracy: 0.7795508274231678\n",
            "Epoch 273/499\n",
            "----------\n",
            "Training loss: 418.638175368309\n",
            "Training accuracy: 0.8584022852639874\n",
            "Validation loss: 489.55673867464066\n",
            "Validation accuracy: 0.7834909377462569\n",
            "Epoch 274/499\n",
            "----------\n",
            "Training loss: 418.29651963710785\n",
            "Training accuracy: 0.8601260835303388\n",
            "Validation loss: 494.90999898314476\n",
            "Validation accuracy: 0.7669424743892829\n",
            "Epoch 275/499\n",
            "----------\n",
            "Training loss: 416.0570071339607\n",
            "Training accuracy: 0.8620468873128447\n",
            "Validation loss: 488.802782446146\n",
            "Validation accuracy: 0.7752167060677699\n",
            "Epoch 276/499\n",
            "----------\n",
            "Training loss: 416.9093220233917\n",
            "Training accuracy: 0.8590425531914894\n",
            "Validation loss: 483.10634022951126\n",
            "Validation accuracy: 0.7817178881008668\n",
            "Epoch 277/499\n",
            "----------\n",
            "Training loss: 416.99189269542694\n",
            "Training accuracy: 0.8580575256107171\n",
            "Validation loss: 485.35271233320236\n",
            "Validation accuracy: 0.7858550039401103\n",
            "Epoch 278/499\n",
            "----------\n",
            "Training loss: 414.46637454628944\n",
            "Training accuracy: 0.8644602048857368\n",
            "Validation loss: 482.41241177916527\n",
            "Validation accuracy: 0.7813238770685579\n",
            "Epoch 279/499\n",
            "----------\n",
            "Training loss: 413.6729472875595\n",
            "Training accuracy: 0.862785657998424\n",
            "Validation loss: 482.77162086963654\n",
            "Validation accuracy: 0.7789598108747045\n",
            "Epoch 280/499\n",
            "----------\n",
            "Training loss: 414.10818845033646\n",
            "Training accuracy: 0.8668242710795903\n",
            "Validation loss: 486.0356022119522\n",
            "Validation accuracy: 0.7728526398739165\n",
            "Epoch 281/499\n",
            "----------\n",
            "Training loss: 411.6826376914978\n",
            "Training accuracy: 0.8662825059101655\n",
            "Validation loss: 492.2010366618633\n",
            "Validation accuracy: 0.7732466509062254\n",
            "Epoch 282/499\n",
            "----------\n",
            "Training loss: 411.2075192928314\n",
            "Training accuracy: 0.867366036249015\n",
            "Validation loss: 485.3246200084686\n",
            "Validation accuracy: 0.7860520094562647\n",
            "Epoch 283/499\n",
            "----------\n",
            "Training loss: 410.58012893795967\n",
            "Training accuracy: 0.867366036249015\n",
            "Validation loss: 485.66774183511734\n",
            "Validation accuracy: 0.7854609929078015\n",
            "Epoch 284/499\n",
            "----------\n",
            "Training loss: 411.6270230412483\n",
            "Training accuracy: 0.8654452324665091\n",
            "Validation loss: 485.2877112329006\n",
            "Validation accuracy: 0.7803388494877856\n",
            "Epoch 285/499\n",
            "----------\n",
            "Training loss: 409.9899721443653\n",
            "Training accuracy: 0.8670212765957447\n",
            "Validation loss: 480.7046102285385\n",
            "Validation accuracy: 0.7923561859732072\n",
            "Epoch 286/499\n",
            "----------\n",
            "Training loss: 408.9339541196823\n",
            "Training accuracy: 0.8722419227738377\n",
            "Validation loss: 483.71892765164375\n",
            "Validation accuracy: 0.7675334909377463\n",
            "Epoch 287/499\n",
            "----------\n",
            "Training loss: 409.5134263932705\n",
            "Training accuracy: 0.8655929866036249\n",
            "Validation loss: 483.5889981687069\n",
            "Validation accuracy: 0.7728526398739165\n",
            "Epoch 288/499\n",
            "----------\n",
            "Training loss: 408.47173419594765\n",
            "Training accuracy: 0.8663810086682427\n",
            "Validation loss: 483.4286750257015\n",
            "Validation accuracy: 0.7870370370370371\n",
            "Epoch 289/499\n",
            "----------\n",
            "Training loss: 406.61751422286034\n",
            "Training accuracy: 0.8683510638297872\n",
            "Validation loss: 481.45090839266777\n",
            "Validation accuracy: 0.7801418439716312\n",
            "Epoch 290/499\n",
            "----------\n",
            "Training loss: 406.7588272690773\n",
            "Training accuracy: 0.8691883372734437\n",
            "Validation loss: 479.3054241538048\n",
            "Validation accuracy: 0.7943262411347518\n",
            "Epoch 291/499\n",
            "----------\n",
            "Training loss: 406.76165348291397\n",
            "Training accuracy: 0.8721434200157604\n",
            "Validation loss: 483.385282933712\n",
            "Validation accuracy: 0.7649724192277384\n",
            "Epoch 292/499\n",
            "----------\n",
            "Training loss: 405.9940868616104\n",
            "Training accuracy: 0.8724881796690307\n",
            "Validation loss: 481.7450375854969\n",
            "Validation accuracy: 0.7734436564223798\n",
            "Epoch 293/499\n",
            "----------\n",
            "Training loss: 405.0696565210819\n",
            "Training accuracy: 0.8699763593380615\n",
            "Validation loss: 481.5089373290539\n",
            "Validation accuracy: 0.7844759653270291\n",
            "Epoch 294/499\n",
            "----------\n",
            "Training loss: 403.6007283627987\n",
            "Training accuracy: 0.87322695035461\n",
            "Validation loss: 476.7409120500088\n",
            "Validation accuracy: 0.7819148936170213\n",
            "Epoch 295/499\n",
            "----------\n",
            "Training loss: 403.7881574034691\n",
            "Training accuracy: 0.8712076438140268\n",
            "Validation loss: 477.3240922987461\n",
            "Validation accuracy: 0.7750197005516154\n",
            "Epoch 296/499\n",
            "----------\n",
            "Training loss: 403.35880869627\n",
            "Training accuracy: 0.8706658786446021\n",
            "Validation loss: 479.07411855459213\n",
            "Validation accuracy: 0.7736406619385343\n",
            "Epoch 297/499\n",
            "----------\n",
            "Training loss: 402.2761283516884\n",
            "Training accuracy: 0.8727344365642238\n",
            "Validation loss: 479.44795510172844\n",
            "Validation accuracy: 0.7817178881008668\n",
            "Epoch 298/499\n",
            "----------\n",
            "Training loss: 401.91951248049736\n",
            "Training accuracy: 0.8717986603624901\n",
            "Validation loss: 470.59387719631195\n",
            "Validation accuracy: 0.7927501970055162\n",
            "Epoch 299/499\n",
            "----------\n",
            "Training loss: 401.16555443406105\n",
            "Training accuracy: 0.8742119779353822\n",
            "Validation loss: 474.75019109249115\n",
            "Validation accuracy: 0.7866430260047281\n",
            "Epoch 300/499\n",
            "----------\n",
            "Training loss: 401.0628729760647\n",
            "Training accuracy: 0.8710106382978723\n",
            "Validation loss: 477.2864676117897\n",
            "Validation accuracy: 0.7821118991331757\n",
            "Epoch 301/499\n",
            "----------\n",
            "Training loss: 399.6904046237469\n",
            "Training accuracy: 0.8776595744680851\n",
            "Validation loss: 472.3224596083164\n",
            "Validation accuracy: 0.7888100866824271\n",
            "Epoch 302/499\n",
            "----------\n",
            "Training loss: 399.643138051033\n",
            "Training accuracy: 0.8747537431048069\n",
            "Validation loss: 471.78747004270554\n",
            "Validation accuracy: 0.7917651694247438\n",
            "Epoch 303/499\n",
            "----------\n",
            "Training loss: 398.81465008854866\n",
            "Training accuracy: 0.8762312844759653\n",
            "Validation loss: 478.8067561984062\n",
            "Validation accuracy: 0.7704885736800631\n",
            "Epoch 304/499\n",
            "----------\n",
            "Training loss: 397.6702354848385\n",
            "Training accuracy: 0.8746552403467297\n",
            "Validation loss: 470.7448207139969\n",
            "Validation accuracy: 0.7894011032308904\n",
            "Epoch 305/499\n",
            "----------\n",
            "Training loss: 398.49616810679436\n",
            "Training accuracy: 0.8756895193065406\n",
            "Validation loss: 491.93812438845634\n",
            "Validation accuracy: 0.746059889676911\n",
            "Epoch 306/499\n",
            "----------\n",
            "Training loss: 398.6455926001072\n",
            "Training accuracy: 0.8739657210401891\n",
            "Validation loss: 477.3044246137142\n",
            "Validation accuracy: 0.7836879432624113\n",
            "Epoch 307/499\n",
            "----------\n",
            "Training loss: 396.06603449583054\n",
            "Training accuracy: 0.8793833727344366\n",
            "Validation loss: 475.3761746287346\n",
            "Validation accuracy: 0.7771867612293144\n",
            "Epoch 308/499\n",
            "----------\n",
            "Training loss: 394.97219917178154\n",
            "Training accuracy: 0.880466903073286\n",
            "Validation loss: 467.1546723842621\n",
            "Validation accuracy: 0.7886130811662726\n",
            "Epoch 309/499\n",
            "----------\n",
            "Training loss: 394.81350004673004\n",
            "Training accuracy: 0.8782505910165485\n",
            "Validation loss: 464.5773393213749\n",
            "Validation accuracy: 0.8022064617809299\n",
            "Epoch 310/499\n",
            "----------\n",
            "Training loss: 394.3696272969246\n",
            "Training accuracy: 0.8795311268715524\n",
            "Validation loss: 476.2762517631054\n",
            "Validation accuracy: 0.7738376674546887\n",
            "Epoch 311/499\n",
            "----------\n",
            "Training loss: 395.4363454282284\n",
            "Training accuracy: 0.8763790386130812\n",
            "Validation loss: 466.9162802398205\n",
            "Validation accuracy: 0.7943262411347518\n",
            "Epoch 312/499\n",
            "----------\n",
            "Training loss: 394.58959823846817\n",
            "Training accuracy: 0.8801221434200157\n",
            "Validation loss: 462.5257701277733\n",
            "Validation accuracy: 0.7939322301024428\n",
            "Epoch 313/499\n",
            "----------\n",
            "Training loss: 393.29363656044006\n",
            "Training accuracy: 0.8784968479117415\n",
            "Validation loss: 474.1331987082958\n",
            "Validation accuracy: 0.776595744680851\n",
            "Epoch 314/499\n",
            "----------\n",
            "Training loss: 393.38566917181015\n",
            "Training accuracy: 0.8831264775413712\n",
            "Validation loss: 476.4069270193577\n",
            "Validation accuracy: 0.7758077226162332\n",
            "Epoch 315/499\n",
            "----------\n",
            "Training loss: 392.2786838412285\n",
            "Training accuracy: 0.8811071710007881\n",
            "Validation loss: 481.1929450035095\n",
            "Validation accuracy: 0.7685185185185185\n",
            "Epoch 316/499\n",
            "----------\n",
            "Training loss: 391.7687212526798\n",
            "Training accuracy: 0.8806146572104019\n",
            "Validation loss: 469.8289795219898\n",
            "Validation accuracy: 0.7907801418439716\n",
            "Epoch 317/499\n",
            "----------\n",
            "Training loss: 391.23346266150475\n",
            "Training accuracy: 0.8817966903073287\n",
            "Validation loss: 460.22266352176666\n",
            "Validation accuracy: 0.8010244286840031\n",
            "Epoch 318/499\n",
            "----------\n",
            "Training loss: 392.11510118842125\n",
            "Training accuracy: 0.8802698975571316\n",
            "Validation loss: 473.971035271883\n",
            "Validation accuracy: 0.77876280535855\n",
            "Epoch 319/499\n",
            "----------\n",
            "Training loss: 390.4862698316574\n",
            "Training accuracy: 0.8857368006304176\n",
            "Validation loss: 462.2909863293171\n",
            "Validation accuracy: 0.7990543735224587\n",
            "Epoch 320/499\n",
            "----------\n",
            "Training loss: 390.32459366321564\n",
            "Training accuracy: 0.8831264775413712\n",
            "Validation loss: 464.47832122445107\n",
            "Validation accuracy: 0.7911741528762806\n",
            "Epoch 321/499\n",
            "----------\n",
            "Training loss: 388.25696989893913\n",
            "Training accuracy: 0.8842100078802206\n",
            "Validation loss: 461.57801616191864\n",
            "Validation accuracy: 0.7984633569739953\n",
            "Epoch 322/499\n",
            "----------\n",
            "Training loss: 388.9347831904888\n",
            "Training accuracy: 0.8828309692671394\n",
            "Validation loss: 463.49654054641724\n",
            "Validation accuracy: 0.7978723404255319\n",
            "Epoch 323/499\n",
            "----------\n",
            "Training loss: 387.88698068261147\n",
            "Training accuracy: 0.8853920409771474\n",
            "Validation loss: 462.94871482253075\n",
            "Validation accuracy: 0.7925531914893617\n",
            "Epoch 324/499\n",
            "----------\n",
            "Training loss: 387.070812612772\n",
            "Training accuracy: 0.8842100078802206\n",
            "Validation loss: 465.54668059945107\n",
            "Validation accuracy: 0.7888100866824271\n",
            "Epoch 325/499\n",
            "----------\n",
            "Training loss: 387.4211410880089\n",
            "Training accuracy: 0.885441292356186\n",
            "Validation loss: 474.64826929569244\n",
            "Validation accuracy: 0.7762017336485422\n",
            "Epoch 326/499\n",
            "----------\n",
            "Training loss: 386.35366854071617\n",
            "Training accuracy: 0.8851950354609929\n",
            "Validation loss: 459.230013102293\n",
            "Validation accuracy: 0.8045705279747833\n",
            "Epoch 327/499\n",
            "----------\n",
            "Training loss: 384.65213772654533\n",
            "Training accuracy: 0.889381402679275\n",
            "Validation loss: 463.79469725489616\n",
            "Validation accuracy: 0.7933412135539795\n",
            "Epoch 328/499\n",
            "----------\n",
            "Training loss: 385.4063690304756\n",
            "Training accuracy: 0.8860815602836879\n",
            "Validation loss: 464.96895238757133\n",
            "Validation accuracy: 0.793538219070134\n",
            "Epoch 329/499\n",
            "----------\n",
            "Training loss: 385.17175260186195\n",
            "Training accuracy: 0.8843577620173365\n",
            "Validation loss: 459.96828293800354\n",
            "Validation accuracy: 0.8026004728132388\n",
            "Epoch 330/499\n",
            "----------\n",
            "Training loss: 382.9854029119015\n",
            "Training accuracy: 0.8900709219858156\n",
            "Validation loss: 468.0728706419468\n",
            "Validation accuracy: 0.7834909377462569\n",
            "Epoch 331/499\n",
            "----------\n",
            "Training loss: 384.2929937839508\n",
            "Training accuracy: 0.8880516154452325\n",
            "Validation loss: 467.1195937991142\n",
            "Validation accuracy: 0.77698975571316\n",
            "Epoch 332/499\n",
            "----------\n",
            "Training loss: 383.429154753685\n",
            "Training accuracy: 0.8892828999211978\n",
            "Validation loss: 457.08438017964363\n",
            "Validation accuracy: 0.8089046493301812\n",
            "Epoch 333/499\n",
            "----------\n",
            "Training loss: 384.0035139620304\n",
            "Training accuracy: 0.8889873916469662\n",
            "Validation loss: 460.394059330225\n",
            "Validation accuracy: 0.801812450748621\n",
            "Epoch 334/499\n",
            "----------\n",
            "Training loss: 382.0874140262604\n",
            "Training accuracy: 0.8885441292356187\n",
            "Validation loss: 466.984859675169\n",
            "Validation accuracy: 0.7901891252955082\n",
            "Epoch 335/499\n",
            "----------\n",
            "Training loss: 381.8900211453438\n",
            "Training accuracy: 0.8857860520094563\n",
            "Validation loss: 466.00946003198624\n",
            "Validation accuracy: 0.789598108747045\n",
            "Epoch 336/499\n",
            "----------\n",
            "Training loss: 383.86038678884506\n",
            "Training accuracy: 0.8847025216706068\n",
            "Validation loss: 463.5279077887535\n",
            "Validation accuracy: 0.7860520094562647\n",
            "Epoch 337/499\n",
            "----------\n",
            "Training loss: 379.65174636244774\n",
            "Training accuracy: 0.8905634357762018\n",
            "Validation loss: 467.9634704887867\n",
            "Validation accuracy: 0.780929866036249\n",
            "Epoch 338/499\n",
            "----------\n",
            "Training loss: 380.9752652645111\n",
            "Training accuracy: 0.8901694247438928\n",
            "Validation loss: 456.8158639371395\n",
            "Validation accuracy: 0.8016154452324665\n",
            "Epoch 339/499\n",
            "----------\n",
            "Training loss: 379.8603972494602\n",
            "Training accuracy: 0.8900709219858156\n",
            "Validation loss: 456.0930404961109\n",
            "Validation accuracy: 0.803585500394011\n",
            "Epoch 340/499\n",
            "----------\n",
            "Training loss: 380.25806000828743\n",
            "Training accuracy: 0.8917947202521671\n",
            "Validation loss: 459.570241779089\n",
            "Validation accuracy: 0.8000394011032309\n",
            "Epoch 341/499\n",
            "----------\n",
            "Training loss: 380.3663004934788\n",
            "Training accuracy: 0.8916469661150512\n",
            "Validation loss: 464.4534185528755\n",
            "Validation accuracy: 0.7980693459416863\n",
            "Epoch 342/499\n",
            "----------\n",
            "Training loss: 379.55613300204277\n",
            "Training accuracy: 0.890021670606777\n",
            "Validation loss: 459.37347760796547\n",
            "Validation accuracy: 0.7998423955870765\n",
            "Epoch 343/499\n",
            "----------\n",
            "Training loss: 377.4843538105488\n",
            "Training accuracy: 0.8920902285263987\n",
            "Validation loss: 455.6769489943981\n",
            "Validation accuracy: 0.80397951142632\n",
            "Epoch 344/499\n",
            "----------\n",
            "Training loss: 377.34297028183937\n",
            "Training accuracy: 0.894602048857368\n",
            "Validation loss: 465.7146107852459\n",
            "Validation accuracy: 0.780929866036249\n",
            "Epoch 345/499\n",
            "----------\n",
            "Training loss: 378.9297178387642\n",
            "Training accuracy: 0.8904156816390859\n",
            "Validation loss: 449.254287391901\n",
            "Validation accuracy: 0.8156028368794326\n",
            "Epoch 346/499\n",
            "----------\n",
            "Training loss: 376.62600472569466\n",
            "Training accuracy: 0.8942080378250591\n",
            "Validation loss: 457.2846482992172\n",
            "Validation accuracy: 0.8043735224586288\n",
            "Epoch 347/499\n",
            "----------\n",
            "Training loss: 376.3063088953495\n",
            "Training accuracy: 0.8924842395587076\n",
            "Validation loss: 468.99486523866653\n",
            "Validation accuracy: 0.7862490149724193\n",
            "Epoch 348/499\n",
            "----------\n",
            "Training loss: 377.09504702687263\n",
            "Training accuracy: 0.8910066981875493\n",
            "Validation loss: 462.25433737039566\n",
            "Validation accuracy: 0.7856579984239559\n",
            "Epoch 349/499\n",
            "----------\n",
            "Training loss: 374.98457461595535\n",
            "Training accuracy: 0.8957348305752562\n",
            "Validation loss: 464.0091046690941\n",
            "Validation accuracy: 0.7825059101654847\n",
            "Epoch 350/499\n",
            "----------\n",
            "Training loss: 373.9483016729355\n",
            "Training accuracy: 0.8954393223010244\n",
            "Validation loss: 455.5887063741684\n",
            "Validation accuracy: 0.801812450748621\n",
            "Epoch 351/499\n",
            "----------\n",
            "Training loss: 375.29054695367813\n",
            "Training accuracy: 0.8943065405831363\n",
            "Validation loss: 468.82267168164253\n",
            "Validation accuracy: 0.7807328605200946\n",
            "Epoch 352/499\n",
            "----------\n",
            "Training loss: 374.8588538169861\n",
            "Training accuracy: 0.8955378250591016\n",
            "Validation loss: 448.4380461871624\n",
            "Validation accuracy: 0.8104806934594169\n",
            "Epoch 353/499\n",
            "----------\n",
            "Training loss: 374.3128410577774\n",
            "Training accuracy: 0.8958825847123719\n",
            "Validation loss: 452.1757895350456\n",
            "Validation accuracy: 0.7943262411347518\n",
            "Epoch 354/499\n",
            "----------\n",
            "Training loss: 373.33271729946136\n",
            "Training accuracy: 0.89701536643026\n",
            "Validation loss: 457.43603974580765\n",
            "Validation accuracy: 0.7929472025216706\n",
            "Epoch 355/499\n",
            "----------\n",
            "Training loss: 371.758979678154\n",
            "Training accuracy: 0.897901891252955\n",
            "Validation loss: 451.28671649098396\n",
            "Validation accuracy: 0.8010244286840031\n",
            "Epoch 356/499\n",
            "----------\n",
            "Training loss: 373.8927193284035\n",
            "Training accuracy: 0.8959318360914106\n",
            "Validation loss: 463.8880614936352\n",
            "Validation accuracy: 0.7848699763593381\n",
            "Epoch 357/499\n",
            "----------\n",
            "Training loss: 371.29981738328934\n",
            "Training accuracy: 0.8976063829787234\n",
            "Validation loss: 445.79614663124084\n",
            "Validation accuracy: 0.8157998423955871\n",
            "Epoch 358/499\n",
            "----------\n",
            "Training loss: 372.11548122763634\n",
            "Training accuracy: 0.8960795902285263\n",
            "Validation loss: 451.0250469148159\n",
            "Validation accuracy: 0.8059495665878644\n",
            "Epoch 359/499\n",
            "----------\n",
            "Training loss: 370.9832275211811\n",
            "Training accuracy: 0.8969168636721828\n",
            "Validation loss: 472.5904183089733\n",
            "Validation accuracy: 0.764381402679275\n",
            "Epoch 360/499\n",
            "----------\n",
            "Training loss: 370.01056334376335\n",
            "Training accuracy: 0.8969661150512215\n",
            "Validation loss: 454.14645090699196\n",
            "Validation accuracy: 0.7947202521670607\n",
            "Epoch 361/499\n",
            "----------\n",
            "Training loss: 371.2572807073593\n",
            "Training accuracy: 0.896128841607565\n",
            "Validation loss: 453.53771138191223\n",
            "Validation accuracy: 0.7921591804570528\n",
            "Epoch 362/499\n",
            "----------\n",
            "Training loss: 370.72050151228905\n",
            "Training accuracy: 0.8980003940110323\n",
            "Validation loss: 447.79195326566696\n",
            "Validation accuracy: 0.8120567375886525\n",
            "Epoch 363/499\n",
            "----------\n",
            "Training loss: 370.36992809176445\n",
            "Training accuracy: 0.8981973995271868\n",
            "Validation loss: 465.01728573441505\n",
            "Validation accuracy: 0.7874310480693459\n",
            "Epoch 364/499\n",
            "----------\n",
            "Training loss: 370.7367804348469\n",
            "Training accuracy: 0.8989854215918046\n",
            "Validation loss: 445.5456604361534\n",
            "Validation accuracy: 0.8165878644602049\n",
            "Epoch 365/499\n",
            "----------\n",
            "Training loss: 369.2072640955448\n",
            "Training accuracy: 0.8978526398739165\n",
            "Validation loss: 460.64984554052353\n",
            "Validation accuracy: 0.7838849487785658\n",
            "Epoch 366/499\n",
            "----------\n",
            "Training loss: 370.80517545342445\n",
            "Training accuracy: 0.8975078802206462\n",
            "Validation loss: 442.43510365486145\n",
            "Validation accuracy: 0.8187549251379038\n",
            "Epoch 367/499\n",
            "----------\n",
            "Training loss: 367.778863966465\n",
            "Training accuracy: 0.9017434988179669\n",
            "Validation loss: 448.2614246606827\n",
            "Validation accuracy: 0.7994483845547675\n",
            "Epoch 368/499\n",
            "----------\n",
            "Training loss: 367.0944267511368\n",
            "Training accuracy: 0.9005122143420016\n",
            "Validation loss: 466.60669896006584\n",
            "Validation accuracy: 0.7639873916469662\n",
            "Epoch 369/499\n",
            "----------\n",
            "Training loss: 367.8221145570278\n",
            "Training accuracy: 0.9004629629629629\n",
            "Validation loss: 460.2100422382355\n",
            "Validation accuracy: 0.7758077226162332\n",
            "Epoch 370/499\n",
            "----------\n",
            "Training loss: 367.3679232597351\n",
            "Training accuracy: 0.9012509850275807\n",
            "Validation loss: 443.25822100043297\n",
            "Validation accuracy: 0.8197399527186762\n",
            "Epoch 371/499\n",
            "----------\n",
            "Training loss: 366.0148912370205\n",
            "Training accuracy: 0.9010539795114263\n",
            "Validation loss: 445.8372028172016\n",
            "Validation accuracy: 0.8094956658786446\n",
            "Epoch 372/499\n",
            "----------\n",
            "Training loss: 364.3855121731758\n",
            "Training accuracy: 0.9027777777777778\n",
            "Validation loss: 450.8075225055218\n",
            "Validation accuracy: 0.7964933018124507\n",
            "Epoch 373/499\n",
            "----------\n",
            "Training loss: 367.3325341939926\n",
            "Training accuracy: 0.9010539795114263\n",
            "Validation loss: 468.25558495521545\n",
            "Validation accuracy: 0.7693065405831363\n",
            "Epoch 374/499\n",
            "----------\n",
            "Training loss: 367.3504829108715\n",
            "Training accuracy: 0.8996749408983451\n",
            "Validation loss: 472.8338279426098\n",
            "Validation accuracy: 0.7710795902285263\n",
            "Epoch 375/499\n",
            "----------\n",
            "Training loss: 366.1551478803158\n",
            "Training accuracy: 0.900709219858156\n",
            "Validation loss: 457.3275668025017\n",
            "Validation accuracy: 0.7797478329393223\n",
            "Epoch 376/499\n",
            "----------\n",
            "Training loss: 365.33002442121506\n",
            "Training accuracy: 0.9029255319148937\n",
            "Validation loss: 452.45218965411186\n",
            "Validation accuracy: 0.7949172576832151\n",
            "Epoch 377/499\n",
            "----------\n",
            "Training loss: 365.36093455553055\n",
            "Training accuracy: 0.9018420015760441\n",
            "Validation loss: 440.7937182188034\n",
            "Validation accuracy: 0.8069345941686368\n",
            "Epoch 378/499\n",
            "----------\n",
            "Training loss: 365.0697820484638\n",
            "Training accuracy: 0.901103230890465\n",
            "Validation loss: 461.0182599723339\n",
            "Validation accuracy: 0.791371158392435\n",
            "Epoch 379/499\n",
            "----------\n",
            "Training loss: 364.23714902997017\n",
            "Training accuracy: 0.9030240346729709\n",
            "Validation loss: 452.6970355808735\n",
            "Validation accuracy: 0.7864460204885737\n",
            "Epoch 380/499\n",
            "----------\n",
            "Training loss: 364.2865462899208\n",
            "Training accuracy: 0.9036643026004728\n",
            "Validation loss: 460.602489978075\n",
            "Validation accuracy: 0.7819148936170213\n",
            "Epoch 381/499\n",
            "----------\n",
            "Training loss: 364.7302507162094\n",
            "Training accuracy: 0.9037135539795115\n",
            "Validation loss: 446.7662253379822\n",
            "Validation accuracy: 0.8091016548463357\n",
            "Epoch 382/499\n",
            "----------\n",
            "Training loss: 363.65460646152496\n",
            "Training accuracy: 0.9029255319148937\n",
            "Validation loss: 452.9544268846512\n",
            "Validation accuracy: 0.7868400315208826\n",
            "Epoch 383/499\n",
            "----------\n",
            "Training loss: 362.3062475025654\n",
            "Training accuracy: 0.9036150512214342\n",
            "Validation loss: 438.19807782769203\n",
            "Validation accuracy: 0.8165878644602049\n",
            "Epoch 384/499\n",
            "----------\n",
            "Training loss: 361.6557959318161\n",
            "Training accuracy: 0.9033687943262412\n",
            "Validation loss: 451.76989164948463\n",
            "Validation accuracy: 0.8051615445232466\n",
            "Epoch 385/499\n",
            "----------\n",
            "Training loss: 361.6196101605892\n",
            "Training accuracy: 0.9062746256895193\n",
            "Validation loss: 445.7564219534397\n",
            "Validation accuracy: 0.8027974783293932\n",
            "Epoch 386/499\n",
            "----------\n",
            "Training loss: 362.8303517997265\n",
            "Training accuracy: 0.902876280535855\n",
            "Validation loss: 439.43922421336174\n",
            "Validation accuracy: 0.814026792750197\n",
            "Epoch 387/499\n",
            "----------\n",
            "Training loss: 360.98546275496483\n",
            "Training accuracy: 0.9056343577620173\n",
            "Validation loss: 437.9519822001457\n",
            "Validation accuracy: 0.8098896769109535\n",
            "Epoch 388/499\n",
            "----------\n",
            "Training loss: 361.7344700098038\n",
            "Training accuracy: 0.9039598108747045\n",
            "Validation loss: 439.3981057703495\n",
            "Validation accuracy: 0.8037825059101655\n",
            "Epoch 389/499\n",
            "----------\n",
            "Training loss: 360.1208173930645\n",
            "Training accuracy: 0.9060776201733649\n",
            "Validation loss: 442.53298634290695\n",
            "Validation accuracy: 0.8004334121355398\n",
            "Epoch 390/499\n",
            "----------\n",
            "Training loss: 359.9530098736286\n",
            "Training accuracy: 0.9052895981087471\n",
            "Validation loss: 439.3927520811558\n",
            "Validation accuracy: 0.8209219858156028\n",
            "Epoch 391/499\n",
            "----------\n",
            "Training loss: 359.5673641562462\n",
            "Training accuracy: 0.9077029156816391\n",
            "Validation loss: 445.0413983762264\n",
            "Validation accuracy: 0.7947202521670607\n",
            "Epoch 392/499\n",
            "----------\n",
            "Training loss: 360.28601720929146\n",
            "Training accuracy: 0.905929866036249\n",
            "Validation loss: 438.3410409986973\n",
            "Validation accuracy: 0.8173758865248227\n",
            "Epoch 393/499\n",
            "----------\n",
            "Training loss: 359.13724356889725\n",
            "Training accuracy: 0.9059791174152876\n",
            "Validation loss: 442.805551469326\n",
            "Validation accuracy: 0.8071315996847912\n",
            "Epoch 394/499\n",
            "----------\n",
            "Training loss: 358.28870487213135\n",
            "Training accuracy: 0.906570133963751\n",
            "Validation loss: 460.32833406329155\n",
            "Validation accuracy: 0.7677304964539007\n",
            "Epoch 395/499\n",
            "----------\n",
            "Training loss: 359.00577276945114\n",
            "Training accuracy: 0.9053388494877856\n",
            "Validation loss: 440.4755555689335\n",
            "Validation accuracy: 0.8120567375886525\n",
            "Epoch 396/499\n",
            "----------\n",
            "Training loss: 358.63928017020226\n",
            "Training accuracy: 0.9047970843183609\n",
            "Validation loss: 441.11675494909286\n",
            "Validation accuracy: 0.8136327817178881\n",
            "Epoch 397/499\n",
            "----------\n",
            "Training loss: 358.7556765973568\n",
            "Training accuracy: 0.9055358550039401\n",
            "Validation loss: 436.988100707531\n",
            "Validation accuracy: 0.8173758865248227\n",
            "Epoch 398/499\n",
            "----------\n",
            "Training loss: 356.85281047225\n",
            "Training accuracy: 0.9078014184397163\n",
            "Validation loss: 441.5941058397293\n",
            "Validation accuracy: 0.8055555555555556\n",
            "Epoch 399/499\n",
            "----------\n",
            "Training loss: 357.06432923674583\n",
            "Training accuracy: 0.9076044129235619\n",
            "Validation loss: 440.874736815691\n",
            "Validation accuracy: 0.8083136327817179\n",
            "Epoch 400/499\n",
            "----------\n",
            "Training loss: 357.8521149754524\n",
            "Training accuracy: 0.9079491725768322\n",
            "Validation loss: 437.7051177918911\n",
            "Validation accuracy: 0.8199369582348306\n",
            "Epoch 401/499\n",
            "----------\n",
            "Training loss: 356.44245660305023\n",
            "Training accuracy: 0.9065208825847124\n",
            "Validation loss: 438.53450641036034\n",
            "Validation accuracy: 0.8138297872340425\n",
            "Epoch 402/499\n",
            "----------\n",
            "Training loss: 355.6352014839649\n",
            "Training accuracy: 0.9083924349881797\n",
            "Validation loss: 435.4017645716667\n",
            "Validation accuracy: 0.8159968479117415\n",
            "Epoch 403/499\n",
            "----------\n",
            "Training loss: 355.63221830129623\n",
            "Training accuracy: 0.9102639873916469\n",
            "Validation loss: 447.7212837934494\n",
            "Validation accuracy: 0.8010244286840031\n",
            "Epoch 404/499\n",
            "----------\n",
            "Training loss: 355.23084074258804\n",
            "Training accuracy: 0.9079984239558707\n",
            "Validation loss: 435.8234221339226\n",
            "Validation accuracy: 0.8167848699763594\n",
            "Epoch 405/499\n",
            "----------\n",
            "Training loss: 356.0370633304119\n",
            "Training accuracy: 0.9088849487785658\n",
            "Validation loss: 436.84663486480713\n",
            "Validation accuracy: 0.8114657210401891\n",
            "Epoch 406/499\n",
            "----------\n",
            "Training loss: 354.9984409213066\n",
            "Training accuracy: 0.9111997635933806\n",
            "Validation loss: 447.7979807853699\n",
            "Validation accuracy: 0.8014184397163121\n",
            "Epoch 407/499\n",
            "----------\n",
            "Training loss: 355.7550125718117\n",
            "Training accuracy: 0.9063731284475965\n",
            "Validation loss: 436.2562952041626\n",
            "Validation accuracy: 0.8104806934594169\n",
            "Epoch 408/499\n",
            "----------\n",
            "Training loss: 354.5328423678875\n",
            "Training accuracy: 0.9103132387706856\n",
            "Validation loss: 436.37400805950165\n",
            "Validation accuracy: 0.8092986603624901\n",
            "Epoch 409/499\n",
            "----------\n",
            "Training loss: 354.08369597792625\n",
            "Training accuracy: 0.9089834515366431\n",
            "Validation loss: 444.4612926840782\n",
            "Validation accuracy: 0.7990543735224587\n",
            "Epoch 410/499\n",
            "----------\n",
            "Training loss: 352.4151164293289\n",
            "Training accuracy: 0.9112982663514578\n",
            "Validation loss: 436.28603249788284\n",
            "Validation accuracy: 0.8154058313632782\n",
            "Epoch 411/499\n",
            "----------\n",
            "Training loss: 352.41293543577194\n",
            "Training accuracy: 0.9112490149724193\n",
            "Validation loss: 429.49065843224525\n",
            "Validation accuracy: 0.8191489361702128\n",
            "Epoch 412/499\n",
            "----------\n",
            "Training loss: 352.7574007809162\n",
            "Training accuracy: 0.911150512214342\n",
            "Validation loss: 432.74150252342224\n",
            "Validation accuracy: 0.8193459416863672\n",
            "Epoch 413/499\n",
            "----------\n",
            "Training loss: 351.47080969810486\n",
            "Training accuracy: 0.9132190701339638\n",
            "Validation loss: 434.5280748307705\n",
            "Validation accuracy: 0.8136327817178881\n",
            "Epoch 414/499\n",
            "----------\n",
            "Training loss: 353.1088904738426\n",
            "Training accuracy: 0.9098207249802994\n",
            "Validation loss: 443.7958001792431\n",
            "Validation accuracy: 0.8055555555555556\n",
            "Epoch 415/499\n",
            "----------\n",
            "Training loss: 353.6318348944187\n",
            "Training accuracy: 0.9107072498029944\n",
            "Validation loss: 432.6072014570236\n",
            "Validation accuracy: 0.8177698975571316\n",
            "Epoch 416/499\n",
            "----------\n",
            "Training loss: 353.1841910779476\n",
            "Training accuracy: 0.9101162332545312\n",
            "Validation loss: 436.5171097815037\n",
            "Validation accuracy: 0.8087076438140268\n",
            "Epoch 417/499\n",
            "----------\n",
            "Training loss: 351.03094866871834\n",
            "Training accuracy: 0.9120862884160756\n",
            "Validation loss: 439.5801944434643\n",
            "Validation accuracy: 0.8094956658786446\n",
            "Epoch 418/499\n",
            "----------\n",
            "Training loss: 352.9313280582428\n",
            "Training accuracy: 0.9110027580772262\n",
            "Validation loss: 427.4990374147892\n",
            "Validation accuracy: 0.8266351457840819\n",
            "Epoch 419/499\n",
            "----------\n",
            "Training loss: 352.5555144548416\n",
            "Training accuracy: 0.9113475177304965\n",
            "Validation loss: 436.3970995545387\n",
            "Validation accuracy: 0.8067375886524822\n",
            "Epoch 420/499\n",
            "----------\n",
            "Training loss: 352.32736414670944\n",
            "Training accuracy: 0.9110027580772262\n",
            "Validation loss: 432.6701437532902\n",
            "Validation accuracy: 0.8236800630417652\n",
            "Epoch 421/499\n",
            "----------\n",
            "Training loss: 352.6473459601402\n",
            "Training accuracy: 0.9137608353033885\n",
            "Validation loss: 443.68787840008736\n",
            "Validation accuracy: 0.8045705279747833\n",
            "Epoch 422/499\n",
            "----------\n",
            "Training loss: 349.509219199419\n",
            "Training accuracy: 0.9132190701339638\n",
            "Validation loss: 443.93150839209557\n",
            "Validation accuracy: 0.8002364066193853\n",
            "Epoch 423/499\n",
            "----------\n",
            "Training loss: 349.3704923093319\n",
            "Training accuracy: 0.9135145784081954\n",
            "Validation loss: 428.1801708936691\n",
            "Validation accuracy: 0.8230890464933018\n",
            "Epoch 424/499\n",
            "----------\n",
            "Training loss: 349.9257565140724\n",
            "Training accuracy: 0.912677304964539\n",
            "Validation loss: 437.12084823846817\n",
            "Validation accuracy: 0.8169818754925138\n",
            "Epoch 425/499\n",
            "----------\n",
            "Training loss: 350.03410118818283\n",
            "Training accuracy: 0.9110520094562647\n",
            "Validation loss: 438.8574825525284\n",
            "Validation accuracy: 0.7978723404255319\n",
            "Epoch 426/499\n",
            "----------\n",
            "Training loss: 348.9004196226597\n",
            "Training accuracy: 0.915090622537431\n",
            "Validation loss: 432.569632768631\n",
            "Validation accuracy: 0.8224980299448384\n",
            "Epoch 427/499\n",
            "----------\n",
            "Training loss: 349.5171188414097\n",
            "Training accuracy: 0.9154353821907013\n",
            "Validation loss: 446.92609190940857\n",
            "Validation accuracy: 0.7876280535855004\n",
            "Epoch 428/499\n",
            "----------\n",
            "Training loss: 349.07351836562157\n",
            "Training accuracy: 0.9147951142631994\n",
            "Validation loss: 436.0194490849972\n",
            "Validation accuracy: 0.8069345941686368\n",
            "Epoch 429/499\n",
            "----------\n",
            "Training loss: 348.19621282815933\n",
            "Training accuracy: 0.9130713159968479\n",
            "Validation loss: 437.8072524666786\n",
            "Validation accuracy: 0.8150118203309693\n",
            "Epoch 430/499\n",
            "----------\n",
            "Training loss: 347.9510189294815\n",
            "Training accuracy: 0.9149428684003152\n",
            "Validation loss: 434.3948199748993\n",
            "Validation accuracy: 0.8236800630417652\n",
            "Epoch 431/499\n",
            "----------\n",
            "Training loss: 347.21247121691704\n",
            "Training accuracy: 0.9166174152876281\n",
            "Validation loss: 456.3607901632786\n",
            "Validation accuracy: 0.7750197005516154\n",
            "Epoch 432/499\n",
            "----------\n",
            "Training loss: 347.67385786771774\n",
            "Training accuracy: 0.9140070921985816\n",
            "Validation loss: 443.50832119584084\n",
            "Validation accuracy: 0.7929472025216706\n",
            "Epoch 433/499\n",
            "----------\n",
            "Training loss: 347.14974626898766\n",
            "Training accuracy: 0.9139085894405043\n",
            "Validation loss: 422.94209825992584\n",
            "Validation accuracy: 0.8353033884948778\n",
            "Epoch 434/499\n",
            "----------\n",
            "Training loss: 346.76278457045555\n",
            "Training accuracy: 0.9146966115051222\n",
            "Validation loss: 460.52470192313194\n",
            "Validation accuracy: 0.7683215130023641\n",
            "Epoch 435/499\n",
            "----------\n",
            "Training loss: 348.4314275085926\n",
            "Training accuracy: 0.9144011032308904\n",
            "Validation loss: 434.38885620236397\n",
            "Validation accuracy: 0.8059495665878644\n",
            "Epoch 436/499\n",
            "----------\n",
            "Training loss: 346.1685004532337\n",
            "Training accuracy: 0.9164696611505122\n",
            "Validation loss: 441.589147567749\n",
            "Validation accuracy: 0.799645390070922\n",
            "Epoch 437/499\n",
            "----------\n",
            "Training loss: 347.7355834543705\n",
            "Training accuracy: 0.9131205673758865\n",
            "Validation loss: 427.36404141783714\n",
            "Validation accuracy: 0.8250591016548463\n",
            "Epoch 438/499\n",
            "----------\n",
            "Training loss: 346.3047888278961\n",
            "Training accuracy: 0.9160756501182034\n",
            "Validation loss: 437.31881695985794\n",
            "Validation accuracy: 0.820133963750985\n",
            "Epoch 439/499\n",
            "----------\n",
            "Training loss: 345.20529195666313\n",
            "Training accuracy: 0.9154353821907013\n",
            "Validation loss: 429.15446919202805\n",
            "Validation accuracy: 0.8187549251379038\n",
            "Epoch 440/499\n",
            "----------\n",
            "Training loss: 347.4315772354603\n",
            "Training accuracy: 0.9143518518518519\n",
            "Validation loss: 437.6148978173733\n",
            "Validation accuracy: 0.8077226162332545\n",
            "Epoch 441/499\n",
            "----------\n",
            "Training loss: 346.84879690408707\n",
            "Training accuracy: 0.9132683215130024\n",
            "Validation loss: 431.1593104302883\n",
            "Validation accuracy: 0.8224980299448384\n",
            "Epoch 442/499\n",
            "----------\n",
            "Training loss: 348.3616618216038\n",
            "Training accuracy: 0.9123817966903073\n",
            "Validation loss: 430.3032723367214\n",
            "Validation accuracy: 0.8181639085894405\n",
            "Epoch 443/499\n",
            "----------\n",
            "Training loss: 345.9595088362694\n",
            "Training accuracy: 0.917651694247439\n",
            "Validation loss: 431.1888666152954\n",
            "Validation accuracy: 0.8118597320724981\n",
            "Epoch 444/499\n",
            "----------\n",
            "Training loss: 346.41156670451164\n",
            "Training accuracy: 0.9147951142631994\n",
            "Validation loss: 431.16994962096214\n",
            "Validation accuracy: 0.8250591016548463\n",
            "Epoch 445/499\n",
            "----------\n",
            "Training loss: 345.36276763677597\n",
            "Training accuracy: 0.9172084318360915\n",
            "Validation loss: 437.7651677429676\n",
            "Validation accuracy: 0.8043735224586288\n",
            "Epoch 446/499\n",
            "----------\n",
            "Training loss: 343.9624854028225\n",
            "Training accuracy: 0.9155338849487785\n",
            "Validation loss: 441.9681459367275\n",
            "Validation accuracy: 0.8065405831363278\n",
            "Epoch 447/499\n",
            "----------\n",
            "Training loss: 343.9875057935715\n",
            "Training accuracy: 0.9162726556343578\n",
            "Validation loss: 429.62485831975937\n",
            "Validation accuracy: 0.8268321513002365\n",
            "Epoch 448/499\n",
            "----------\n",
            "Training loss: 345.08996948599815\n",
            "Training accuracy: 0.9162234042553191\n",
            "Validation loss: 424.94024443626404\n",
            "Validation accuracy: 0.824468085106383\n",
            "Epoch 449/499\n",
            "----------\n",
            "Training loss: 344.62314969301224\n",
            "Training accuracy: 0.9156816390858944\n",
            "Validation loss: 425.2545656263828\n",
            "Validation accuracy: 0.8268321513002365\n",
            "Epoch 450/499\n",
            "----------\n",
            "Training loss: 344.9417137503624\n",
            "Training accuracy: 0.9151398739164697\n",
            "Validation loss: 465.5184742808342\n",
            "Validation accuracy: 0.7490149724192278\n",
            "Epoch 451/499\n",
            "----------\n",
            "Training loss: 342.95514729619026\n",
            "Training accuracy: 0.9190799842395587\n",
            "Validation loss: 427.1667949259281\n",
            "Validation accuracy: 0.8226950354609929\n",
            "Epoch 452/499\n",
            "----------\n",
            "Training loss: 342.2283950150013\n",
            "Training accuracy: 0.9192769897557131\n",
            "Validation loss: 438.0687725841999\n",
            "Validation accuracy: 0.7998423955870765\n",
            "Epoch 453/499\n",
            "----------\n",
            "Training loss: 343.6395780444145\n",
            "Training accuracy: 0.917897951142632\n",
            "Validation loss: 429.87402641773224\n",
            "Validation accuracy: 0.8175728920409772\n",
            "Epoch 454/499\n",
            "----------\n",
            "Training loss: 342.46800154447556\n",
            "Training accuracy: 0.9185874704491725\n",
            "Validation loss: 430.61594542860985\n",
            "Validation accuracy: 0.8108747044917257\n",
            "Epoch 455/499\n",
            "----------\n",
            "Training loss: 342.14647656679153\n",
            "Training accuracy: 0.9201635145784082\n",
            "Validation loss: 417.2229284644127\n",
            "Validation accuracy: 0.8400315208825847\n",
            "Epoch 456/499\n",
            "----------\n",
            "Training loss: 343.6756466627121\n",
            "Training accuracy: 0.9189322301024428\n",
            "Validation loss: 420.5414994060993\n",
            "Validation accuracy: 0.8295902285263987\n",
            "Epoch 457/499\n",
            "----------\n",
            "Training loss: 343.4699587225914\n",
            "Training accuracy: 0.9169621749408984\n",
            "Validation loss: 431.33116695284843\n",
            "Validation accuracy: 0.8169818754925138\n",
            "Epoch 458/499\n",
            "----------\n",
            "Training loss: 340.86958453059196\n",
            "Training accuracy: 0.9201142631993696\n",
            "Validation loss: 448.3614976108074\n",
            "Validation accuracy: 0.780929866036249\n",
            "Epoch 459/499\n",
            "----------\n",
            "Training loss: 342.01771929860115\n",
            "Training accuracy: 0.9196217494089834\n",
            "Validation loss: 439.2027007341385\n",
            "Validation accuracy: 0.8053585500394012\n",
            "Epoch 460/499\n",
            "----------\n",
            "Training loss: 342.416197180748\n",
            "Training accuracy: 0.9196710007880221\n",
            "Validation loss: 464.42580765485764\n",
            "Validation accuracy: 0.7537431048069346\n",
            "Epoch 461/499\n",
            "----------\n",
            "Training loss: 341.7451890707016\n",
            "Training accuracy: 0.9177501970055162\n",
            "Validation loss: 420.18806916475296\n",
            "Validation accuracy: 0.8337273443656422\n",
            "Epoch 462/499\n",
            "----------\n",
            "Training loss: 342.16735434532166\n",
            "Training accuracy: 0.9190799842395587\n",
            "Validation loss: 422.12942230701447\n",
            "Validation accuracy: 0.8396375098502759\n",
            "Epoch 463/499\n",
            "----------\n",
            "Training loss: 340.7374592125416\n",
            "Training accuracy: 0.9191292356185973\n",
            "Validation loss: 420.97895166277885\n",
            "Validation accuracy: 0.8370764381402679\n",
            "Epoch 464/499\n",
            "----------\n",
            "Training loss: 341.8802133202553\n",
            "Training accuracy: 0.9207545311268716\n",
            "Validation loss: 451.9883911907673\n",
            "Validation accuracy: 0.7775807722616234\n",
            "Epoch 465/499\n",
            "----------\n",
            "Training loss: 341.7142399251461\n",
            "Training accuracy: 0.9209022852639874\n",
            "Validation loss: 433.69472989439964\n",
            "Validation accuracy: 0.8134357762017337\n",
            "Epoch 466/499\n",
            "----------\n",
            "Training loss: 341.3539383113384\n",
            "Training accuracy: 0.9180949566587865\n",
            "Validation loss: 424.9145458936691\n",
            "Validation accuracy: 0.8226950354609929\n",
            "Epoch 467/499\n",
            "----------\n",
            "Training loss: 338.84924787282944\n",
            "Training accuracy: 0.9229215918045706\n",
            "Validation loss: 421.9672965705395\n",
            "Validation accuracy: 0.8266351457840819\n",
            "Epoch 468/499\n",
            "----------\n",
            "Training loss: 341.18638813495636\n",
            "Training accuracy: 0.920311268715524\n",
            "Validation loss: 424.4167973995209\n",
            "Validation accuracy: 0.8240740740740741\n",
            "Epoch 469/499\n",
            "----------\n",
            "Training loss: 339.46122592687607\n",
            "Training accuracy: 0.9200157604412924\n",
            "Validation loss: 425.5693052113056\n",
            "Validation accuracy: 0.8272261623325453\n",
            "Epoch 470/499\n",
            "----------\n",
            "Training loss: 339.47368535399437\n",
            "Training accuracy: 0.9212470449172577\n",
            "Validation loss: 427.0242186486721\n",
            "Validation accuracy: 0.8226950354609929\n",
            "Epoch 471/499\n",
            "----------\n",
            "Training loss: 337.089328199625\n",
            "Training accuracy: 0.922478329393223\n",
            "Validation loss: 434.2092943787575\n",
            "Validation accuracy: 0.7998423955870765\n",
            "Epoch 472/499\n",
            "----------\n",
            "Training loss: 339.15956991910934\n",
            "Training accuracy: 0.9186859732072498\n",
            "Validation loss: 434.4126017987728\n",
            "Validation accuracy: 0.8012214342001576\n",
            "Epoch 473/499\n",
            "----------\n",
            "Training loss: 337.3996950685978\n",
            "Training accuracy: 0.9228723404255319\n",
            "Validation loss: 417.80472058057785\n",
            "Validation accuracy: 0.8337273443656422\n",
            "Epoch 474/499\n",
            "----------\n",
            "Training loss: 338.13572576642036\n",
            "Training accuracy: 0.9213947990543735\n",
            "Validation loss: 427.2552194595337\n",
            "Validation accuracy: 0.8262411347517731\n",
            "Epoch 475/499\n",
            "----------\n",
            "Training loss: 338.02255472540855\n",
            "Training accuracy: 0.9235126083530338\n",
            "Validation loss: 417.7232400774956\n",
            "Validation accuracy: 0.8307722616233254\n",
            "Epoch 476/499\n",
            "----------\n",
            "Training loss: 338.31559294462204\n",
            "Training accuracy: 0.9210992907801419\n",
            "Validation loss: 417.89343297481537\n",
            "Validation accuracy: 0.8386524822695035\n",
            "Epoch 477/499\n",
            "----------\n",
            "Training loss: 338.0743356347084\n",
            "Training accuracy: 0.9205575256107171\n",
            "Validation loss: 427.700077265501\n",
            "Validation accuracy: 0.8116627265563435\n",
            "Epoch 478/499\n",
            "----------\n",
            "Training loss: 336.1955479979515\n",
            "Training accuracy: 0.9234633569739953\n",
            "Validation loss: 435.444867759943\n",
            "Validation accuracy: 0.8130417651694247\n",
            "Epoch 479/499\n",
            "----------\n",
            "Training loss: 337.68997102975845\n",
            "Training accuracy: 0.922724586288416\n",
            "Validation loss: 419.20705115795135\n",
            "Validation accuracy: 0.8307722616233254\n",
            "Epoch 480/499\n",
            "----------\n",
            "Training loss: 338.10637643933296\n",
            "Training accuracy: 0.921591804570528\n",
            "Validation loss: 447.2279403656721\n",
            "Validation accuracy: 0.7834909377462569\n",
            "Epoch 481/499\n",
            "----------\n",
            "Training loss: 336.42381861805916\n",
            "Training accuracy: 0.9242513790386131\n",
            "Validation loss: 428.257199048996\n",
            "Validation accuracy: 0.8173758865248227\n",
            "Epoch 482/499\n",
            "----------\n",
            "Training loss: 338.0745639204979\n",
            "Training accuracy: 0.9210992907801419\n",
            "Validation loss: 438.60423868894577\n",
            "Validation accuracy: 0.7957052797478329\n",
            "Epoch 483/499\n",
            "----------\n",
            "Training loss: 335.5309916436672\n",
            "Training accuracy: 0.924645390070922\n",
            "Validation loss: 432.49296510219574\n",
            "Validation accuracy: 0.8110717100078803\n",
            "Epoch 484/499\n",
            "----------\n",
            "Training loss: 337.56897309422493\n",
            "Training accuracy: 0.9218873128447597\n",
            "Validation loss: 444.9933507889509\n",
            "Validation accuracy: 0.7738376674546887\n",
            "Epoch 485/499\n",
            "----------\n",
            "Training loss: 336.1423580646515\n",
            "Training accuracy: 0.9213947990543735\n",
            "Validation loss: 426.00363940000534\n",
            "Validation accuracy: 0.8211189913317573\n",
            "Epoch 486/499\n",
            "----------\n",
            "Training loss: 337.00278756022453\n",
            "Training accuracy: 0.9239558707643813\n",
            "Validation loss: 421.95808732509613\n",
            "Validation accuracy: 0.8215130023640662\n",
            "Epoch 487/499\n",
            "----------\n",
            "Training loss: 335.762581795454\n",
            "Training accuracy: 0.9235126083530338\n",
            "Validation loss: 418.4774975478649\n",
            "Validation accuracy: 0.8260441292356187\n",
            "Epoch 488/499\n",
            "----------\n",
            "Training loss: 336.02770537137985\n",
            "Training accuracy: 0.9227738376674547\n",
            "Validation loss: 418.2685761451721\n",
            "Validation accuracy: 0.8353033884948778\n",
            "Epoch 489/499\n",
            "----------\n",
            "Training loss: 336.9610463678837\n",
            "Training accuracy: 0.9221335697399528\n",
            "Validation loss: 419.2588814198971\n",
            "Validation accuracy: 0.8297872340425532\n",
            "Epoch 490/499\n",
            "----------\n",
            "Training loss: 335.36366787552834\n",
            "Training accuracy: 0.9218873128447597\n",
            "Validation loss: 432.33226826786995\n",
            "Validation accuracy: 0.814026792750197\n",
            "Epoch 491/499\n",
            "----------\n",
            "Training loss: 335.4767629802227\n",
            "Training accuracy: 0.9238081166272656\n",
            "Validation loss: 431.3445480763912\n",
            "Validation accuracy: 0.8130417651694247\n",
            "Epoch 492/499\n",
            "----------\n",
            "Training loss: 336.6296007633209\n",
            "Training accuracy: 0.9213455476753349\n",
            "Validation loss: 418.34600818157196\n",
            "Validation accuracy: 0.8297872340425532\n",
            "Epoch 493/499\n",
            "----------\n",
            "Training loss: 334.1713341474533\n",
            "Training accuracy: 0.924645390070922\n",
            "Validation loss: 448.4650750756264\n",
            "Validation accuracy: 0.7799448384554768\n",
            "Epoch 494/499\n",
            "----------\n",
            "Training loss: 334.402989000082\n",
            "Training accuracy: 0.9253349093774625\n",
            "Validation loss: 416.81055849790573\n",
            "Validation accuracy: 0.8368794326241135\n",
            "Epoch 495/499\n",
            "----------\n",
            "Training loss: 334.5504116117954\n",
            "Training accuracy: 0.9237096138691884\n",
            "Validation loss: 411.161266207695\n",
            "Validation accuracy: 0.8378644602048857\n",
            "Epoch 496/499\n",
            "----------\n",
            "Training loss: 333.81252458691597\n",
            "Training accuracy: 0.9253841607565012\n",
            "Validation loss: 422.41213831305504\n",
            "Validation accuracy: 0.8264381402679275\n",
            "Epoch 497/499\n",
            "----------\n",
            "Training loss: 333.2014458477497\n",
            "Training accuracy: 0.9234141055949566\n",
            "Validation loss: 422.80629459023476\n",
            "Validation accuracy: 0.8157998423955871\n",
            "Epoch 498/499\n",
            "----------\n",
            "Training loss: 334.38831117749214\n",
            "Training accuracy: 0.9238573680063041\n",
            "Validation loss: 417.11436754465103\n",
            "Validation accuracy: 0.8402285263987391\n",
            "Epoch 499/499\n",
            "----------\n",
            "Training loss: 334.5765996873379\n",
            "Training accuracy: 0.925531914893617\n",
            "Validation loss: 447.5720668435097\n",
            "Validation accuracy: 0.7693065405831363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZu3tyuNvQe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "b833c2a5-a075-4f36-bcfc-1c0b3928b6f3"
      },
      "source": [
        "# Plotting the training and validation history\n",
        "\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(v_a)\n",
        "plt.plot(range(epoch),t_a)\n",
        "plt.plot(range(epoch),v_a)\n",
        "plt.title('ShallowConv model accuracy with num_samples = 300')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(range(epoch),t_l)\n",
        "plt.plot(range(epoch),v_l)\n",
        "plt.title('ShallowConv model loss with num_samples = 300')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'], loc='upper left')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.27698975571316, 0.2929472025216706, 0.30437352245862886, 0.3195429472025217, 0.32959022852639874, 0.347123719464145, 0.3605200945626478, 0.38081166272655637, 0.38987391646966113, 0.3983451536643026, 0.4083924349881797, 0.42257683215130026, 0.42139479905437355, 0.435973207249803, 0.44188337273443656, 0.4466115051221434, 0.4517336485421592, 0.45468873128447596, 0.4643420015760441, 0.45488573680063044, 0.4649330181245075, 0.475177304964539, 0.48187549251379036, 0.47832939322301027, 0.48699763593380613, 0.48955870764381404, 0.49527186761229314, 0.49901497241922776, 0.49645390070921985, 0.49940898345153667, 0.4992119779353822, 0.5078802206461781, 0.5110323089046493, 0.5141843971631206, 0.5173364854215918, 0.5244286840031521, 0.5262017336485422, 0.5323089046493302, 0.5372340425531915, 0.539598108747045, 0.5411741528762806, 0.5425531914893617, 0.5468873128447597, 0.5514184397163121, 0.553585500394011, 0.5522064617809299, 0.5709219858156028, 0.5606776989755713, 0.5567375886524822, 0.5596926713947991, 0.5829393223010244, 0.5815602836879432, 0.5746650906225375, 0.5979117415287628, 0.5977147360126084, 0.6014578408195429, 0.6038219070133963, 0.5884554767533491, 0.5973207249802994, 0.5961386918833728, 0.6122931442080378, 0.6089440504334122, 0.6065799842395587, 0.619779353821907, 0.6184003152088259, 0.6176122931442081, 0.611899133175729, 0.6312056737588653, 0.6286446020488574, 0.6341607565011821, 0.6227344365642238, 0.6369188337273444, 0.6245074862096138, 0.6266745468873128, 0.6379038613081166, 0.6337667454688731, 0.6501182033096927, 0.6442080378250591, 0.6483451536643026, 0.6599684791174153, 0.6593774625689519, 0.6497241922773838, 0.6422379826635146, 0.6603624901497241, 0.6585894405043341, 0.6662726556343578, 0.6538613081166272, 0.6631205673758865, 0.6451930654058313, 0.6499211977935382, 0.6666666666666666, 0.6727738376674547, 0.6782899921197794, 0.6745468873128447, 0.6745468873128447, 0.6818360914105595, 0.6743498817966903, 0.6733648542159181, 0.6849881796690307, 0.6851851851851852, 0.6903073286052009, 0.6936564223798266, 0.6623325453112687, 0.681639085894405, 0.6863672182821119, 0.6792750197005516, 0.6830181245074862, 0.6853821907013397, 0.6723798266351458, 0.69424743892829, 0.6711977935382191, 0.6845941686367218, 0.6897163120567376, 0.6806540583136328, 0.6946414499605988, 0.6958234830575256, 0.6903073286052009, 0.6847911741528763, 0.6903073286052009, 0.6907013396375099, 0.6877462568951931, 0.6993695823483057, 0.6830181245074862, 0.6564223798266351, 0.6849881796690307, 0.6991725768321513, 0.6952324665090622, 0.6881402679275019, 0.6796690307328606, 0.6926713947990544, 0.682033096926714, 0.6954294720252167, 0.6605594956658787, 0.6847911741528763, 0.6719858156028369, 0.6889282899921197, 0.6710007880220646, 0.6824271079590228, 0.652876280535855, 0.7011426319936959, 0.6759259259259259, 0.696414499605989, 0.6924743892829, 0.685973207249803, 0.7070527974783294, 0.6692277383766746, 0.6806540583136328, 0.7011426319936959, 0.6830181245074862, 0.7070527974783294, 0.6881402679275019, 0.681639085894405, 0.7076438140267928, 0.7062647754137116, 0.6627265563435776, 0.7117809298660362, 0.7013396375098503, 0.7115839243498818, 0.7019306540583137, 0.7019306540583137, 0.6767139479905437, 0.6934594168636722, 0.6851851851851852, 0.6881402679275019, 0.7037037037037037, 0.7127659574468085, 0.6865642237982663, 0.7147360126083531, 0.7113869188337274, 0.6526792750197006, 0.6983845547675335, 0.7113869188337274, 0.7054767533490938, 0.7214342001576044, 0.7127659574468085, 0.7019306540583137, 0.7218282111899134, 0.7019306540583137, 0.7066587864460205, 0.7184791174152876, 0.6581954294720253, 0.7007486209613869, 0.7241922773837668, 0.7263593380614657, 0.7178881008668243, 0.7129629629629629, 0.7330575256107171, 0.7259653270291568, 0.7186761229314421, 0.7202521670606777, 0.710795902285264, 0.7265563435776202, 0.7145390070921985, 0.7035066981875493, 0.708628841607565, 0.7198581560283688, 0.7257683215130024, 0.7092198581560284, 0.7157210401891253, 0.72123719464145, 0.7328605200945626, 0.7062647754137116, 0.7287234042553191, 0.7391646966115051, 0.7336485421591804, 0.7198581560283688, 0.7338455476753349, 0.7310874704491725, 0.7062647754137116, 0.7176910953506698, 0.7127659574468085, 0.737391646966115, 0.7456658786446021, 0.7348305752561072, 0.7301024428684003, 0.7174940898345153, 0.7379826635145784, 0.7338455476753349, 0.7202521670606777, 0.7285263987391647, 0.7338455476753349, 0.7411347517730497, 0.7263593380614657, 0.7324665090622537, 0.7133569739952719, 0.7344365642237982, 0.7570921985815603, 0.7438928289992119, 0.739558707643814, 0.7450748620961387, 0.7397557131599685, 0.737391646966115, 0.7598502758077226, 0.7523640661938534, 0.7454688731284476, 0.7360126083530338, 0.7551221434200157, 0.7667454688731284, 0.7259653270291568, 0.7669424743892829, 0.7371946414499606, 0.7549251379038613, 0.7486209613869188, 0.7590622537431048, 0.7616233254531127, 0.758274231678487, 0.7618203309692672, 0.7730496453900709, 0.752167060677699, 0.7283293932230103, 0.7594562647754137, 0.7624113475177305, 0.7586682427107959, 0.7616233254531127, 0.7630023640661938, 0.7637903861308116, 0.7596532702915682, 0.7659574468085106, 0.7525610717100079, 0.7767927501970056, 0.7590622537431048, 0.7702915681639085, 0.7669424743892829, 0.7693065405831363, 0.77698975571316, 0.7663514578408196, 0.7762017336485422, 0.7649724192277384, 0.7738376674546887, 0.7724586288416075, 0.7691095350669819, 0.7568951930654059, 0.7795508274231678, 0.7834909377462569, 0.7669424743892829, 0.7752167060677699, 0.7817178881008668, 0.7858550039401103, 0.7813238770685579, 0.7789598108747045, 0.7728526398739165, 0.7732466509062254, 0.7860520094562647, 0.7854609929078015, 0.7803388494877856, 0.7923561859732072, 0.7675334909377463, 0.7728526398739165, 0.7870370370370371, 0.7801418439716312, 0.7943262411347518, 0.7649724192277384, 0.7734436564223798, 0.7844759653270291, 0.7819148936170213, 0.7750197005516154, 0.7736406619385343, 0.7817178881008668, 0.7927501970055162, 0.7866430260047281, 0.7821118991331757, 0.7888100866824271, 0.7917651694247438, 0.7704885736800631, 0.7894011032308904, 0.746059889676911, 0.7836879432624113, 0.7771867612293144, 0.7886130811662726, 0.8022064617809299, 0.7738376674546887, 0.7943262411347518, 0.7939322301024428, 0.776595744680851, 0.7758077226162332, 0.7685185185185185, 0.7907801418439716, 0.8010244286840031, 0.77876280535855, 0.7990543735224587, 0.7911741528762806, 0.7984633569739953, 0.7978723404255319, 0.7925531914893617, 0.7888100866824271, 0.7762017336485422, 0.8045705279747833, 0.7933412135539795, 0.793538219070134, 0.8026004728132388, 0.7834909377462569, 0.77698975571316, 0.8089046493301812, 0.801812450748621, 0.7901891252955082, 0.789598108747045, 0.7860520094562647, 0.780929866036249, 0.8016154452324665, 0.803585500394011, 0.8000394011032309, 0.7980693459416863, 0.7998423955870765, 0.80397951142632, 0.780929866036249, 0.8156028368794326, 0.8043735224586288, 0.7862490149724193, 0.7856579984239559, 0.7825059101654847, 0.801812450748621, 0.7807328605200946, 0.8104806934594169, 0.7943262411347518, 0.7929472025216706, 0.8010244286840031, 0.7848699763593381, 0.8157998423955871, 0.8059495665878644, 0.764381402679275, 0.7947202521670607, 0.7921591804570528, 0.8120567375886525, 0.7874310480693459, 0.8165878644602049, 0.7838849487785658, 0.8187549251379038, 0.7994483845547675, 0.7639873916469662, 0.7758077226162332, 0.8197399527186762, 0.8094956658786446, 0.7964933018124507, 0.7693065405831363, 0.7710795902285263, 0.7797478329393223, 0.7949172576832151, 0.8069345941686368, 0.791371158392435, 0.7864460204885737, 0.7819148936170213, 0.8091016548463357, 0.7868400315208826, 0.8165878644602049, 0.8051615445232466, 0.8027974783293932, 0.814026792750197, 0.8098896769109535, 0.8037825059101655, 0.8004334121355398, 0.8209219858156028, 0.7947202521670607, 0.8173758865248227, 0.8071315996847912, 0.7677304964539007, 0.8120567375886525, 0.8136327817178881, 0.8173758865248227, 0.8055555555555556, 0.8083136327817179, 0.8199369582348306, 0.8138297872340425, 0.8159968479117415, 0.8010244286840031, 0.8167848699763594, 0.8114657210401891, 0.8014184397163121, 0.8104806934594169, 0.8092986603624901, 0.7990543735224587, 0.8154058313632782, 0.8191489361702128, 0.8193459416863672, 0.8136327817178881, 0.8055555555555556, 0.8177698975571316, 0.8087076438140268, 0.8094956658786446, 0.8266351457840819, 0.8067375886524822, 0.8236800630417652, 0.8045705279747833, 0.8002364066193853, 0.8230890464933018, 0.8169818754925138, 0.7978723404255319, 0.8224980299448384, 0.7876280535855004, 0.8069345941686368, 0.8150118203309693, 0.8236800630417652, 0.7750197005516154, 0.7929472025216706, 0.8353033884948778, 0.7683215130023641, 0.8059495665878644, 0.799645390070922, 0.8250591016548463, 0.820133963750985, 0.8187549251379038, 0.8077226162332545, 0.8224980299448384, 0.8181639085894405, 0.8118597320724981, 0.8250591016548463, 0.8043735224586288, 0.8065405831363278, 0.8268321513002365, 0.824468085106383, 0.8268321513002365, 0.7490149724192278, 0.8226950354609929, 0.7998423955870765, 0.8175728920409772, 0.8108747044917257, 0.8400315208825847, 0.8295902285263987, 0.8169818754925138, 0.780929866036249, 0.8053585500394012, 0.7537431048069346, 0.8337273443656422, 0.8396375098502759, 0.8370764381402679, 0.7775807722616234, 0.8134357762017337, 0.8226950354609929, 0.8266351457840819, 0.8240740740740741, 0.8272261623325453, 0.8226950354609929, 0.7998423955870765, 0.8012214342001576, 0.8337273443656422, 0.8262411347517731, 0.8307722616233254, 0.8386524822695035, 0.8116627265563435, 0.8130417651694247, 0.8307722616233254, 0.7834909377462569, 0.8173758865248227, 0.7957052797478329, 0.8110717100078803, 0.7738376674546887, 0.8211189913317573, 0.8215130023640662, 0.8260441292356187, 0.8353033884948778, 0.8297872340425532, 0.814026792750197, 0.8130417651694247, 0.8297872340425532, 0.7799448384554768, 0.8368794326241135, 0.8378644602048857, 0.8264381402679275, 0.8157998423955871, 0.8402285263987391, 0.7693065405831363]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roi_oRfovQe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cfab105-72a4-4994-e718-c9b5aef82c64"
      },
      "source": [
        "# Testing the model\n",
        "\n",
        "num_samples_frame = 300\n",
        "stride = 60\n",
        "X_test_win,y_test_win = make_win_data_pipeline(X_test,y_test,num_samples_frame,stride)\n",
        "\n",
        "# Preparing the test dataset\n",
        "X_test_tensor = torch.from_numpy(X_test_win).float().to(device)\n",
        "y_test_tensor = torch.from_numpy(y_test_win).float().long().to(device) \n",
        "    \n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor) \n",
        "    \n",
        "test_data = EEGDataset(test_dataset, transform=None)\n",
        "\n",
        "test_a = test_model(shallow_model,test_data,criterion)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss tensor(2.7331, device='cuda:0')\n",
            "Test accuracy 40.105342362678705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iwFZMd5vQe4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}